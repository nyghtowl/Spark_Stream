{
 "metadata": {
  "name": "",
  "signature": "sha256:1df067fca857fa5517d7ff43ce9d2e921032d1b32413a4edb89b232e9315ea06"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc # confirming connection works"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<pyspark.context.SparkContext at 0x104695890>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pyspark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [1, 2, 3, 5, 6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData = sc.parallelize(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "[1, 2, 3, 5, 6]"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.reduce(lambda a,b: a+b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "17"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distFile = sc.textFile('../Word_Game_AI/*')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distFile.map(lambda s: len(s)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[12,\n",
        " 12,\n",
        " 0,\n",
        " 136,\n",
        " 14,\n",
        " 0,\n",
        " 19,\n",
        " 26,\n",
        " 11,\n",
        " 26,\n",
        " 0,\n",
        " 41,\n",
        " 11,\n",
        " 29,\n",
        " 26,\n",
        " 29,\n",
        " 49,\n",
        " 0,\n",
        " 25,\n",
        " 26,\n",
        " 0,\n",
        " 26,\n",
        " 11,\n",
        " 70,\n",
        " 11,\n",
        " 50,\n",
        " 22,\n",
        " 0,\n",
        " 24,\n",
        " 38,\n",
        " 4,\n",
        " 34,\n",
        " 65,\n",
        " 50,\n",
        " 8,\n",
        " 54,\n",
        " 73,\n",
        " 50,\n",
        " 12,\n",
        " 39,\n",
        " 11,\n",
        " 79,\n",
        " 0,\n",
        " 82,\n",
        " 47,\n",
        " 0,\n",
        " 68,\n",
        " 45,\n",
        " 11,\n",
        " 155,\n",
        " 22,\n",
        " 31,\n",
        " 56,\n",
        " 0,\n",
        " 0,\n",
        " 27,\n",
        " 11,\n",
        " 41,\n",
        " 11,\n",
        " 15,\n",
        " 27,\n",
        " 31,\n",
        " 18,\n",
        " 4,\n",
        " 0,\n",
        " 27,\n",
        " 11,\n",
        " 67,\n",
        " 0,\n",
        " 72,\n",
        " 79,\n",
        " 0,\n",
        " 71,\n",
        " 34,\n",
        " 8,\n",
        " 20,\n",
        " 58,\n",
        " 11,\n",
        " 35,\n",
        " 0,\n",
        " 27,\n",
        " 16,\n",
        " 37,\n",
        " 28,\n",
        " 28,\n",
        " 38,\n",
        " 36,\n",
        " 28,\n",
        " 28,\n",
        " 19,\n",
        " 0,\n",
        " 4,\n",
        " 22,\n",
        " 11,\n",
        " 52,\n",
        " 11,\n",
        " 19,\n",
        " 47,\n",
        " 48,\n",
        " 21,\n",
        " 0,\n",
        " 4,\n",
        " 16,\n",
        " 12,\n",
        " 27,\n",
        " 0,\n",
        " 30,\n",
        " 12,\n",
        " 27,\n",
        " 0,\n",
        " 19,\n",
        " 12,\n",
        " 31,\n",
        " 1,\n",
        " 20,\n",
        " 55,\n",
        " 39,\n",
        " 1,\n",
        " 0,\n",
        " 13,\n",
        " 13,\n",
        " 0,\n",
        " 16,\n",
        " 36,\n",
        " 13,\n",
        " 0,\n",
        " 26,\n",
        " 212,\n",
        " 1,\n",
        " 0,\n",
        " 37,\n",
        " 13,\n",
        " 49,\n",
        " 0,\n",
        " 31,\n",
        " 0,\n",
        " 16,\n",
        " 7,\n",
        " 74,\n",
        " 4,\n",
        " 61,\n",
        " 27,\n",
        " 7,\n",
        " 42,\n",
        " 18,\n",
        " 44,\n",
        " 31,\n",
        " 17,\n",
        " 23,\n",
        " 45,\n",
        " 46,\n",
        " 19,\n",
        " 0,\n",
        " 31,\n",
        " 7,\n",
        " 68,\n",
        " 67,\n",
        " 43,\n",
        " 0,\n",
        " 28,\n",
        " 22,\n",
        " 7,\n",
        " 45,\n",
        " 13,\n",
        " 22,\n",
        " 35,\n",
        " 15,\n",
        " 1,\n",
        " 0,\n",
        " 22,\n",
        " 37,\n",
        " 0,\n",
        " 1,\n",
        " 28,\n",
        " 1,\n",
        " 26,\n",
        " 7,\n",
        " 67,\n",
        " 0,\n",
        " 68,\n",
        " 71,\n",
        " 39,\n",
        " 0,\n",
        " 71,\n",
        " 79,\n",
        " 0,\n",
        " 36,\n",
        " 74,\n",
        " 21,\n",
        " 7,\n",
        " 17,\n",
        " 24,\n",
        " 0,\n",
        " 80,\n",
        " 8,\n",
        " 21,\n",
        " 20,\n",
        " 0,\n",
        " 17,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 80,\n",
        " 1,\n",
        " 22,\n",
        " 7,\n",
        " 47,\n",
        " 0,\n",
        " 16,\n",
        " 49,\n",
        " 36,\n",
        " 20,\n",
        " 44,\n",
        " 0,\n",
        " 36,\n",
        " 7,\n",
        " 30,\n",
        " 37,\n",
        " 68,\n",
        " 61,\n",
        " 0,\n",
        " 1,\n",
        " 80,\n",
        " 1,\n",
        " 16,\n",
        " 7,\n",
        " 57,\n",
        " 58,\n",
        " 0,\n",
        " 55,\n",
        " 54,\n",
        " 47,\n",
        " 0,\n",
        " 15,\n",
        " 39,\n",
        " 7,\n",
        " 11,\n",
        " 21,\n",
        " 4,\n",
        " 30,\n",
        " 51,\n",
        " 36,\n",
        " 8,\n",
        " 37,\n",
        " 59,\n",
        " 36,\n",
        " 8,\n",
        " 15,\n",
        " 0,\n",
        " 1,\n",
        " 47,\n",
        " 1,\n",
        " 27,\n",
        " 7,\n",
        " 52,\n",
        " 56,\n",
        " 54,\n",
        " 31,\n",
        " 0,\n",
        " 59,\n",
        " 58,\n",
        " 0,\n",
        " 46,\n",
        " 0,\n",
        " 16,\n",
        " 40,\n",
        " 39,\n",
        " 7,\n",
        " 29,\n",
        " 23,\n",
        " 67,\n",
        " 0,\n",
        " 22,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 32,\n",
        " 1,\n",
        " 38,\n",
        " 7,\n",
        " 59,\n",
        " 62,\n",
        " 0,\n",
        " 37,\n",
        " 3,\n",
        " 16,\n",
        " 36,\n",
        " 39,\n",
        " 7,\n",
        " 27,\n",
        " 0,\n",
        " 28,\n",
        " 20,\n",
        " 0,\n",
        " 23,\n",
        " 58,\n",
        " 61,\n",
        " 13,\n",
        " 24,\n",
        " 0,\n",
        " 20,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 28,\n",
        " 1,\n",
        " 0,\n",
        " 27,\n",
        " 8,\n",
        " 63,\n",
        " 4,\n",
        " 35,\n",
        " 20,\n",
        " 7,\n",
        " 62,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 32,\n",
        " 7,\n",
        " 55,\n",
        " 0,\n",
        " 28,\n",
        " 68,\n",
        " 38,\n",
        " 67,\n",
        " 74,\n",
        " 69,\n",
        " 67,\n",
        " 67,\n",
        " 37,\n",
        " 69,\n",
        " 73,\n",
        " 18,\n",
        " 0,\n",
        " 38,\n",
        " 41,\n",
        " 76,\n",
        " 6,\n",
        " 7,\n",
        " 0,\n",
        " 35,\n",
        " 19,\n",
        " 58,\n",
        " 37,\n",
        " 0,\n",
        " 26,\n",
        " 40,\n",
        " 8,\n",
        " 28,\n",
        " 85,\n",
        " 0,\n",
        " 42,\n",
        " 31,\n",
        " 50,\n",
        " 17,\n",
        " 12,\n",
        " 55,\n",
        " 13,\n",
        " 8,\n",
        " 39,\n",
        " 53,\n",
        " 80,\n",
        " 58,\n",
        " 44,\n",
        " 17,\n",
        " 130,\n",
        " 44,\n",
        " 36,\n",
        " 99,\n",
        " 34,\n",
        " 45,\n",
        " 16,\n",
        " 0,\n",
        " 91,\n",
        " 35,\n",
        " 75,\n",
        " 9,\n",
        " 63,\n",
        " 1,\n",
        " 28,\n",
        " 2,\n",
        " 0,\n",
        " 23,\n",
        " 7,\n",
        " 56,\n",
        " 0,\n",
        " 48,\n",
        " 70,\n",
        " 70,\n",
        " 46,\n",
        " 76,\n",
        " 1,\n",
        " 57,\n",
        " 7,\n",
        " 18,\n",
        " 15,\n",
        " 106,\n",
        " 29,\n",
        " 38,\n",
        " 47,\n",
        " 25,\n",
        " 31,\n",
        " 31,\n",
        " 86,\n",
        " 24,\n",
        " 17,\n",
        " 51,\n",
        " 33,\n",
        " 23,\n",
        " 13,\n",
        " 37,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 61,\n",
        " 1,\n",
        " 26,\n",
        " 26,\n",
        " 22,\n",
        " 2,\n",
        " 93,\n",
        " 13,\n",
        " 6,\n",
        " 6,\n",
        " 97,\n",
        " 6,\n",
        " 13,\n",
        " 55,\n",
        " 26,\n",
        " 245,\n",
        " 203,\n",
        " 74,\n",
        " 4,\n",
        " 61,\n",
        " 27,\n",
        " 57,\n",
        " 254,\n",
        " 73,\n",
        " 16,\n",
        " 68,\n",
        " 67,\n",
        " 43,\n",
        " 0,\n",
        " 28,\n",
        " 22,\n",
        " 184,\n",
        " 2,\n",
        " 121,\n",
        " 67,\n",
        " 0,\n",
        " 68,\n",
        " 71,\n",
        " 39,\n",
        " 0,\n",
        " 71,\n",
        " 79,\n",
        " 0,\n",
        " 36,\n",
        " 74,\n",
        " 21,\n",
        " 248,\n",
        " 60,\n",
        " 13,\n",
        " 17,\n",
        " 47,\n",
        " 0,\n",
        " 16,\n",
        " 49,\n",
        " 36,\n",
        " 20,\n",
        " 44,\n",
        " 0,\n",
        " 36,\n",
        " 389,\n",
        " 57,\n",
        " 58,\n",
        " 0,\n",
        " 55,\n",
        " 54,\n",
        " 47,\n",
        " 0,\n",
        " 15,\n",
        " 39,\n",
        " 76,\n",
        " 43,\n",
        " 128,\n",
        " 104,\n",
        " 52,\n",
        " 56,\n",
        " 54,\n",
        " 31,\n",
        " 0,\n",
        " 59,\n",
        " 58,\n",
        " 0,\n",
        " 46,\n",
        " 0,\n",
        " 16,\n",
        " 40,\n",
        " 39,\n",
        " 164,\n",
        " 26,\n",
        " 145,\n",
        " 59,\n",
        " 62,\n",
        " 0,\n",
        " 37,\n",
        " 3,\n",
        " 16,\n",
        " 36,\n",
        " 39,\n",
        " 214,\n",
        " 87,\n",
        " 63,\n",
        " 4,\n",
        " 35,\n",
        " 20,\n",
        " 20,\n",
        " 375,\n",
        " 8,\n",
        " 55,\n",
        " 0,\n",
        " 28,\n",
        " 68,\n",
        " 38,\n",
        " 67,\n",
        " 74,\n",
        " 69,\n",
        " 67,\n",
        " 67,\n",
        " 37,\n",
        " 69,\n",
        " 73,\n",
        " 18,\n",
        " 0,\n",
        " 38,\n",
        " 41,\n",
        " 76,\n",
        " 6,\n",
        " 132,\n",
        " 45,\n",
        " 313,\n",
        " 200,\n",
        " 56,\n",
        " 0,\n",
        " 48,\n",
        " 70,\n",
        " 70,\n",
        " 46,\n",
        " 76,\n",
        " 1,\n",
        " 57,\n",
        " 250,\n",
        " 452,\n",
        " 18,\n",
        " 11,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 37,\n",
        " 1,\n",
        " 1,\n",
        " 38,\n",
        " 7,\n",
        " 58,\n",
        " 43,\n",
        " 0,\n",
        " 63,\n",
        " 20,\n",
        " 0,\n",
        " 71,\n",
        " 0,\n",
        " 36,\n",
        " 27,\n",
        " 74,\n",
        " 0,\n",
        " 27,\n",
        " 7,\n",
        " 17,\n",
        " 81,\n",
        " 20,\n",
        " 35,\n",
        " 25,\n",
        " 54,\n",
        " 169,\n",
        " 45,\n",
        " 57,\n",
        " 41,\n",
        " 71,\n",
        " 33,\n",
        " 67,\n",
        " 33,\n",
        " 32,\n",
        " 0,\n",
        " 37,\n",
        " 20,\n",
        " 0,\n",
        " 1,\n",
        " 35,\n",
        " 1,\n",
        " 36,\n",
        " 7,\n",
        " 76,\n",
        " 74,\n",
        " 15,\n",
        " 0,\n",
        " 29,\n",
        " 35,\n",
        " 71,\n",
        " 72,\n",
        " 34,\n",
        " 71,\n",
        " 70,\n",
        " 47,\n",
        " 1,\n",
        " 36,\n",
        " 27,\n",
        " 74,\n",
        " 7,\n",
        " 35,\n",
        " 19,\n",
        " 58,\n",
        " 37,\n",
        " 0,\n",
        " 26,\n",
        " 32,\n",
        " 25,\n",
        " 8,\n",
        " 48,\n",
        " 0,\n",
        " 42,\n",
        " 32,\n",
        " 50,\n",
        " 17,\n",
        " 12,\n",
        " 55,\n",
        " 21,\n",
        " 40,\n",
        " 32,\n",
        " 95,\n",
        " 30,\n",
        " 41,\n",
        " 16,\n",
        " 50,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 28,\n",
        " 1,\n",
        " 1,\n",
        " 23,\n",
        " 7,\n",
        " 56,\n",
        " 1,\n",
        " 48,\n",
        " 60,\n",
        " 90,\n",
        " 0,\n",
        " 45,\n",
        " 84,\n",
        " 0,\n",
        " 55,\n",
        " 61,\n",
        " 67,\n",
        " 6,\n",
        " 62,\n",
        " 49,\n",
        " 62,\n",
        " 58,\n",
        " 0,\n",
        " 73,\n",
        " 0,\n",
        " 27,\n",
        " 7,\n",
        " 66,\n",
        " 0,\n",
        " 18,\n",
        " 0,\n",
        " 15,\n",
        " 27,\n",
        " 94,\n",
        " 17,\n",
        " 29,\n",
        " 51,\n",
        " 31,\n",
        " 55,\n",
        " 17,\n",
        " 41,\n",
        " 30,\n",
        " 0,\n",
        " 107,\n",
        " 13,\n",
        " 29,\n",
        " 17,\n",
        " 31,\n",
        " 38,\n",
        " 40,\n",
        " 25,\n",
        " 31,\n",
        " 31,\n",
        " 86,\n",
        " 24,\n",
        " 17,\n",
        " 44,\n",
        " 13,\n",
        " 37,\n",
        " 8,\n",
        " 1,\n",
        " 61,\n",
        " 1,\n",
        " 26,\n",
        " 26,\n",
        " 22,\n",
        " 0,\n",
        " 0,\n",
        " 18,\n",
        " 11,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 37,\n",
        " 1,\n",
        " 1,\n",
        " 35,\n",
        " 7,\n",
        " 58,\n",
        " 43,\n",
        " 0,\n",
        " 63,\n",
        " 43,\n",
        " 0,\n",
        " 66,\n",
        " 0,\n",
        " 36,\n",
        " 27,\n",
        " 27,\n",
        " 7,\n",
        " 147,\n",
        " 80,\n",
        " 0,\n",
        " 81,\n",
        " 0,\n",
        " 35,\n",
        " 0,\n",
        " 54,\n",
        " 169,\n",
        " 0,\n",
        " 57,\n",
        " 0,\n",
        " 71,\n",
        " 0,\n",
        " 67,\n",
        " 0,\n",
        " 0,\n",
        " 37,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 35,\n",
        " 1,\n",
        " 33,\n",
        " 7,\n",
        " 76,\n",
        " 74,\n",
        " 15,\n",
        " 0,\n",
        " 29,\n",
        " 35,\n",
        " 71,\n",
        " 72,\n",
        " 34,\n",
        " 71,\n",
        " 70,\n",
        " 47,\n",
        " 1,\n",
        " 36,\n",
        " 27,\n",
        " 7,\n",
        " 67,\n",
        " 4,\n",
        " 1,\n",
        " 28,\n",
        " 1,\n",
        " 1,\n",
        " 23,\n",
        " 7,\n",
        " 56,\n",
        " 1,\n",
        " 48,\n",
        " 60,\n",
        " 90,\n",
        " 0,\n",
        " 45,\n",
        " 84,\n",
        " 0,\n",
        " 55,\n",
        " 61,\n",
        " 67,\n",
        " 6,\n",
        " 62,\n",
        " 49,\n",
        " 62,\n",
        " 58,\n",
        " 0,\n",
        " 73,\n",
        " 0,\n",
        " 27,\n",
        " 7,\n",
        " 66,\n",
        " 87,\n",
        " 0,\n",
        " 8,\n",
        " 1,\n",
        " 61,\n",
        " 1,\n",
        " 26,\n",
        " 26,\n",
        " 22,\n",
        " 0,\n",
        " 0,\n",
        " 18,\n",
        " 0,\n",
        " 1,\n",
        " 11,\n",
        " 88,\n",
        " 0,\n",
        " 89,\n",
        " 0,\n",
        " 24,\n",
        " 7,\n",
        " 30,\n",
        " 7,\n",
        " 17,\n",
        " 36,\n",
        " 141,\n",
        " 34,\n",
        " 37,\n",
        " 37,\n",
        " 48,\n",
        " 124,\n",
        " 24,\n",
        " 19,\n",
        " 44,\n",
        " 0,\n",
        " 26,\n",
        " 0,\n",
        " 0,\n",
        " 22,\n",
        " 7,\n",
        " 28,\n",
        " 7,\n",
        " 12,\n",
        " 57,\n",
        " 30,\n",
        " 18,\n",
        " 0,\n",
        " 38,\n",
        " 34,\n",
        " 62,\n",
        " 57,\n",
        " 77,\n",
        " 95,\n",
        " 0,\n",
        " 30,\n",
        " 28,\n",
        " 77,\n",
        " 45,\n",
        " 77,\n",
        " 57,\n",
        " 8,\n",
        " 30,\n",
        " 8,\n",
        " 12,\n",
        " 50,\n",
        " 30,\n",
        " 17,\n",
        " 0,\n",
        " 38,\n",
        " 41,\n",
        " 55,\n",
        " 57,\n",
        " 85,\n",
        " 95,\n",
        " 0,\n",
        " 30,\n",
        " 0,\n",
        " 28,\n",
        " 77,\n",
        " 45,\n",
        " 77,\n",
        " 57,\n",
        " 8,\n",
        " 30,\n",
        " 0,\n",
        " 12,\n",
        " 47,\n",
        " 30,\n",
        " 18,\n",
        " 0,\n",
        " 38,\n",
        " 22,\n",
        " 52,\n",
        " 57,\n",
        " 93,\n",
        " 95,\n",
        " 8,\n",
        " 30,\n",
        " 0,\n",
        " 28,\n",
        " 77,\n",
        " 45,\n",
        " 77,\n",
        " 57,\n",
        " 8,\n",
        " 30,\n",
        " 0,\n",
        " 38,\n",
        " 0,\n",
        " 24,\n",
        " 0,\n",
        " 31,\n",
        " 7,\n",
        " 29,\n",
        " 7,\n",
        " 17,\n",
        " 12,\n",
        " 18,\n",
        " 37,\n",
        " 30,\n",
        " 0,\n",
        " 49,\n",
        " 43,\n",
        " 91,\n",
        " 0,\n",
        " 22,\n",
        " 0,\n",
        " 69,\n",
        " 49,\n",
        " 43,\n",
        " 0,\n",
        " 32,\n",
        " 98,\n",
        " 86,\n",
        " 0,\n",
        " 13,\n",
        " 91,\n",
        " 39,\n",
        " 78,\n",
        " 0,\n",
        " 91,\n",
        " 0,\n",
        " 22,\n",
        " 0,\n",
        " 0,\n",
        " 12,\n",
        " 58,\n",
        " 20,\n",
        " 0,\n",
        " 42,\n",
        " 43,\n",
        " 87,\n",
        " 0,\n",
        " 30,\n",
        " 0,\n",
        " 12,\n",
        " 65,\n",
        " 18,\n",
        " 0,\n",
        " 46,\n",
        " 43,\n",
        " 85,\n",
        " 0,\n",
        " 46,\n",
        " 0,\n",
        " 12,\n",
        " 50,\n",
        " 18,\n",
        " 0,\n",
        " 42,\n",
        " 43,\n",
        " 87,\n",
        " 8,\n",
        " 22,\n",
        " 0,\n",
        " 12,\n",
        " 46,\n",
        " 17,\n",
        " 4,\n",
        " 46,\n",
        " 43,\n",
        " 87,\n",
        " 8,\n",
        " 22,\n",
        " 8,\n",
        " ...]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distFile.map(lambda s: len(s)).reduce(lambda a, b: a+b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "601000"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distFile.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "u'Word_Game_AI'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val = sc.wholeTextFiles('../Word_Game_AI/*')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "(u'/Users/willow/Documents/Wiley_Warrick/Projects/Word_Game_AI/README.md',\n",
        " u'Word_Game_AI\\n============\\n\\nWord game from CS class that a user can play or computer can play. The structure was pre-set by the class and is not the most efficient.\\n')"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = sc.textFile(\"../Word_Game_AI/README.md\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "[u'Word_Game_AI',\n",
        " u'============',\n",
        " u'',\n",
        " u'Word game from CS class that a user can play or computer can play. The structure was pre-set by the class and is not the most efficient.']"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lineLengths = lines.map(lambda s: len(s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lineLengths.persist(StorageLevel.DISK_ONLY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "PythonRDD[102] at RDD at PythonRDD.scala:37"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lineLengths.reduce(lambda a, b: a+b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "160"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_file = '../Word_Game_AI/*'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Methods for calling and running values through more complicated functions/methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if __name__ == \"__main__\": # for a script\n",
      "def myFunc(s):\n",
      "    words = s.split(\" \")\n",
      "    return len(words)\n",
      "\n",
      "# sc = SparkContext(...)\n",
      "sc.textFile(sample_file).map(myFunc).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "[1,\n",
        " 1,\n",
        " 1,\n",
        " 27,\n",
        " 3,\n",
        " 1,\n",
        " 2,\n",
        " 7,\n",
        " 9,\n",
        " 11,\n",
        " 1,\n",
        " 15,\n",
        " 9,\n",
        " 12,\n",
        " 11,\n",
        " 11,\n",
        " 11,\n",
        " 1,\n",
        " 13,\n",
        " 9,\n",
        " 1,\n",
        " 6,\n",
        " 9,\n",
        " 21,\n",
        " 9,\n",
        " 16,\n",
        " 11,\n",
        " 1,\n",
        " 12,\n",
        " 13,\n",
        " 5,\n",
        " 12,\n",
        " 15,\n",
        " 18,\n",
        " 9,\n",
        " 17,\n",
        " 15,\n",
        " 18,\n",
        " 13,\n",
        " 7,\n",
        " 9,\n",
        " 20,\n",
        " 1,\n",
        " 23,\n",
        " 14,\n",
        " 1,\n",
        " 18,\n",
        " 13,\n",
        " 9,\n",
        " 23,\n",
        " 11,\n",
        " 12,\n",
        " 18,\n",
        " 1,\n",
        " 1,\n",
        " 6,\n",
        " 9,\n",
        " 14,\n",
        " 9,\n",
        " 11,\n",
        " 12,\n",
        " 15,\n",
        " 10,\n",
        " 5,\n",
        " 1,\n",
        " 7,\n",
        " 9,\n",
        " 19,\n",
        " 1,\n",
        " 20,\n",
        " 21,\n",
        " 1,\n",
        " 22,\n",
        " 12,\n",
        " 9,\n",
        " 10,\n",
        " 18,\n",
        " 9,\n",
        " 11,\n",
        " 1,\n",
        " 12,\n",
        " 13,\n",
        " 19,\n",
        " 14,\n",
        " 18,\n",
        " 12,\n",
        " 16,\n",
        " 18,\n",
        " 11,\n",
        " 10,\n",
        " 1,\n",
        " 5,\n",
        " 6,\n",
        " 9,\n",
        " 15,\n",
        " 9,\n",
        " 11,\n",
        " 12,\n",
        " 17,\n",
        " 10,\n",
        " 1,\n",
        " 5,\n",
        " 3,\n",
        " 2,\n",
        " 2,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 2,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 6,\n",
        " 1,\n",
        " 5,\n",
        " 10,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 2,\n",
        " 1,\n",
        " 3,\n",
        " 3,\n",
        " 3,\n",
        " 1,\n",
        " 3,\n",
        " 56,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 3,\n",
        " 9,\n",
        " 1,\n",
        " 3,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 16,\n",
        " 5,\n",
        " 15,\n",
        " 9,\n",
        " 5,\n",
        " 10,\n",
        " 7,\n",
        " 9,\n",
        " 9,\n",
        " 7,\n",
        " 8,\n",
        " 9,\n",
        " 11,\n",
        " 6,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 15,\n",
        " 16,\n",
        " 11,\n",
        " 1,\n",
        " 8,\n",
        " 6,\n",
        " 5,\n",
        " 10,\n",
        " 7,\n",
        " 8,\n",
        " 13,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 5,\n",
        " 2,\n",
        " 1,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 3,\n",
        " 5,\n",
        " 17,\n",
        " 1,\n",
        " 19,\n",
        " 18,\n",
        " 11,\n",
        " 1,\n",
        " 20,\n",
        " 19,\n",
        " 1,\n",
        " 8,\n",
        " 14,\n",
        " 8,\n",
        " 5,\n",
        " 7,\n",
        " 7,\n",
        " 1,\n",
        " 13,\n",
        " 9,\n",
        " 8,\n",
        " 11,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 15,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 11,\n",
        " 1,\n",
        " 6,\n",
        " 9,\n",
        " 9,\n",
        " 14,\n",
        " 11,\n",
        " 1,\n",
        " 9,\n",
        " 5,\n",
        " 8,\n",
        " 12,\n",
        " 35,\n",
        " 40,\n",
        " 1,\n",
        " 1,\n",
        " 15,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 12,\n",
        " 15,\n",
        " 1,\n",
        " 12,\n",
        " 14,\n",
        " 11,\n",
        " 1,\n",
        " 8,\n",
        " 9,\n",
        " 5,\n",
        " 5,\n",
        " 9,\n",
        " 5,\n",
        " 8,\n",
        " 11,\n",
        " 14,\n",
        " 9,\n",
        " 13,\n",
        " 11,\n",
        " 14,\n",
        " 9,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 9,\n",
        " 1,\n",
        " 3,\n",
        " 5,\n",
        " 13,\n",
        " 13,\n",
        " 14,\n",
        " 11,\n",
        " 1,\n",
        " 15,\n",
        " 14,\n",
        " 1,\n",
        " 12,\n",
        " 1,\n",
        " 6,\n",
        " 13,\n",
        " 9,\n",
        " 5,\n",
        " 7,\n",
        " 8,\n",
        " 21,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 4,\n",
        " 5,\n",
        " 15,\n",
        " 13,\n",
        " 1,\n",
        " 10,\n",
        " 4,\n",
        " 6,\n",
        " 9,\n",
        " 9,\n",
        " 5,\n",
        " 7,\n",
        " 1,\n",
        " 9,\n",
        " 10,\n",
        " 1,\n",
        " 8,\n",
        " 16,\n",
        " 19,\n",
        " 9,\n",
        " 14,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 6,\n",
        " 14,\n",
        " 5,\n",
        " 8,\n",
        " 6,\n",
        " 5,\n",
        " 14,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 4,\n",
        " 5,\n",
        " 14,\n",
        " 1,\n",
        " 9,\n",
        " 19,\n",
        " 11,\n",
        " 15,\n",
        " 20,\n",
        " 18,\n",
        " 16,\n",
        " 17,\n",
        " 12,\n",
        " 17,\n",
        " 18,\n",
        " 9,\n",
        " 1,\n",
        " 11,\n",
        " 11,\n",
        " 16,\n",
        " 7,\n",
        " 5,\n",
        " 1,\n",
        " 11,\n",
        " 7,\n",
        " 16,\n",
        " 8,\n",
        " 1,\n",
        " 12,\n",
        " 13,\n",
        " 9,\n",
        " 13,\n",
        " 21,\n",
        " 1,\n",
        " 16,\n",
        " 20,\n",
        " 21,\n",
        " 13,\n",
        " 13,\n",
        " 17,\n",
        " 9,\n",
        " 9,\n",
        " 19,\n",
        " 17,\n",
        " 28,\n",
        " 21,\n",
        " 18,\n",
        " 13,\n",
        " 39,\n",
        " 19,\n",
        " 19,\n",
        " 28,\n",
        " 21,\n",
        " 20,\n",
        " 17,\n",
        " 1,\n",
        " 23,\n",
        " 8,\n",
        " 19,\n",
        " 5,\n",
        " 15,\n",
        " 1,\n",
        " 6,\n",
        " 2,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 14,\n",
        " 1,\n",
        " 15,\n",
        " 20,\n",
        " 20,\n",
        " 15,\n",
        " 19,\n",
        " 2,\n",
        " 18,\n",
        " 5,\n",
        " 7,\n",
        " 6,\n",
        " 28,\n",
        " 12,\n",
        " 15,\n",
        " 15,\n",
        " 15,\n",
        " 12,\n",
        " 16,\n",
        " 29,\n",
        " 17,\n",
        " 13,\n",
        " 19,\n",
        " 14,\n",
        " 19,\n",
        " 9,\n",
        " 14,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 4,\n",
        " 7,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 16,\n",
        " 5,\n",
        " 15,\n",
        " 9,\n",
        " 11,\n",
        " 2,\n",
        " 2,\n",
        " 1,\n",
        " 15,\n",
        " 16,\n",
        " 11,\n",
        " 1,\n",
        " 8,\n",
        " 6,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 17,\n",
        " 1,\n",
        " 19,\n",
        " 18,\n",
        " 11,\n",
        " 1,\n",
        " 20,\n",
        " 19,\n",
        " 1,\n",
        " 8,\n",
        " 14,\n",
        " 8,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 6,\n",
        " 9,\n",
        " 9,\n",
        " 14,\n",
        " 11,\n",
        " 1,\n",
        " 9,\n",
        " 5,\n",
        " 12,\n",
        " 15,\n",
        " 1,\n",
        " 12,\n",
        " 14,\n",
        " 11,\n",
        " 1,\n",
        " 8,\n",
        " 9,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 13,\n",
        " 13,\n",
        " 14,\n",
        " 11,\n",
        " 1,\n",
        " 15,\n",
        " 14,\n",
        " 1,\n",
        " 12,\n",
        " 1,\n",
        " 6,\n",
        " 13,\n",
        " 9,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 15,\n",
        " 13,\n",
        " 1,\n",
        " 10,\n",
        " 4,\n",
        " 6,\n",
        " 9,\n",
        " 9,\n",
        " 5,\n",
        " 2,\n",
        " 14,\n",
        " 5,\n",
        " 8,\n",
        " 6,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 14,\n",
        " 1,\n",
        " 9,\n",
        " 19,\n",
        " 11,\n",
        " 15,\n",
        " 20,\n",
        " 18,\n",
        " 16,\n",
        " 17,\n",
        " 12,\n",
        " 17,\n",
        " 18,\n",
        " 9,\n",
        " 1,\n",
        " 11,\n",
        " 11,\n",
        " 16,\n",
        " 7,\n",
        " 22,\n",
        " 7,\n",
        " 14,\n",
        " 1,\n",
        " 14,\n",
        " 1,\n",
        " 15,\n",
        " 20,\n",
        " 20,\n",
        " 15,\n",
        " 19,\n",
        " 2,\n",
        " 18,\n",
        " 35,\n",
        " 1,\n",
        " 4,\n",
        " 2,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 7,\n",
        " 1,\n",
        " 1,\n",
        " 4,\n",
        " 5,\n",
        " 16,\n",
        " 11,\n",
        " 1,\n",
        " 14,\n",
        " 7,\n",
        " 1,\n",
        " 18,\n",
        " 1,\n",
        " 9,\n",
        " 7,\n",
        " 14,\n",
        " 1,\n",
        " 8,\n",
        " 5,\n",
        " 7,\n",
        " 21,\n",
        " 7,\n",
        " 11,\n",
        " 8,\n",
        " 18,\n",
        " 41,\n",
        " 12,\n",
        " 22,\n",
        " 16,\n",
        " 25,\n",
        " 16,\n",
        " 25,\n",
        " 19,\n",
        " 19,\n",
        " 1,\n",
        " 11,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 7,\n",
        " 1,\n",
        " 4,\n",
        " 5,\n",
        " 16,\n",
        " 17,\n",
        " 6,\n",
        " 1,\n",
        " 9,\n",
        " 10,\n",
        " 19,\n",
        " 16,\n",
        " 8,\n",
        " 18,\n",
        " 16,\n",
        " 9,\n",
        " 2,\n",
        " 9,\n",
        " 7,\n",
        " 14,\n",
        " 5,\n",
        " 11,\n",
        " 7,\n",
        " 16,\n",
        " 8,\n",
        " 1,\n",
        " 12,\n",
        " 11,\n",
        " 9,\n",
        " 9,\n",
        " 13,\n",
        " 1,\n",
        " 16,\n",
        " 20,\n",
        " 21,\n",
        " 13,\n",
        " 13,\n",
        " 17,\n",
        " 17,\n",
        " 15,\n",
        " 15,\n",
        " 24,\n",
        " 17,\n",
        " 16,\n",
        " 17,\n",
        " 10,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 14,\n",
        " 2,\n",
        " 15,\n",
        " 18,\n",
        " 24,\n",
        " 1,\n",
        " 15,\n",
        " 23,\n",
        " 1,\n",
        " 12,\n",
        " 19,\n",
        " 20,\n",
        " 7,\n",
        " 20,\n",
        " 16,\n",
        " 20,\n",
        " 17,\n",
        " 1,\n",
        " 18,\n",
        " 1,\n",
        " 7,\n",
        " 5,\n",
        " 16,\n",
        " 1,\n",
        " 7,\n",
        " 1,\n",
        " 6,\n",
        " 10,\n",
        " 27,\n",
        " 13,\n",
        " 16,\n",
        " 19,\n",
        " 16,\n",
        " 19,\n",
        " 13,\n",
        " 18,\n",
        " 17,\n",
        " 1,\n",
        " 29,\n",
        " 9,\n",
        " 12,\n",
        " 13,\n",
        " 12,\n",
        " 15,\n",
        " 15,\n",
        " 15,\n",
        " 12,\n",
        " 16,\n",
        " 29,\n",
        " 17,\n",
        " 13,\n",
        " 19,\n",
        " 9,\n",
        " 14,\n",
        " 9,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 4,\n",
        " 7,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 4,\n",
        " 2,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 7,\n",
        " 1,\n",
        " 1,\n",
        " 3,\n",
        " 5,\n",
        " 16,\n",
        " 11,\n",
        " 1,\n",
        " 14,\n",
        " 10,\n",
        " 1,\n",
        " 14,\n",
        " 1,\n",
        " 9,\n",
        " 7,\n",
        " 8,\n",
        " 5,\n",
        " 26,\n",
        " 19,\n",
        " 1,\n",
        " 21,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 18,\n",
        " 41,\n",
        " 1,\n",
        " 22,\n",
        " 1,\n",
        " 25,\n",
        " 1,\n",
        " 25,\n",
        " 1,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 7,\n",
        " 1,\n",
        " 3,\n",
        " 5,\n",
        " 16,\n",
        " 17,\n",
        " 6,\n",
        " 1,\n",
        " 9,\n",
        " 10,\n",
        " 19,\n",
        " 16,\n",
        " 8,\n",
        " 18,\n",
        " 16,\n",
        " 9,\n",
        " 2,\n",
        " 9,\n",
        " 7,\n",
        " 5,\n",
        " 17,\n",
        " 5,\n",
        " 1,\n",
        " 6,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 14,\n",
        " 2,\n",
        " 15,\n",
        " 18,\n",
        " 24,\n",
        " 1,\n",
        " 15,\n",
        " 23,\n",
        " 1,\n",
        " 12,\n",
        " 19,\n",
        " 20,\n",
        " 7,\n",
        " 20,\n",
        " 16,\n",
        " 20,\n",
        " 17,\n",
        " 1,\n",
        " 18,\n",
        " 1,\n",
        " 7,\n",
        " 5,\n",
        " 16,\n",
        " 18,\n",
        " 1,\n",
        " 9,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 4,\n",
        " 7,\n",
        " 5,\n",
        " 1,\n",
        " 1,\n",
        " 4,\n",
        " 1,\n",
        " 1,\n",
        " 3,\n",
        " 18,\n",
        " 1,\n",
        " 19,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 8,\n",
        " 5,\n",
        " 5,\n",
        " 10,\n",
        " 22,\n",
        " 9,\n",
        " 12,\n",
        " 13,\n",
        " 15,\n",
        " 34,\n",
        " 13,\n",
        " 7,\n",
        " 11,\n",
        " 1,\n",
        " 4,\n",
        " 1,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 8,\n",
        " 5,\n",
        " 7,\n",
        " 12,\n",
        " 7,\n",
        " 7,\n",
        " 1,\n",
        " 8,\n",
        " 8,\n",
        " 12,\n",
        " 12,\n",
        " 18,\n",
        " 18,\n",
        " 1,\n",
        " 12,\n",
        " 8,\n",
        " 18,\n",
        " 13,\n",
        " 17,\n",
        " 16,\n",
        " 9,\n",
        " 12,\n",
        " 9,\n",
        " 7,\n",
        " 11,\n",
        " 7,\n",
        " 7,\n",
        " 1,\n",
        " 8,\n",
        " 9,\n",
        " 11,\n",
        " 12,\n",
        " 26,\n",
        " 18,\n",
        " 1,\n",
        " 12,\n",
        " 1,\n",
        " 8,\n",
        " 18,\n",
        " 13,\n",
        " 17,\n",
        " 16,\n",
        " 9,\n",
        " 12,\n",
        " 1,\n",
        " 7,\n",
        " 14,\n",
        " 7,\n",
        " 7,\n",
        " 1,\n",
        " 8,\n",
        " 7,\n",
        " 14,\n",
        " 12,\n",
        " 34,\n",
        " 18,\n",
        " 9,\n",
        " 12,\n",
        " 1,\n",
        " 8,\n",
        " 18,\n",
        " 13,\n",
        " 17,\n",
        " 16,\n",
        " 9,\n",
        " 12,\n",
        " 1,\n",
        " 7,\n",
        " 1,\n",
        " 4,\n",
        " 1,\n",
        " 2,\n",
        " 5,\n",
        " 8,\n",
        " 5,\n",
        " 5,\n",
        " 7,\n",
        " 7,\n",
        " 7,\n",
        " 7,\n",
        " 1,\n",
        " 9,\n",
        " 11,\n",
        " 24,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 18,\n",
        " 9,\n",
        " 11,\n",
        " 1,\n",
        " 12,\n",
        " 27,\n",
        " 25,\n",
        " 1,\n",
        " 9,\n",
        " 25,\n",
        " 17,\n",
        " 24,\n",
        " 1,\n",
        " 24,\n",
        " 1,\n",
        " 11,\n",
        " 1,\n",
        " 1,\n",
        " 7,\n",
        " 17,\n",
        " 7,\n",
        " 1,\n",
        " 9,\n",
        " 11,\n",
        " 24,\n",
        " 1,\n",
        " 19,\n",
        " 1,\n",
        " 7,\n",
        " 18,\n",
        " 7,\n",
        " 1,\n",
        " 10,\n",
        " 11,\n",
        " 22,\n",
        " 1,\n",
        " 35,\n",
        " 1,\n",
        " 7,\n",
        " 15,\n",
        " 7,\n",
        " 1,\n",
        " 9,\n",
        " 11,\n",
        " 24,\n",
        " 9,\n",
        " 11,\n",
        " 1,\n",
        " 7,\n",
        " 11,\n",
        " 7,\n",
        " 5,\n",
        " 10,\n",
        " 11,\n",
        " 24,\n",
        " 9,\n",
        " 11,\n",
        " 9,\n",
        " ...]"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MyClass(object):\n",
      "    def func(self, s):\n",
      "        return s\n",
      "    def doStuff(self, rdd):\n",
      "        return rdd.map(self.func)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = MyClass()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test.doStuff(sc.textFile(sample_file)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "[u'Word_Game_AI',\n",
        " u'============',\n",
        " u'',\n",
        " u'Word game from CS class that a user can play or computer can play. The structure was pre-set by the class and is not the most efficient.',\n",
        " u'import random ',\n",
        " u'',\n",
        " u'class Hand(object):',\n",
        " u'    def __init__(self, n):',\n",
        " u\"        '''\",\n",
        " u'        Initialize a Hand.',\n",
        " u'',\n",
        " u'        n: integer, the size of the hand.',\n",
        " u\"        '''\",\n",
        " u'        assert type(n) == int',\n",
        " u'        self.HAND_SIZE = n',\n",
        " u\"        self.VOWELS = 'aeiou'\",\n",
        " u\"        self.CONSONANTS = 'bcdfghjklmnpqrstvwxyz'\",\n",
        " u'',\n",
        " u'        # Deal a new hand',\n",
        " u'        self.dealNewHand()',\n",
        " u'',\n",
        " u'    def dealNewHand(self):',\n",
        " u\"        '''\",\n",
        " u'        Deals a new hand, and sets the hand attribute to the new hand.',\n",
        " u\"        '''\",\n",
        " u'        # Set self.hand to a new, empty dictionary',\n",
        " u'        self.hand = {}',\n",
        " u'',\n",
        " u'        # Build the hand',\n",
        " u'        numVowels = self.HAND_SIZE / 3',\n",
        " u'    ',\n",
        " u'        for i in range(numVowels):',\n",
        " u'            x = self.VOWELS[random.randrange(0,len(self.VOWELS))]',\n",
        " u'            self.hand[x] = self.hand.get(x, 0) + 1',\n",
        " u'        ',\n",
        " u'        for i in range(numVowels, self.HAND_SIZE):    ',\n",
        " u'            x = self.CONSONANTS[random.randrange(0,len(self.CONSONANTS))]',\n",
        " u'            self.hand[x] = self.hand.get(x, 0) + 1',\n",
        " u'            ',\n",
        " u'    def setDummyHand(self, handString):',\n",
        " u\"        '''\",\n",
        " u'        Allows you to set a dummy hand. Useful for testing your implementation.',\n",
        " u'',\n",
        " u'        handString: A string of letters you wish to be in the hand. Length of this',\n",
        " u'        string must be equal to self.HAND_SIZE.',\n",
        " u'',\n",
        " u'        This method converts sets the hand attribute to a dictionary',\n",
        " u'        containing the letters of handString.',\n",
        " u\"        '''\",\n",
        " u'        assert len(handString) == self.HAND_SIZE, \"Length of handString ({0}) must equal length of HAND_SIZE ({1})\".format(len(handString), self.HAND_SIZE)',\n",
        " u'        self.hand = {}',\n",
        " u'        for char in handString:',\n",
        " u'            self.hand[char] = self.hand.get(char, 0) + 1',\n",
        " u'',\n",
        " u'',\n",
        " u'    def calculateLen(self):',\n",
        " u\"        '''\",\n",
        " u'        Calculate the length of the hand.',\n",
        " u\"        '''\",\n",
        " u'        ans = 0',\n",
        " u'        for k in self.hand:',\n",
        " u'            ans += self.hand[k]',\n",
        " u'        return ans',\n",
        " u'    ',\n",
        " u'',\n",
        " u'    def update(self, word):',\n",
        " u'        \"\"\"',\n",
        " u'        Does not assume that self.hand has all the letters in word.',\n",
        " u'',\n",
        " u'        Updates the hand: if self.hand does have all the letters to make',\n",
        " u'        the word, modifies self.hand by using up the letters in the given word.',\n",
        " u'',\n",
        " u'        Returns True if the word was able to be made with the letter in',\n",
        " u'        the hand; False otherwise.',\n",
        " u'        ',\n",
        " u'        word: string',\n",
        " u'        returns: Boolean (if the word was or was not made)',\n",
        " u'        \"\"\"',\n",
        " u'        new_hand = self.hand.copy()',\n",
        " u'',\n",
        " u'        for letter in word:',\n",
        " u'            try:',\n",
        " u'                new_hand[letter] -= 1',\n",
        " u'            except KeyError:',\n",
        " u'                return False',\n",
        " u'        for letter in new_hand.keys():',\n",
        " u'            if new_hand[letter] < 0:',\n",
        " u'                return False',\n",
        " u'        self.hand = new_hand',\n",
        " u'        return True',\n",
        " u'',\n",
        " u'    ',\n",
        " u'    def __str__(self):',\n",
        " u\"        '''\",\n",
        " u'        Display a string representation of the hand.',\n",
        " u\"        '''\",\n",
        " u\"        output = ''\",\n",
        " u'        for letter in sorted(self.hand.keys()):',\n",
        " u'            output += letter * self.hand[letter]',\n",
        " u'        return output',\n",
        " u'',\n",
        " u'    ',\n",
        " u'myHand = Hand(7)',\n",
        " u'print myHand',\n",
        " u'print myHand.calculateLen()',\n",
        " u'',\n",
        " u\"myHand.setDummyHand('aazzmsp')\",\n",
        " u'print myHand',\n",
        " u'print myHand.calculateLen()',\n",
        " u'',\n",
        " u\"myHand.update('za')\",\n",
        " u'print myHand',\n",
        " u'# 6.00x Problem Set 4A Template',\n",
        " u'#',\n",
        " u'# The 6.00 Word Game',\n",
        " u'# Created by: Kevin Luu <luuk> and Jenna Wiens <jwiens>',\n",
        " u'# Modified by: Sarina Canelake <sarina>',\n",
        " u'#',\n",
        " u'',\n",
        " u'import random',\n",
        " u'import string',\n",
        " u'',\n",
        " u\"VOWELS = 'aeiou'\",\n",
        " u\"CONSONANTS = 'bcdfghjklmnpqrstvwxyz'\",\n",
        " u'HAND_SIZE = 7',\n",
        " u'',\n",
        " u'SCRABBLE_LETTER_VALUES = {',\n",
        " u\"    'a': 1, 'b': 3, 'c': 3, 'd': 2, 'e': 1, 'f': 4, 'g': 2, 'h': 4, 'i': 1, 'j': 8, 'k': 5, 'l': 1, 'm': 3, 'n': 1, 'o': 1, 'p': 3, 'q': 10, 'r': 1, 's': 1, 't': 1, 'u': 1, 'v': 4, 'w': 4, 'x': 8, 'y': 4, 'z': 10\",\n",
        " u'}',\n",
        " u'',\n",
        " u'# -----------------------------------',\n",
        " u'# Helper code',\n",
        " u\"# (you don't need to understand this helper code)\",\n",
        " u'',\n",
        " u'WORDLIST_FILENAME = \"words.txt\"',\n",
        " u'',\n",
        " u'def loadWords():',\n",
        " u'    \"\"\"',\n",
        " u'    Returns a list of valid words. Words are strings of lowercase letters.',\n",
        " u'    ',\n",
        " u'    Depending on the size of the word list, this function may',\n",
        " u'    take a while to finish.',\n",
        " u'    \"\"\"',\n",
        " u'    print \"Loading word list from file...\"',\n",
        " u'    # inFile: file',\n",
        " u\"    inFile = open(WORDLIST_FILENAME, 'r', 0)\",\n",
        " u'    # wordList: list of strings',\n",
        " u'    wordList = []',\n",
        " u'    for line in inFile:',\n",
        " u'        wordList.append(line.strip().lower())',\n",
        " u'    print \"  \", len(wordList), \"words loaded.\"',\n",
        " u'    return wordList',\n",
        " u'',\n",
        " u'def getFrequencyDict(sequence):',\n",
        " u'    \"\"\"',\n",
        " u'    Returns a dictionary where the keys are elements of the sequence',\n",
        " u'    and the values are integer counts, for the number of times that',\n",
        " u'    an element is repeated in the sequence.',\n",
        " u'',\n",
        " u'    sequence: string or list',\n",
        " u'    return: dictionary',\n",
        " u'    \"\"\"',\n",
        " u'    # freqs: dictionary (element_type -> int)',\n",
        " u'    freq = {}',\n",
        " u'    for x in sequence:',\n",
        " u'        freq[x] = freq.get(x,0) + 1',\n",
        " u'    return freq',\n",
        " u'\\t',\n",
        " u'',\n",
        " u'# (end of helper code)',\n",
        " u'# -----------------------------------',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #1: Scoring a word',\n",
        " u'#',\n",
        " u'def getWordScore(word, n):',\n",
        " u'    \"\"\"',\n",
        " u'    Returns the score for a word. Assumes the word is a valid word.',\n",
        " u'',\n",
        " u'    The score for a word is the sum of the points for letters in the',\n",
        " u'    word, multiplied by the length of the word, PLUS 50 points if all n',\n",
        " u'    letters are used on the first turn.',\n",
        " u'',\n",
        " u'    Letters are scored as in Scrabble; A is worth 1, B is worth 3, C is',\n",
        " u'    worth 3, D is worth 2, E is worth 1, and so on (see SCRABBLE_LETTER_VALUES)',\n",
        " u'',\n",
        " u'    word: string (lowercase letters)',\n",
        " u'    n: integer (HAND_SIZE; i.e., hand size required for additional points)',\n",
        " u'    returns: int >= 0',\n",
        " u'    \"\"\"',\n",
        " u'    points = None',\n",
        " u'    word_len = len(word)',\n",
        " u'',\n",
        " u'    points = word_len * sum([SCRABBLE_LETTER_VALUES[letter] for letter in word])',\n",
        " u'        ',\n",
        " u'    if word_len == n:',\n",
        " u'        points += 50',\n",
        " u'',\n",
        " u'    return points',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #2: Make sure you understand how this function works and what it does!',\n",
        " u'#',\n",
        " u'def displayHand(hand):',\n",
        " u'    \"\"\"',\n",
        " u'    Displays the letters currently in the hand.',\n",
        " u'',\n",
        " u'    For example:',\n",
        " u\"    >>> displayHand({'a':1, 'x':2, 'l':3, 'e':1})\",\n",
        " u'    Should print out something like:',\n",
        " u'       a x x l l l e',\n",
        " u'    The order of the letters is unimportant.',\n",
        " u'',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    \"\"\"',\n",
        " u'    for letter in hand.keys():',\n",
        " u'        for j in range(hand[letter]):',\n",
        " u'             print letter,              # print all on the same line',\n",
        " u'    print                               # print an empty line',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #2: Make sure you understand how this function works and what it does!',\n",
        " u'#',\n",
        " u'def dealHand(n):',\n",
        " u'    \"\"\"',\n",
        " u'    Returns a random hand containing n lowercase letters.',\n",
        " u'    At least n/3 the letters in the hand should be VOWELS.',\n",
        " u'',\n",
        " u'    Hands are represented as dictionaries. The keys are',\n",
        " u'    letters and the values are the number of times the',\n",
        " u'    particular letter is repeated in that hand.',\n",
        " u'',\n",
        " u'    n: int >= 0',\n",
        " u'    returns: dictionary (string -> int)',\n",
        " u'    \"\"\"',\n",
        " u'    hand={}',\n",
        " u'    numVowels = n / 3',\n",
        " u'    ',\n",
        " u'    for i in range(numVowels):',\n",
        " u'        x = VOWELS[random.randrange(0,len(VOWELS))]',\n",
        " u'        hand[x] = hand.get(x, 0) + 1',\n",
        " u'        ',\n",
        " u'    for i in range(numVowels, n):    ',\n",
        " u'        x = CONSONANTS[random.randrange(0,len(CONSONANTS))]',\n",
        " u'        hand[x] = hand.get(x, 0) + 1',\n",
        " u'        ',\n",
        " u'    return hand',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #2: Update a hand by removing letters',\n",
        " u'#',\n",
        " u'def updateHand(hand, word):',\n",
        " u'    \"\"\"',\n",
        " u\"    Assumes that 'hand' has all the letters in word.\",\n",
        " u'    In other words, this assumes that however many times',\n",
        " u\"    a letter appears in 'word', 'hand' has at least as\",\n",
        " u'    many of that letter in it. ',\n",
        " u'',\n",
        " u'    Updates the hand: uses up the letters in the given word',\n",
        " u'    and returns the new hand, without those letters in it.',\n",
        " u'',\n",
        " u'    Has no side effects: does not modify hand.',\n",
        " u'',\n",
        " u'    word: string',\n",
        " u'    hand: dictionary (string -> int)    ',\n",
        " u'    returns: dictionary (string -> int)',\n",
        " u'    \"\"\"',\n",
        " u'    update_hand = hand.copy()',\n",
        " u'    for letter in word:',\n",
        " u'        update_hand[letter] = update_hand.get(letter,0) - 1        ',\n",
        " u'',\n",
        " u'    return update_hand',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #3: Test word validity',\n",
        " u'#',\n",
        " u'def isValidWord(word, hand, wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Returns True if word is in the wordList and is entirely',\n",
        " u'    composed of letters in the hand. Otherwise, returns False.',\n",
        " u'',\n",
        " u'    Does not mutate hand or wordList.',\n",
        " u'   ',\n",
        " u'    word: string',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    wordList: list of lowercase strings',\n",
        " u'    \"\"\"',\n",
        " u'    hand_copy = hand.copy()',\n",
        " u'',\n",
        " u'    if word not in wordList:',\n",
        " u'        return False',\n",
        " u'',\n",
        " u'    for letter in word:',\n",
        " u'        if letter in hand_copy and hand_copy[letter] != 0:',\n",
        " u'            hand_copy[letter] = hand_copy.get(letter,0) - 1  ',\n",
        " u'        else:',\n",
        " u'            return False',\n",
        " u'',\n",
        " u'    return True     ',\n",
        " u'',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #4: Playing a hand',\n",
        " u'#',\n",
        " u'',\n",
        " u'def calculateHandlen(hand):',\n",
        " u'    \"\"\" ',\n",
        " u'    Returns the length (number of letters) in the current hand.',\n",
        " u'    ',\n",
        " u'    hand: dictionary (string-> int)',\n",
        " u'    returns: integer',\n",
        " u'    \"\"\"',\n",
        " u'    return sum([num for num in hand.itervalues() if num != 0])',\n",
        " u'',\n",
        " u'',\n",
        " u'',\n",
        " u'def playHand(hand, wordList, n):',\n",
        " u'    \"\"\"',\n",
        " u'    Allows the user to play the given hand, as follows:',\n",
        " u'',\n",
        " u'    * The hand is displayed.',\n",
        " u'    * The user may input a word or a single period (the string \".\") ',\n",
        " u\"      to indicate they're done playing\",\n",
        " u'    * Invalid words are rejected, and a message is displayed asking',\n",
        " u'      the user to choose another word until they enter a valid word or \".\"',\n",
        " u'    * When a valid word is entered, it uses up letters from the hand.',\n",
        " u'    * After every valid word: the score for that word is displayed,',\n",
        " u'      the remaining letters in the hand are displayed, and the user',\n",
        " u'      is asked to input another word.',\n",
        " u'    * The sum of the word scores is displayed when the hand finishes.',\n",
        " u'    * The hand finishes when there are no more unused letters or the user',\n",
        " u'      inputs a \".\"',\n",
        " u'',\n",
        " u'      hand: dictionary (string -> int)',\n",
        " u'      wordList: list of lowercase strings',\n",
        " u'      n: integer (HAND_SIZE; i.e., hand size required for additional points)',\n",
        " u'      ',\n",
        " u'    \"\"\"',\n",
        " u'',\n",
        " u'    # Keep track of the total score',\n",
        " u'    total_score = 0',\n",
        " u'    # As long as there are still letters left in the hand:',\n",
        " u'    while calculateHandlen(hand) > 0:',\n",
        " u'',\n",
        " u'        # Display the hand',\n",
        " u'        print(\"Current Hand: %s\") % hand',\n",
        " u'        ',\n",
        " u'        # Ask user for input',\n",
        " u'        word = raw_input(\"Enter word, or a \\\\\".\\\\\" to indicate that you are finished:\")',\n",
        " u'',\n",
        " u'        # If the input is a single period:',\n",
        " u\"        if word == '.':        \",\n",
        " u'            # End the game (break out of the loop)',\n",
        " u'            break',\n",
        " u'            ',\n",
        " u'        # Otherwise (the input is not a single period):',\n",
        " u'        else:',\n",
        " u'        ',\n",
        " u'            # If the word is not valid:',\n",
        " u'            if not isValidWord(word, hand, wordList):',\n",
        " u'                # Reject invalid word (print a message followed by a blank line)',\n",
        " u'                print(\"Invalid word, please try again.\\\\n\")',\n",
        " u'            # Otherwise (the word is valid):',\n",
        " u'            else:',\n",
        " u'                # Tell the user how many points the word earned, and the updated total score, in one line followed by a blank line',\n",
        " u'                score = getWordScore(word,n)',\n",
        " u'                total_score += score',\n",
        " u'                print(\"\\\\\\'%s\\\\\\' earned %d points. Total: %d points.\\\\n\") % (word, score , total_score)',\n",
        " u'                # Update the hand ',\n",
        " u'                hand = updateHand(hand, word)',\n",
        " u'                ',\n",
        " u'',\n",
        " u\"    # Game is over (user entered a '.' or ran out of letters), so tell user the total score\",\n",
        " u'    if calculateHandlen(hand) == 0:',\n",
        " u'        print(\"Run out of letters. Total score: %d points. \") % total_score',\n",
        " u'    else:',\n",
        " u'        print(\"Goodbye! Total score: %d points.\") % total_score',\n",
        " u'#',\n",
        " u'# Problem #5: Playing a game',\n",
        " u'# ',\n",
        " u'',\n",
        " u'def playGame(wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Allow the user to play an arbitrary number of hands.',\n",
        " u'',\n",
        " u\"    1) Asks the user to input 'n' or 'r' or 'e'.\",\n",
        " u\"      * If the user inputs 'n', let the user play a new (random) hand.\",\n",
        " u\"      * If the user inputs 'r', let the user play the last hand again.\",\n",
        " u\"      * If the user inputs 'e', exit the game.\",\n",
        " u'      * If the user inputs anything else, tell them their input was invalid.',\n",
        " u' ',\n",
        " u'    2) When done playing the hand, repeat from step 1    ',\n",
        " u'    \"\"\"',\n",
        " u'    played = False',\n",
        " u'    while True:',\n",
        " u'        user_input = raw_input(\"Enter n to deal a new hand, r to replay the last hand, or e to end game:\")',\n",
        " u\"        if user_input == 'n':\",\n",
        " u'            hand = dealHand(HAND_SIZE)',\n",
        " u'            playHand(hand, wordList, HAND_SIZE)',\n",
        " u'            played = True',\n",
        " u\"        elif user_input == 'r':\",\n",
        " u'            if played == False:',\n",
        " u'                print(\"You have not played a hand yet. Please play a new hand first!\")',\n",
        " u'                continue',\n",
        " u'            else:',\n",
        " u'                playHand(hand, wordList, HAND_SIZE)',\n",
        " u\"        elif user_input == 'e':  \",\n",
        " u'            break      ',\n",
        " u'        else:',\n",
        " u'            print(\"Invalid command.\")',\n",
        " u'',\n",
        " u'',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Build data structures used for entire session and play game',\n",
        " u'#',\n",
        " u\"if __name__ == '__main__':\",\n",
        " u'    wordList = loadWords()',\n",
        " u'    playGame(wordList)',\n",
        " u'\\x03\\ufffd',\n",
        " u'\\x0fh\\ufffdRc\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00@\\x00\\x00\\x00sl\\x01\\x00\\x00d\\x00\\x00d\\x01\\x00l\\x00\\x00Z\\x00\\x00d\\x00\\x00d\\x01\\x00l\\x01\\x00Z\\x01\\x00d\\x02\\x00Z\\x02\\x00d\\x03\\x00Z\\x03\\x00d\\x04\\x00Z\\x04\\x00i\\x1a\\x00d\\x05\\x00d\\x06\\x006d\\x07\\x00d\\x08\\x006d\\x07\\x00d\\t\\x006d',\n",
        " u'\\x00d\\x0b\\x006d\\x05\\x00d\\x0c\\x006d',\n",
        " u'\\x00d\\x0e\\x006d',\n",
        " u'\\x00d\\x0f\\x006d',\n",
        " u'\\x00d\\x10\\x006d\\x05\\x00d\\x11\\x006d\\x12\\x00d\\x13\\x006d\\x14\\x00d\\x15\\x006d\\x05\\x00d\\x16\\x006d\\x07\\x00d\\x17\\x006d\\x05\\x00d\\x18\\x006d\\x05\\x00d\\x19\\x006d\\x07\\x00d\\x1a\\x006d\\x1b\\x00d\\x1c\\x006d\\x05\\x00d\\x1d\\x006d\\x05\\x00d\\x1e\\x006d\\x05\\x00d\\x1f\\x006d\\x05\\x00d \\x006d',\n",
        " u'\\x00d!\\x006d',\n",
        " u'\\x00d\"\\x006d\\x12\\x00d#\\x006d',\n",
        " u\"\\x00d$\\x006d\\x1b\\x00d%\\x006Z\\x05\\x00d&\\x00Z\\x06\\x00d'\\x00\\ufffd\\x00\\x00Z\\x07\\x00d(\\x00\\ufffd\\x00\\x00Z\\x08\\x00d)\\x00\\ufffd\\x00\\x00Z\\t\\x00d*\\x00\\ufffd\\x00\\x00Z\",\n",
        " u'\\x00d+\\x00\\ufffd\\x00\\x00Z\\x0b\\x00d,\\x00\\ufffd\\x00\\x00Z\\x0c\\x00d-\\x00\\ufffd\\x00\\x00Z',\n",
        " u'\\x00d.\\x00\\ufffd\\x00\\x00Z\\x0e\\x00d/\\x00\\ufffd\\x00\\x00Z\\x0f\\x00d0\\x00\\ufffd\\x00\\x00Z\\x10\\x00e\\x11\\x00d1\\x00k\\x02\\x00rh\\x01e\\x07\\x00\\ufffd\\x00\\x00Z\\x12\\x00e\\x10\\x00e\\x12\\x00\\ufffd\\x01\\x00\\x01n\\x00\\x00d\\x01\\x00S(2\\x00\\x00\\x00i\\ufffd\\ufffd\\ufffd\\ufffdNt\\x05\\x00\\x00\\x00aeiout\\x15\\x00\\x00\\x00bcdfghjklmnpqrstvwxyzi\\x07\\x00\\x00\\x00i\\x01\\x00\\x00\\x00t\\x01\\x00\\x00\\x00ai\\x03\\x00\\x00\\x00t\\x01\\x00\\x00\\x00bt\\x01\\x00\\x00\\x00ci\\x02\\x00\\x00\\x00t\\x01\\x00\\x00\\x00dt\\x01\\x00\\x00\\x00ei\\x04\\x00\\x00\\x00t\\x01\\x00\\x00\\x00ft\\x01\\x00\\x00\\x00gt\\x01\\x00\\x00\\x00ht\\x01\\x00\\x00\\x00ii\\x08\\x00\\x00\\x00t\\x01\\x00\\x00\\x00ji\\x05\\x00\\x00\\x00t\\x01\\x00\\x00\\x00kt\\x01\\x00\\x00\\x00lt\\x01\\x00\\x00\\x00mt\\x01\\x00\\x00\\x00nt\\x01\\x00\\x00\\x00ot\\x01\\x00\\x00\\x00pi',\n",
        " u\"\\x00\\x00\\x00t\\x01\\x00\\x00\\x00qt\\x01\\x00\\x00\\x00rt\\x01\\x00\\x00\\x00st\\x01\\x00\\x00\\x00tt\\x01\\x00\\x00\\x00ut\\x01\\x00\\x00\\x00vt\\x01\\x00\\x00\\x00wt\\x01\\x00\\x00\\x00xt\\x01\\x00\\x00\\x00yt\\x01\\x00\\x00\\x00zs\\t\\x00\\x00\\x00words.txtc\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00C\\x00\\x00\\x00s^\\x00\\x00\\x00d\\x01\\x00GHt\\x00\\x00t\\x01\\x00d\\x02\\x00d\\x03\\x00\\ufffd\\x03\\x00}\\x00\\x00g\\x00\\x00}\\x01\\x00x'\\x00|\\x00\\x00D]\\x1f\\x00}\\x02\\x00|\\x01\\x00j\\x02\\x00|\\x02\\x00j\\x03\\x00\\ufffd\\x00\\x00j\\x04\\x00\\ufffd\\x00\\x00\\ufffd\\x01\\x00\\x01q$\\x00Wd\\x04\\x00Gt\\x05\\x00|\\x01\\x00\\ufffd\\x01\\x00Gd\\x05\\x00GH|\\x01\\x00S(\\x06\\x00\\x00\\x00s\\ufffd\\x00\\x00\\x00\",\n",
        " u'    Returns a list of valid words. Words are strings of lowercase letters.',\n",
        " u'    ',\n",
        " u'    Depending on the size of the word list, this function may',\n",
        " u'    take a while to finish.',\n",
        " u'    s\\x1e\\x00\\x00\\x00Loading word list from file...R\\x13\\x00\\x00\\x00i\\x00\\x00\\x00\\x00s\\x02\\x00\\x00\\x00  s',\n",
        " u'\\x00\\x00\\x00words loaded.(\\x06\\x00\\x00\\x00t\\x04\\x00\\x00\\x00opent\\x11\\x00\\x00\\x00WORDLIST_FILENAMEt\\x06\\x00\\x00\\x00appendt\\x05\\x00\\x00\\x00stript\\x05\\x00\\x00\\x00lowert\\x03\\x00\\x00\\x00len(\\x03\\x00\\x00\\x00t\\x06\\x00\\x00\\x00inFilet\\x08\\x00\\x00\\x00wordListt\\x04\\x00\\x00\\x00line(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\t\\x00\\x00\\x00loadWords\\x19\\x00\\x00\\x00s\\x0e\\x00\\x00\\x00\\x00\\x07\\x05\\x02\\x12\\x02\\x06\\x01',\n",
        " u'\\x01\\x1d\\x01\\x13\\x01c\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00C\\x00\\x00\\x00s5\\x00\\x00\\x00i\\x00\\x00}\\x01\\x00x(\\x00|\\x00\\x00D] \\x00}\\x02\\x00|\\x01\\x00j\\x00\\x00|\\x02\\x00d\\x01\\x00\\ufffd\\x02\\x00d\\x02\\x00\\x17|\\x01\\x00|\\x02\\x00<q',\n",
        " u'\\x00W|\\x01\\x00S(\\x03\\x00\\x00\\x00s\\ufffd\\x00\\x00\\x00',\n",
        " u'    Returns a dictionary where the keys are elements of the sequence',\n",
        " u'    and the values are integer counts, for the number of times that',\n",
        " u'    an element is repeated in the sequence.',\n",
        " u'',\n",
        " u'    sequence: string or list',\n",
        " u'    return: dictionary',\n",
        " u'    i\\x00\\x00\\x00\\x00i\\x01\\x00\\x00\\x00(\\x01\\x00\\x00\\x00t\\x03\\x00\\x00\\x00get(\\x03\\x00\\x00\\x00t\\x08\\x00\\x00\\x00sequencet\\x04\\x00\\x00\\x00freqR\\x19\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x10\\x00\\x00\\x00getFrequencyDict*\\x00\\x00\\x00s\\x08\\x00\\x00\\x00\\x00',\n",
        " u'\\x06\\x01',\n",
        " u'\\x01\\x1e\\x01c\\x02\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x06\\x00\\x00\\x00C\\x00\\x00\\x00sV\\x00\\x00\\x00d\\x02\\x00}\\x02\\x00t\\x01\\x00|\\x00\\x00\\ufffd\\x01\\x00}\\x03\\x00|\\x03\\x00t\\x02\\x00g\\x00\\x00|\\x00\\x00D]\\x10\\x00}\\x04\\x00t\\x03\\x00|\\x04\\x00\\x19^\\x02\\x00q\\x1f\\x00\\ufffd\\x01\\x00\\x14}\\x02\\x00|\\x03\\x00|\\x01\\x00k\\x02\\x00rR\\x00|\\x02\\x00d\\x01\\x007}\\x02\\x00n\\x00\\x00|\\x02\\x00S(\\x03\\x00\\x00\\x00s\\x1f\\x02\\x00\\x00',\n",
        " u'    Returns the score for a word. Assumes the word is a valid word.',\n",
        " u'',\n",
        " u'    The score for a word is the sum of the points for letters in the',\n",
        " u'    word, multiplied by the length of the word, PLUS 50 points if all n',\n",
        " u'    letters are used on the first turn.',\n",
        " u'',\n",
        " u'    Letters are scored as in Scrabble; A is worth 1, B is worth 3, C is',\n",
        " u'    worth 3, D is worth 2, E is worth 1, and so on (see SCRABBLE_LETTER_VALUES)',\n",
        " u'',\n",
        " u'    word: string (lowercase letters)',\n",
        " u'    n: integer (HAND_SIZE; i.e., hand size required for additional points)',\n",
        " u'    returns: int >= 0',\n",
        " u\"    i2\\x00\\x00\\x00N(\\x04\\x00\\x00\\x00t\\x04\\x00\\x00\\x00NoneR!\\x00\\x00\\x00t\\x03\\x00\\x00\\x00sumt\\x16\\x00\\x00\\x00SCRABBLE_LETTER_VALUES(\\x05\\x00\\x00\\x00t\\x04\\x00\\x00\\x00wordR\\x0f\\x00\\x00\\x00t\\x06\\x00\\x00\\x00pointst\\x08\\x00\\x00\\x00word_lent\\x06\\x00\\x00\\x00letter(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x0c\\x00\\x00\\x00getWordScore@\\x00\\x00\\x00s\\x0c\\x00\\x00\\x00\\x00\\x0f\\x06\\x01\\x0c\\x02'\\x02\\x0c\\x01\",\n",
        " u'\\x02c\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00C\\x00\\x00\\x00s;\\x00\\x00\\x00x3\\x00|\\x00\\x00j\\x00\\x00\\ufffd\\x00\\x00D]%\\x00}\\x01\\x00x\\x1c\\x00t\\x01\\x00|\\x00\\x00|\\x01\\x00\\x19\\ufffd\\x01\\x00D]',\n",
        " u'\\x00}\\x02\\x00|\\x01\\x00Gq$\\x00Wq',\n",
        " u'\\x00WHd\\x01\\x00S(\\x02\\x00\\x00\\x00s\\x06\\x01\\x00\\x00',\n",
        " u'    Displays the letters currently in the hand.',\n",
        " u'',\n",
        " u'    For example:',\n",
        " u\"    >>> displayHand({'a':1, 'x':2, 'l':3, 'e':1})\",\n",
        " u'    Should print out something like:',\n",
        " u'       a x x l l l e',\n",
        " u'    The order of the letters is unimportant.',\n",
        " u'',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    N(\\x02\\x00\\x00\\x00t\\x04\\x00\\x00\\x00keyst\\x05\\x00\\x00\\x00range(\\x03\\x00\\x00\\x00t\\x04\\x00\\x00\\x00handR0\\x00\\x00\\x00R\\x0b\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x0b\\x00\\x00\\x00displayHand]\\x00\\x00\\x00s\\x08\\x00\\x00\\x00\\x00\\x0c\\x13\\x01\\x17\\x01\\x0c\\x01c\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x06\\x00\\x00\\x00C\\x00\\x00\\x00s\\ufffd\\x00\\x00\\x00i\\x00\\x00}\\x01\\x00|\\x00\\x00d\\x01\\x00\\x15}\\x02\\x00xJ\\x00t\\x00\\x00|\\x02\\x00\\ufffd\\x01\\x00D]<\\x00}\\x03\\x00t\\x01\\x00t\\x02\\x00j\\x03\\x00d\\x02\\x00t\\x04\\x00t\\x01\\x00\\ufffd\\x01\\x00\\ufffd\\x02\\x00\\x19}\\x04\\x00|\\x01\\x00j\\x05\\x00|\\x04\\x00d\\x02\\x00\\ufffd\\x02\\x00d\\x03\\x00\\x17|\\x01\\x00|\\x04\\x00<q\\x1d\\x00WxM\\x00t\\x00\\x00|\\x02\\x00|\\x00\\x00\\ufffd\\x02\\x00D]<\\x00}\\x03\\x00t\\x06\\x00t\\x02\\x00j\\x03\\x00d\\x02\\x00t\\x04\\x00t\\x06\\x00\\ufffd\\x01\\x00\\ufffd\\x02\\x00\\x19}\\x04\\x00|\\x01\\x00j\\x05\\x00|\\x04\\x00d\\x02\\x00\\ufffd\\x02\\x00d\\x03\\x00\\x17|\\x01\\x00|\\x04\\x00<qm\\x00W|\\x01\\x00S(\\x04\\x00\\x00\\x00sS\\x01\\x00\\x00',\n",
        " u'    Returns a random hand containing n lowercase letters.',\n",
        " u'    At least n/3 the letters in the hand should be VOWELS.',\n",
        " u'',\n",
        " u'    Hands are represented as dictionaries. The keys are',\n",
        " u'    letters and the values are the number of times the',\n",
        " u'    particular letter is repeated in that hand.',\n",
        " u'',\n",
        " u'    n: int >= 0',\n",
        " u'    returns: dictionary (string -> int)',\n",
        " u'    i\\x03\\x00\\x00\\x00i\\x00\\x00\\x00\\x00i\\x01\\x00\\x00\\x00(\\x07\\x00\\x00\\x00R3\\x00\\x00\\x00t\\x06\\x00\\x00\\x00VOWELSt\\x06\\x00\\x00\\x00randomt\\t\\x00\\x00\\x00randrangeR!\\x00\\x00\\x00R&\\x00\\x00\\x00t',\n",
        " u'\\x00\\x00\\x00CONSONANTS(\\x05\\x00\\x00\\x00R\\x0f\\x00\\x00\\x00R4\\x00\\x00\\x00t\\t\\x00\\x00\\x00numVowelsR',\n",
        " u'\\x00\\x00\\x00R\\x19\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x08\\x00\\x00\\x00dealHandq\\x00\\x00\\x00s\\x12\\x00\\x00\\x00\\x00\\x0c\\x06\\x01',\n",
        " u'\\x02\\x13\\x01\\x1c\\x01\\x1e\\x02\\x16\\x01\\x1c\\x01\\x1e\\x02c\\x02\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00C\\x00\\x00\\x00s;\\x00\\x00\\x00|\\x00\\x00j\\x00\\x00\\ufffd\\x00\\x00}\\x02\\x00x(\\x00|\\x01\\x00D] \\x00}\\x03\\x00|\\x02\\x00j\\x01\\x00|\\x03\\x00d\\x01\\x00\\ufffd\\x02\\x00d\\x02\\x00\\x18|\\x02\\x00|\\x03\\x00<q\\x13\\x00W|\\x02\\x00S(\\x03\\x00\\x00\\x00s\\ufffd\\x01\\x00\\x00',\n",
        " u\"    Assumes that 'hand' has all the letters in word.\",\n",
        " u'    In other words, this assumes that however many times',\n",
        " u\"    a letter appears in 'word', 'hand' has at least as\",\n",
        " u'    many of that letter in it. ',\n",
        " u'',\n",
        " u'    Updates the hand: uses up the letters in the given word',\n",
        " u'    and returns the new hand, without those letters in it.',\n",
        " u'',\n",
        " u'    Has no side effects: does not modify hand.',\n",
        " u'',\n",
        " u'    word: string',\n",
        " u'    hand: dictionary (string -> int)    ',\n",
        " u'    returns: dictionary (string -> int)',\n",
        " u'    i\\x00\\x00\\x00\\x00i\\x01\\x00\\x00\\x00(\\x02\\x00\\x00\\x00t\\x04\\x00\\x00\\x00copyR&\\x00\\x00\\x00(\\x04\\x00\\x00\\x00R4\\x00\\x00\\x00R-\\x00\\x00\\x00t\\x0b\\x00\\x00\\x00update_handR0\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt',\n",
        " u'\\x00\\x00\\x00updateHand\\ufffd\\x00\\x00\\x00s\\x08\\x00\\x00\\x00\\x00\\x10\\x0c\\x01',\n",
        " u'\\x01\\x1e\\x02c\\x03\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x05\\x00\\x00\\x00C\\x00\\x00\\x00sn\\x00\\x00\\x00|\\x01\\x00j\\x00\\x00\\ufffd\\x00\\x00}\\x03\\x00|\\x00\\x00|\\x02\\x00k\\x07\\x00r\\x1c\\x00t\\x01\\x00SxK\\x00|\\x00\\x00D]C\\x00}\\x04\\x00|\\x04\\x00|\\x03\\x00k\\x06\\x00rb\\x00|\\x03\\x00|\\x04\\x00\\x19d\\x01\\x00k\\x03\\x00rb\\x00|\\x03\\x00j\\x02\\x00|\\x04\\x00d\\x01\\x00\\ufffd\\x02\\x00d\\x02\\x00\\x18|\\x03\\x00|\\x04\\x00<q#\\x00t\\x01\\x00Sq#\\x00Wt\\x03\\x00S(\\x03\\x00\\x00\\x00s\\t\\x01\\x00\\x00',\n",
        " u'    Returns True if word is in the wordList and is entirely',\n",
        " u'    composed of letters in the hand. Otherwise, returns False.',\n",
        " u'',\n",
        " u'    Does not mutate hand or wordList.',\n",
        " u'   ',\n",
        " u'    word: string',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    wordList: list of lowercase strings',\n",
        " u'    i\\x00\\x00\\x00\\x00i\\x01\\x00\\x00\\x00(\\x04\\x00\\x00\\x00R<\\x00\\x00\\x00t\\x05\\x00\\x00\\x00FalseR&\\x00\\x00\\x00t\\x04\\x00\\x00\\x00True(\\x05\\x00\\x00\\x00R-\\x00\\x00\\x00R4\\x00\\x00\\x00R#\\x00\\x00\\x00t\\t\\x00\\x00\\x00hand_copyR0\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x0b\\x00\\x00\\x00isValidWord\\ufffd\\x00\\x00\\x00s\\x10\\x00\\x00\\x00\\x00\\x0b\\x0c\\x02\\x0c\\x01\\x04\\x02',\n",
        " u'\\x01\\x1c\\x01\\x1d\\x02\\x08\\x02c\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x05\\x00\\x00\\x00C\\x00\\x00\\x00s/\\x00\\x00\\x00t\\x00\\x00g\\x00\\x00|\\x00\\x00j\\x01\\x00\\ufffd\\x00\\x00D]\\x18\\x00}\\x01\\x00|\\x01\\x00d\\x01\\x00k\\x03\\x00r\\x10\\x00|\\x01\\x00^\\x02\\x00q\\x10\\x00\\ufffd\\x01\\x00S(\\x02\\x00\\x00\\x00s\\ufffd\\x00\\x00\\x00 ',\n",
        " u'    Returns the length (number of letters) in the current hand.',\n",
        " u'    ',\n",
        " u'    hand: dictionary (string-> int)',\n",
        " u'    returns: integer',\n",
        " u'    i\\x00\\x00\\x00\\x00(\\x02\\x00\\x00\\x00R+\\x00\\x00\\x00t',\n",
        " u'\\x00\\x00\\x00itervalues(\\x02\\x00\\x00\\x00R4\\x00\\x00\\x00t\\x03\\x00\\x00\\x00num(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x10\\x00\\x00\\x00calculateHandlen\\ufffd\\x00\\x00\\x00s\\x02\\x00\\x00\\x00\\x00\\x07c\\x03\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x04\\x00\\x00\\x00C\\x00\\x00\\x00s\\ufffd\\x00\\x00\\x00d\\x01\\x00}\\x03\\x00x\\ufffd\\x00t\\x00\\x00|\\x00\\x00\\ufffd\\x01\\x00d\\x01\\x00k\\x04\\x00r\\ufffd\\x00d\\x02\\x00|\\x00\\x00\\x16GHt\\x01\\x00d\\x03\\x00\\ufffd\\x01\\x00}\\x04\\x00|\\x04\\x00d\\x04\\x00k\\x02\\x00r@\\x00Pq\\t\\x00t\\x02\\x00|\\x04\\x00|\\x00\\x00|\\x01\\x00\\ufffd\\x03\\x00sZ\\x00d\\x05\\x00GHq\\t\\x00t\\x03\\x00|\\x04\\x00|\\x02\\x00\\ufffd\\x02\\x00}\\x05\\x00|\\x03\\x00|\\x05\\x007}\\x03\\x00d\\x06\\x00|\\x04\\x00|\\x05\\x00|\\x03\\x00f\\x03\\x00\\x16GHt\\x04\\x00|\\x00\\x00|\\x04\\x00\\ufffd\\x02\\x00}\\x00\\x00q\\t\\x00Wt\\x00\\x00|\\x00\\x00\\ufffd\\x01\\x00d\\x01\\x00k\\x02\\x00r\\ufffd\\x00d\\x07\\x00|\\x03\\x00\\x16GHn\\t\\x00d\\x08\\x00|\\x03\\x00\\x16GHd\\t\\x00S(',\n",
        " u'\\x00\\x00\\x00s\\ufffd\\x03\\x00\\x00',\n",
        " u'    Allows the user to play the given hand, as follows:',\n",
        " u'',\n",
        " u'    * The hand is displayed.',\n",
        " u'    * The user may input a word or a single period (the string \".\") ',\n",
        " u\"      to indicate they're done playing\",\n",
        " u'    * Invalid words are rejected, and a message is displayed asking',\n",
        " u'      the user to choose another word until they enter a valid word or \".\"',\n",
        " u'    * When a valid word is entered, it uses up letters from the hand.',\n",
        " u'    * After every valid word: the score for that word is displayed,',\n",
        " u'      the remaining letters in the hand are displayed, and the user',\n",
        " u'      is asked to input another word.',\n",
        " u'    * The sum of the word scores is displayed when the hand finishes.',\n",
        " u'    * The hand finishes when there are no more unused letters or the user',\n",
        " u'      inputs a \".\"',\n",
        " u'',\n",
        " u'      hand: dictionary (string -> int)',\n",
        " u'      wordList: list of lowercase strings',\n",
        " u'      n: integer (HAND_SIZE; i.e., hand size required for additional points)',\n",
        " u'      ',\n",
        " u'    i\\x00\\x00\\x00\\x00s\\x10\\x00\\x00\\x00Current Hand: %ss7\\x00\\x00\\x00Enter word, or a \".\" to indicate that you are finished:t\\x01\\x00\\x00\\x00.s \\x00\\x00\\x00Invalid word, please try again.',\n",
        " u\"s)\\x00\\x00\\x00'%s' earned %d points. Total: %d points.\",\n",
        " u's,\\x00\\x00\\x00Run out of letters. Total score: %d points. s \\x00\\x00\\x00Goodbye! Total score: %d points.N(\\x05\\x00\\x00\\x00RE\\x00\\x00\\x00t\\t\\x00\\x00\\x00raw_inputRB\\x00\\x00\\x00R1\\x00\\x00\\x00R>\\x00\\x00\\x00(\\x06\\x00\\x00\\x00R4\\x00\\x00\\x00R#\\x00\\x00\\x00R\\x0f\\x00\\x00\\x00t\\x0b\\x00\\x00\\x00total_scoreR-\\x00\\x00\\x00t\\x05\\x00\\x00\\x00score(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x08\\x00\\x00\\x00playHand\\ufffd\\x00\\x00\\x00s\\x1e\\x00\\x00\\x00\\x00\\x18\\x06\\x02\\x15\\x03\\t\\x03\\x0c\\x03\\x0c\\x02\\x04\\x06\\x12\\x02\\x08\\x04\\x0f\\x01',\n",
        " u'\\x01\\x12\\x02\\x13\\x04\\x12\\x01\\x0c\\x02c\\x01\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00C\\x00\\x00\\x00s\\ufffd\\x00\\x00\\x00t\\x00\\x00}\\x01\\x00x\\ufffd\\x00t\\x01\\x00r\\ufffd\\x00t\\x02\\x00d\\x01\\x00\\ufffd\\x01\\x00}\\x02\\x00|\\x02\\x00d\\x02\\x00k\\x02\\x00rL\\x00t\\x03\\x00t\\x04\\x00\\ufffd\\x01\\x00}\\x03\\x00t\\x05\\x00|\\x03\\x00|\\x00\\x00t\\x04\\x00\\ufffd\\x03\\x00\\x01t\\x01\\x00}\\x01\\x00q\\t\\x00|\\x02\\x00d\\x03\\x00k\\x02\\x00r\\ufffd\\x00|\\x01\\x00t\\x00\\x00k\\x02\\x00ro\\x00d\\x04\\x00GHq\\t\\x00q\\ufffd\\x00t\\x05\\x00|\\x03\\x00|\\x00\\x00t\\x04\\x00\\ufffd\\x03\\x00\\x01q\\t\\x00|\\x02\\x00d\\x05\\x00k\\x02\\x00r\\ufffd\\x00Pq\\t\\x00d\\x06\\x00GHq\\t\\x00Wd\\x07\\x00S(\\x08\\x00\\x00\\x00s\\ufffd\\x01\\x00\\x00',\n",
        " u'    Allow the user to play an arbitrary number of hands.',\n",
        " u'',\n",
        " u\"    1) Asks the user to input 'n' or 'r' or 'e'.\",\n",
        " u\"      * If the user inputs 'n', let the user play a new (random) hand.\",\n",
        " u\"      * If the user inputs 'r', let the user play the last hand again.\",\n",
        " u\"      * If the user inputs 'e', exit the game.\",\n",
        " u'      * If the user inputs anything else, tell them their input was invalid.',\n",
        " u' ',\n",
        " u'    2) When done playing the hand, repeat from step 1    ',\n",
        " u'    sH\\x00\\x00\\x00Enter n to deal a new hand, r to replay the last hand, or e to end game:R\\x0f\\x00\\x00\\x00R\\x13\\x00\\x00\\x00s=\\x00\\x00\\x00You have not played a hand yet. Please play a new hand first!R\\x06\\x00\\x00\\x00s\\x10\\x00\\x00\\x00Invalid command.N(\\x06\\x00\\x00\\x00R?\\x00\\x00\\x00R@\\x00\\x00\\x00RG\\x00\\x00\\x00R;\\x00\\x00\\x00t\\t\\x00\\x00\\x00HAND_SIZERJ\\x00\\x00\\x00(\\x04\\x00\\x00\\x00R#\\x00\\x00\\x00t\\x06\\x00\\x00\\x00playedt',\n",
        " u'\\x00\\x00\\x00user_inputR4\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x08\\x00\\x00\\x00playGame\\x11\\x01\\x00\\x00s\\x1e\\x00\\x00\\x00\\x00\\x0c\\x06\\x01\\t\\x01\\x0c\\x01\\x0c\\x01\\x0c\\x01\\x10\\x01\\t\\x01\\x0c\\x01\\x0c\\x01\\x05\\x01\\x06\\x02\\x13\\x01\\x0c\\x01\\x04\\x02t\\x08\\x00\\x00\\x00__main__(\\x13\\x00\\x00\\x00R7\\x00\\x00\\x00t\\x06\\x00\\x00\\x00stringR6\\x00\\x00\\x00R9\\x00\\x00\\x00RK\\x00\\x00\\x00R,\\x00\\x00\\x00R\\x1d\\x00\\x00\\x00R%\\x00\\x00\\x00R)\\x00\\x00\\x00R1\\x00\\x00\\x00R5\\x00\\x00\\x00R;\\x00\\x00\\x00R>\\x00\\x00\\x00RB\\x00\\x00\\x00RE\\x00\\x00\\x00RJ\\x00\\x00\\x00RN\\x00\\x00\\x00t\\x08\\x00\\x00\\x00__name__R#\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00sO\\x00\\x00\\x00/Users/willow/Documents/Hackbright/InterviewP/Problems/python/word_game/ps4a.pyt\\x08\\x00\\x00\\x00<module>\\x08\\x00\\x00\\x00s(\\x00\\x00\\x00\\x0c\\x01\\x0c\\x02\\x06\\x01\\x06\\x01\\x06\\x02\\x03\\x01\\ufffd\\x07\\x06\\x02\\t\\x11\\t\\x16\\t\\x1d\\t\\x14\\t\\x1c\\t\\x1a\\t\\x1e\\t\\x0b\\tA\\t$\\x0c\\x01\\t\\x01',\n",
        " u'from ps4a import *',\n",
        " u'import time',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'#',\n",
        " u'# Problem #6: Computer chooses a word',\n",
        " u'#',\n",
        " u'#',\n",
        " u'def compChooseWord(hand, wordList, n):',\n",
        " u'    \"\"\"',\n",
        " u'    Given a hand and a wordList, find the word that gives ',\n",
        " u'    the maximum value score, and return it.',\n",
        " u'',\n",
        " u'    This word should be calculated by considering all the words',\n",
        " u'    in the wordList.',\n",
        " u'',\n",
        " u'    If no words in the wordList can be made from the hand, return None.',\n",
        " u'',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    wordList: list (string)',\n",
        " u'    n: integer (HAND_SIZE; i.e., hand size required for additional points)',\n",
        " u'',\n",
        " u'    returns: string or None',\n",
        " u'    \"\"\"',\n",
        " u'    max_score = 0',\n",
        " u'    # Create a new variable to store the best word seen so far (initially None)  ',\n",
        " u'    best_word = None',\n",
        " u'    # For each word in the wordList',\n",
        " u'    for word in wordList:',\n",
        " u'        # If you can construct the word from your hand',\n",
        " u\"        # (hint: you can use isValidWord, or - since you don't really need to test if the word is in the wordList - you can make a similar function that omits that test)\",\n",
        " u'        if isValidWord(word, hand, wordList):',\n",
        " u'            # Find out how much making that word is worth',\n",
        " u'            score = getWordScore(word, n)',\n",
        " u'            # If the score for that word is higher than your best score',\n",
        " u'            if score > max_score:',\n",
        " u'                # Update your best score, and best word accordingly',\n",
        " u'                max_score = score',\n",
        " u'                best_word = word',\n",
        " u'',\n",
        " u'    # return the best word you found.',\n",
        " u'    return best_word',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #7: Computer plays a hand',\n",
        " u'#',\n",
        " u'def compPlayHand(hand, wordList, n):',\n",
        " u'    \"\"\"',\n",
        " u'    Allows the computer to play the given hand, following the same procedure',\n",
        " u'    as playHand, except instead of the user choosing a word, the computer ',\n",
        " u'    chooses it.',\n",
        " u'',\n",
        " u'    1) The hand is displayed.',\n",
        " u'    2) The computer chooses a word.',\n",
        " u'    3) After every valid word: the word and the score for that word is ',\n",
        " u'    displayed, the remaining letters in the hand are displayed, and the ',\n",
        " u'    computer chooses another word.',\n",
        " u'    4)  The sum of the word scores is displayed when the hand finishes.',\n",
        " u'    5)  The hand finishes when the computer has exhausted its possible',\n",
        " u'    choices (i.e. compChooseWord returns None).',\n",
        " u' ',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    wordList: list (string)',\n",
        " u'    n: integer (HAND_SIZE; i.e., hand size required for additional points)',\n",
        " u'    \"\"\"',\n",
        " u'    # Keep track of the total score',\n",
        " u'    total_score = 0',\n",
        " u'    # As long as there are still letters left in the hand:',\n",
        " u'    while calculateHandlen(hand) > 0:',\n",
        " u'',\n",
        " u'        # Display the hand',\n",
        " u'        print(\"Current Hand: \"),',\n",
        " u'        displayHand(hand)',\n",
        " u'        ',\n",
        " u'        word = compChooseWord(hand, wordList, n)',\n",
        " u'',\n",
        " u'        # If the input is a single period:',\n",
        " u'        if word == None:        ',\n",
        " u'            # End the game (break out of the loop)',\n",
        " u'            break',\n",
        " u'            ',\n",
        " u'        # Otherwise (the input is not a single period):',\n",
        " u'        else:        ',\n",
        " u'            score = getWordScore(word,n)',\n",
        " u'            total_score += score',\n",
        " u'            print(\"\\\\\\'%s\\\\\\' earned %d points. Total: %d points.\\\\n\") % (word, score , total_score)',\n",
        " u'            # Update the hand ',\n",
        " u'            hand = updateHand(hand, word)',\n",
        " u'                ',\n",
        " u'    print(\"Total score: %d points.\") % total_score',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #8: Playing a game',\n",
        " u'#',\n",
        " u'#',\n",
        " u'def playGame(wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Allow the user to play an arbitrary number of hands.',\n",
        " u' ',\n",
        " u\"    1) Asks the user to input 'n' or 'r' or 'e'.\",\n",
        " u\"        * If the user inputs 'e', immediately exit the game.\",\n",
        " u\"        * If the user inputs anything that's not 'n', 'r', or 'e', keep asking them again.\",\n",
        " u'',\n",
        " u\"    2) Asks the user to input a 'u' or a 'c'.\",\n",
        " u\"        * If the user inputs anything that's not 'c' or 'u', keep asking them again.\",\n",
        " u'',\n",
        " u'    3) Switch functionality based on the above choices:',\n",
        " u\"        * If the user inputted 'n', play a new (random) hand.\",\n",
        " u\"        * Else, if the user inputted 'r', play the last hand again.\",\n",
        " u'      ',\n",
        " u\"        * If the user inputted 'u', let the user play the game\",\n",
        " u'          with the selected hand, using playHand.',\n",
        " u\"        * If the user inputted 'c', let the computer play the \",\n",
        " u'          game with the selected hand, using compPlayHand.',\n",
        " u'',\n",
        " u'    4) After the computer or user has played the hand, repeat from step 1',\n",
        " u'',\n",
        " u'    wordList: list (string)',\n",
        " u'    \"\"\"',\n",
        " u'    # TO DO... <-- Remove this comment when you code this function',\n",
        " u'',\n",
        " u'    played = False',\n",
        " u'',\n",
        " u'    while True:',\n",
        " u'        def choosePlayer():',\n",
        " u'            player = raw_input(\"Enter u to have yourself play, c to have the computer play: \")',\n",
        " u'            print',\n",
        " u\"            if player == 'u':\",\n",
        " u'                playHand(hand, wordList, HAND_SIZE)',\n",
        " u\"            elif player == 'c':\",\n",
        " u'                compPlayHand(hand, wordList, HAND_SIZE)',\n",
        " u'            else:',\n",
        " u'                print(\"Invalid command.\")',\n",
        " u'                choosePlayer()',\n",
        " u'',\n",
        " u'        user_input = raw_input(\"Enter n to deal a new hand, r to replay the last hand, or e to end game: \")',\n",
        " u'        print',\n",
        " u\"        if user_input == 'e':\",\n",
        " u'            break',\n",
        " u\"        elif user_input == 'n':\",\n",
        " u'            hand = dealHand(HAND_SIZE)',\n",
        " u'            game_player = choosePlayer()',\n",
        " u'            played = True',\n",
        " u\"        elif user_input == 'r':\",\n",
        " u'            if played == False:',\n",
        " u'                print(\"You have not played a hand yet. Please play a new hand first!\")',\n",
        " u'                continue',\n",
        " u'            else:',\n",
        " u'                game_player = choosePlayer()',\n",
        " u'        else:',\n",
        " u'            print(\"Invalid command.\")',\n",
        " u'        ',\n",
        " u'#',\n",
        " u'# Build data structures used for entire session and play game',\n",
        " u'#',\n",
        " u\"if __name__ == '__main__':\",\n",
        " u'    wordList = loadWords()',\n",
        " u'    playGame(wordList)',\n",
        " u'',\n",
        " u'',\n",
        " u'from ps4a import *',\n",
        " u'import time',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'#',\n",
        " u'# Problem #6: Computer chooses a word',\n",
        " u'#',\n",
        " u'#',\n",
        " u'def compChooseWord(hand, wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Given a hand and a wordList, find the word that gives ',\n",
        " u'    the maximum value score, and return it.',\n",
        " u'',\n",
        " u'    This word should be calculated by considering all possible ',\n",
        " u'    permutations of lengths 1 to HAND_SIZE.',\n",
        " u'',\n",
        " u'    If all possible permutations are not in wordList, return None.',\n",
        " u'',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    wordList: list (string)',\n",
        " u'    returns: string or None',\n",
        " u'    \"\"\"',\n",
        " u'    # BEGIN PSEUDOCODE <-- Remove this comment when you code this function; do your coding within the pseudocode (leaving those comments in-place!)',\n",
        " u'    # Create a new variable to store the maximum score seen so far (initially 0)',\n",
        " u'',\n",
        " u'    # Create a new variable to store the best word seen so far (initially None)  ',\n",
        " u'',\n",
        " u'    # For each word in the wordList',\n",
        " u'',\n",
        " u'        # If you can construct the word from your hand',\n",
        " u\"        # (hint: you can use isValidWord, or - since you don't really need to test if the word is in the wordList - you can make a similar function that omits that test)\",\n",
        " u'',\n",
        " u'            # Find out how much making that word is worth',\n",
        " u'',\n",
        " u'            # If the score for that word is higher than your best score',\n",
        " u'',\n",
        " u'                # Update your best score, and best word accordingly',\n",
        " u'',\n",
        " u'',\n",
        " u'    # return the best word you found.',\n",
        " u'',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Problem #7: Computer plays a hand',\n",
        " u'#',\n",
        " u'def compPlayHand(hand, wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Allows the computer to play the given hand, following the same procedure',\n",
        " u'    as playHand, except instead of the user choosing a word, the computer ',\n",
        " u'    chooses it.',\n",
        " u'',\n",
        " u'    1) The hand is displayed.',\n",
        " u'    2) The computer chooses a word.',\n",
        " u'    3) After every valid word: the word and the score for that word is ',\n",
        " u'    displayed, the remaining letters in the hand are displayed, and the ',\n",
        " u'    computer chooses another word.',\n",
        " u'    4)  The sum of the word scores is displayed when the hand finishes.',\n",
        " u'    5)  The hand finishes when the computer has exhausted its possible',\n",
        " u'    choices (i.e. compChooseWord returns None).',\n",
        " u' ',\n",
        " u'    hand: dictionary (string -> int)',\n",
        " u'    wordList: list (string)',\n",
        " u'    \"\"\"',\n",
        " u'    # TO DO ... <-- Remove this comment when you code this function',\n",
        " u'    ',\n",
        " u'#',\n",
        " u'# Problem #8: Playing a game',\n",
        " u'#',\n",
        " u'#',\n",
        " u'def playGame(wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Allow the user to play an arbitrary number of hands.',\n",
        " u' ',\n",
        " u\"    1) Asks the user to input 'n' or 'r' or 'e'.\",\n",
        " u\"        * If the user inputs 'e', immediately exit the game.\",\n",
        " u\"        * If the user inputs anything that's not 'n', 'r', or 'e', keep asking them again.\",\n",
        " u'',\n",
        " u\"    2) Asks the user to input a 'u' or a 'c'.\",\n",
        " u\"        * If the user inputs anything that's not 'c' or 'u', keep asking them again.\",\n",
        " u'',\n",
        " u'    3) Switch functionality based on the above choices:',\n",
        " u\"        * If the user inputted 'n', play a new (random) hand.\",\n",
        " u\"        * Else, if the user inputted 'r', play the last hand again.\",\n",
        " u'      ',\n",
        " u\"        * If the user inputted 'u', let the user play the game\",\n",
        " u'          with the selected hand, using playHand.',\n",
        " u\"        * If the user inputted 'c', let the computer play the \",\n",
        " u'          game with the selected hand, using compPlayHand.',\n",
        " u'',\n",
        " u'    4) After the computer or user has played the hand, repeat from step 1',\n",
        " u'',\n",
        " u'    wordList: list (string)',\n",
        " u'    \"\"\"',\n",
        " u'    # TO DO... <-- Remove this comment when you code this function',\n",
        " u'    print \"playGame not yet implemented.\" # <-- Remove this when you code this function',\n",
        " u'',\n",
        " u'        ',\n",
        " u'#',\n",
        " u'# Build data structures used for entire session and play game',\n",
        " u'#',\n",
        " u\"if __name__ == '__main__':\",\n",
        " u'    wordList = loadWords()',\n",
        " u'    playGame(wordList)',\n",
        " u'',\n",
        " u'',\n",
        " u'from ps4a import *',\n",
        " u'',\n",
        " u'#',\n",
        " u'# Test code',\n",
        " u\"# You don't need to understand how this test code works (but feel free to look it over!)\",\n",
        " u'',\n",
        " u'# To run these tests, simply run this file (open up in IDLE, then run the file as normal)',\n",
        " u'',\n",
        " u'def test_getWordScore():',\n",
        " u'    \"\"\"',\n",
        " u'    Unit test for getWordScore',\n",
        " u'    \"\"\"',\n",
        " u'    failure=False',\n",
        " u'    # dictionary of words and scores',\n",
        " u'    words = {(\"\", 7):0, (\"it\", 7):4, (\"was\", 7):18, (\"scored\", 7):54, (\"waybill\", 7):155, (\"outgnaw\", 7):127, (\"fork\", 7):44, (\"fork\", 4):94}',\n",
        " u'    for (word, n) in words.keys():',\n",
        " u'        score = getWordScore(word, n)',\n",
        " u'        if score != words[(word, n)]:',\n",
        " u'            print \"FAILURE: test_getWordScore()\"',\n",
        " u'            print \"\\\\tExpected\", words[(word, n)], \"points but got \\'\" + str(score) + \"\\' for word \\'\" + word + \"\\', n=\" + str(n)',\n",
        " u'            failure=True',\n",
        " u'    if not failure:',\n",
        " u'        print \"SUCCESS: test_getWordScore()\"',\n",
        " u'',\n",
        " u'# end of test_getWordScore',\n",
        " u'',\n",
        " u'',\n",
        " u'def test_updateHand():',\n",
        " u'    \"\"\"',\n",
        " u'    Unit test for updateHand',\n",
        " u'    \"\"\"',\n",
        " u'    # test 1',\n",
        " u\"    handOrig = {'a':1, 'q':1, 'l':2, 'm':1, 'u':1, 'i':1}\",\n",
        " u'    handCopy = handOrig.copy()',\n",
        " u'    word = \"quail\"',\n",
        " u'',\n",
        " u'    hand2 = updateHand(handCopy, word)',\n",
        " u\"    expectedHand1 = {'l':1, 'm':1}\",\n",
        " u\"    expectedHand2 = {'a':0, 'q':0, 'l':1, 'm':1, 'u':0, 'i':0}\",\n",
        " u'    if hand2 != expectedHand1 and hand2 != expectedHand2:',\n",
        " u'        print \"FAILURE: test_updateHand(\\'\"+ word +\"\\', \" + str(handOrig) + \")\"',\n",
        " u'        print \"\\\\tReturned: \", hand2, \"\\\\n\\\\t-- but expected:\", expectedHand1, \"or\", expectedHand2',\n",
        " u'',\n",
        " u'        return # exit function',\n",
        " u'    if handCopy != handOrig:',\n",
        " u'        print \"FAILURE: test_updateHand(\\'\"+ word +\"\\', \" + str(handOrig) + \")\"',\n",
        " u'        print \"\\\\tOriginal hand was\", handOrig',\n",
        " u'        print \"\\\\tbut implementation of updateHand mutated the original hand!\"',\n",
        " u'        print \"\\\\tNow the hand looks like this:\", handCopy',\n",
        " u'        ',\n",
        " u'        return # exit function',\n",
        " u'        ',\n",
        " u'    # test 2',\n",
        " u\"    handOrig = {'e':1, 'v':2, 'n':1, 'i':1, 'l':2}\",\n",
        " u'    handCopy = handOrig.copy()',\n",
        " u'    word = \"evil\"',\n",
        " u'',\n",
        " u'    hand2 = updateHand(handCopy, word)',\n",
        " u\"    expectedHand1 = {'v':1, 'n':1, 'l':1}\",\n",
        " u\"    expectedHand2 = {'e':0, 'v':1, 'n':1, 'i':0, 'l':1}\",\n",
        " u'    if hand2 != expectedHand1 and hand2 != expectedHand2:',\n",
        " u'        print \"FAILURE: test_updateHand(\\'\"+ word +\"\\', \" + str(handOrig) + \")\"        ',\n",
        " u'        print \"\\\\tReturned: \", hand2, \"\\\\n\\\\t-- but expected:\", expectedHand1, \"or\", expectedHand2',\n",
        " u'',\n",
        " u'        return # exit function',\n",
        " u'',\n",
        " u'    if handCopy != handOrig:',\n",
        " u'        print \"FAILURE: test_updateHand(\\'\"+ word +\"\\', \" + str(handOrig) + \")\"',\n",
        " u'        print \"\\\\tOriginal hand was\", handOrig',\n",
        " u'        print \"\\\\tbut implementation of updateHand mutated the original hand!\"',\n",
        " u'        print \"\\\\tNow the hand looks like this:\", handCopy',\n",
        " u'        ',\n",
        " u'        return # exit function',\n",
        " u'',\n",
        " u'    # test 3',\n",
        " u\"    handOrig = {'h': 1, 'e': 1, 'l': 2, 'o': 1}\",\n",
        " u'    handCopy = handOrig.copy()',\n",
        " u'    word = \"hello\"',\n",
        " u'',\n",
        " u'    hand2 = updateHand(handCopy, word)',\n",
        " u'    expectedHand1 = {}',\n",
        " u\"    expectedHand2 = {'h': 0, 'e': 0, 'l': 0, 'o': 0}\",\n",
        " u'    if hand2 != expectedHand1 and hand2 != expectedHand2:',\n",
        " u'        print \"FAILURE: test_updateHand(\\'\"+ word +\"\\', \" + str(handOrig) + \")\"                ',\n",
        " u'        print \"\\\\tReturned: \", hand2, \"\\\\n\\\\t-- but expected:\", expectedHand1, \"or\", expectedHand2',\n",
        " u'        ',\n",
        " u'        return # exit function',\n",
        " u'',\n",
        " u'    if handCopy != handOrig:',\n",
        " u'        print \"FAILURE: test_updateHand(\\'\"+ word +\"\\', \" + str(handOrig) + \")\"',\n",
        " u'        print \"\\\\tOriginal hand was\", handOrig',\n",
        " u'        print \"\\\\tbut implementation of updateHand mutated the original hand!\"',\n",
        " u'        print \"\\\\tNow the hand looks like this:\", handCopy',\n",
        " u'        ',\n",
        " u'        return # exit function',\n",
        " u'',\n",
        " u'    print \"SUCCESS: test_updateHand()\"',\n",
        " u'',\n",
        " u'# end of test_updateHand',\n",
        " u'',\n",
        " u'def test_isValidWord(wordList):',\n",
        " u'    \"\"\"',\n",
        " u'    Unit test for isValidWord',\n",
        " u'    \"\"\"',\n",
        " u'    failure=False',\n",
        " u'    # test 1',\n",
        " u'    word = \"hello\"',\n",
        " u'    handOrig = getFrequencyDict(word)',\n",
        " u'    handCopy = handOrig.copy()',\n",
        " u'',\n",
        " u'    if not isValidWord(word, handCopy, wordList):',\n",
        " u'        print \"FAILURE: test_isValidWord()\"',\n",
        " u'        print \"\\\\tExpected True, but got False for word: \\'\" + word + \"\\' and hand:\", handOrig',\n",
        " u'',\n",
        " u'        failure = True',\n",
        " u'',\n",
        " u'    # Test a second time to see if wordList or hand has been modified',\n",
        " u'    if not isValidWord(word, handCopy, wordList):',\n",
        " u'        print \"FAILURE: test_isValidWord()\"',\n",
        " u'',\n",
        " u'        if handCopy != handOrig:',\n",
        " u'            print \"\\\\tTesting word\", word, \"for a second time - be sure you\\'re not modifying hand.\"',\n",
        " u'            print \"\\\\tAt this point, hand ought to be\", handOrig, \"but it is\", handCopy',\n",
        " u'',\n",
        " u'        else:',\n",
        " u'            print \"\\\\tTesting word\", word, \"for a second time - have you modified wordList?\"',\n",
        " u'            wordInWL = word in wordList',\n",
        " u'            print \"The word\", word, \"should be in wordList - is it?\", wordInWL',\n",
        " u'',\n",
        " u'        print \"\\\\tExpected True, but got False for word: \\'\" + word + \"\\' and hand:\", handCopy',\n",
        " u'',\n",
        " u'        failure = True',\n",
        " u'',\n",
        " u'',\n",
        " u'    # test 2',\n",
        " u\"    hand = {'r': 1, 'a': 3, 'p': 2, 'e': 1, 't': 1, 'u':1}\",\n",
        " u'    word = \"rapture\"',\n",
        " u'',\n",
        " u'    if  isValidWord(word, hand, wordList):',\n",
        " u'        print \"FAILURE: test_isValidWord()\"',\n",
        " u'        print \"\\\\tExpected False, but got True for word: \\'\" + word + \"\\' and hand:\", hand',\n",
        " u'',\n",
        " u'        failure = True        ',\n",
        " u'',\n",
        " u'    # test 3',\n",
        " u\"    hand = {'n': 1, 'h': 1, 'o': 1, 'y': 1, 'd':1, 'w':1, 'e': 2}\",\n",
        " u'    word = \"honey\"',\n",
        " u'',\n",
        " u'    if  not isValidWord(word, hand, wordList):',\n",
        " u'        print \"FAILURE: test_isValidWord()\"',\n",
        " u'        print \"\\\\tExpected True, but got False for word: \\'\"+ word +\"\\' and hand:\", hand',\n",
        " u'',\n",
        " u'        failure = True                        ',\n",
        " u'',\n",
        " u'    # test 4',\n",
        " u\"    hand = {'r': 1, 'a': 3, 'p': 2, 't': 1, 'u':2}\",\n",
        " u'    word = \"honey\"',\n",
        " u'',\n",
        " u'    if  isValidWord(word, hand, wordList):',\n",
        " u'        print \"FAILURE: test_isValidWord()\"',\n",
        " u'        print \"\\\\tExpected False, but got True for word: \\'\" + word + \"\\' and hand:\", hand',\n",
        " u'        ',\n",
        " u'        failure = True',\n",
        " u'',\n",
        " u'    # test 5',\n",
        " u\"    hand = {'e':1, 'v':2, 'n':1, 'i':1, 'l':2}\",\n",
        " u'    word = \"evil\"',\n",
        " u'    ',\n",
        " u'    if  not isValidWord(word, hand, wordList):',\n",
        " u'        print \"FAILURE: test_isValidWord()\"',\n",
        " u'        print \"\\\\tExpected True, but got False for word: \\'\" + word + \"\\' and hand:\", hand',\n",
        " u'        ',\n",
        " u'        failure = True',\n",
        " u'        ',\n",
        " ...]"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MyClass(object):\n",
      "    def __init__(self):\n",
      "        self.field = \"Hello\"\n",
      "    def doStuff(self, rdd):\n",
      "        field = self.field\n",
      "        return rdd.map(lambda s: field + x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test2 = MyClass()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vals = test2.doStuff(sc.textFile(\"../Word_Game_AI/README.md\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "PythonRDD[97] at RDD at PythonRDD.scala:37"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Accumulators"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accum = sc.accumulator(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.parallelize([1,2,3,4]).foreach(lambda x: accum.add(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accum.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "10"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Play with Bloom"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_words(txt):\n",
      "    return filter(lambda x: len(x) > 0, re.sub(\"[^A-Z,a-z]\", \" \", txt).split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jabber_text = \"\"\"\n",
      "`Twas brillig, and the slithy toves\n",
      "  Did gyre and gimble in the wabe:\n",
      "All mimsy were the borogoves,\n",
      "  And the mome raths outgrabe.\n",
      "\n",
      "\"Beware the Jabberwock, my son!\n",
      "  The jaws that bite, the claws that catch!\n",
      "Beware the Jubjub bird, and shun\n",
      "  The frumious Bandersnatch!\"\n",
      "He took his vorpal sword in hand:\n",
      "  Long time the manxome foe he sought --\n",
      "So rested he by the Tumtum tree,\n",
      "  And stood awhile in thought.\n",
      "And, as in uffish thought he stood,\n",
      "  The Jabberwock, with eyes of flame,\n",
      "Came whiffling through the tulgey wood,\n",
      "  And burbled as it came!\n",
      "One, two! One, two! And through and through\n",
      "  The vorpal blade went snicker-snack!\n",
      "He left it dead, and with its head\n",
      "  He went galumphing back.\n",
      "\"And, has thou slain the Jabberwock?\n",
      "  Come to my arms, my beamish boy!\n",
      "O frabjous day! Callooh! Callay!'\n",
      "  He chortled in his joy.\n",
      "\n",
      "`Twas brillig, and the slithy toves\n",
      "  Did gyre and gimble in the wabe;\n",
      "All mimsy were the borogoves,\n",
      "  And the mome raths outgrabe.\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(jabber_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "962"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jabber_words = clean_words(jabber_text.lower())\n",
      "print \"full:\", jabber_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "full: ['twas', 'brillig,', 'and', 'the', 'slithy', 'toves', 'did', 'gyre', 'and', 'gimble', 'in', 'the', 'wabe', 'all', 'mimsy', 'were', 'the', 'borogoves,', 'and', 'the', 'mome', 'raths', 'outgrabe', 'beware', 'the', 'jabberwock,', 'my', 'son', 'the', 'jaws', 'that', 'bite,', 'the', 'claws', 'that', 'catch', 'beware', 'the', 'jubjub', 'bird,', 'and', 'shun', 'the', 'frumious', 'bandersnatch', 'he', 'took', 'his', 'vorpal', 'sword', 'in', 'hand', 'long', 'time', 'the', 'manxome', 'foe', 'he', 'sought', 'so', 'rested', 'he', 'by', 'the', 'tumtum', 'tree,', 'and', 'stood', 'awhile', 'in', 'thought', 'and,', 'as', 'in', 'uffish', 'thought', 'he', 'stood,', 'the', 'jabberwock,', 'with', 'eyes', 'of', 'flame,', 'came', 'whiffling', 'through', 'the', 'tulgey', 'wood,', 'and', 'burbled', 'as', 'it', 'came', 'one,', 'two', 'one,', 'two', 'and', 'through', 'and', 'through', 'the', 'vorpal', 'blade', 'went', 'snicker', 'snack', 'he', 'left', 'it', 'dead,', 'and', 'with', 'its', 'head', 'he', 'went', 'galumphing', 'back', 'and,', 'has', 'thou', 'slain', 'the', 'jabberwock', 'come', 'to', 'my', 'arms,', 'my', 'beamish', 'boy', 'o', 'frabjous', 'day', 'callooh', 'callay', 'he', 'chortled', 'in', 'his', 'joy', 'twas', 'brillig,', 'and', 'the', 'slithy', 'toves', 'did', 'gyre', 'and', 'gimble', 'in', 'the', 'wabe', 'all', 'mimsy', 'were', 'the', 'borogoves,', 'and', 'the', 'mome', 'raths', 'outgrabe']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(jabber_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "167"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jabber_uniq = sorted(set(jabber_words))\n",
      "print \"uniq:\", jabber_uniq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "uniq: ['all', 'and', 'and,', 'arms,', 'as', 'awhile', 'back', 'bandersnatch', 'beamish', 'beware', 'bird,', 'bite,', 'blade', 'borogoves,', 'boy', 'brillig,', 'burbled', 'by', 'callay', 'callooh', 'came', 'catch', 'chortled', 'claws', 'come', 'day', 'dead,', 'did', 'eyes', 'flame,', 'foe', 'frabjous', 'frumious', 'galumphing', 'gimble', 'gyre', 'hand', 'has', 'he', 'head', 'his', 'in', 'it', 'its', 'jabberwock', 'jabberwock,', 'jaws', 'joy', 'jubjub', 'left', 'long', 'manxome', 'mimsy', 'mome', 'my', 'o', 'of', 'one,', 'outgrabe', 'raths', 'rested', 'shun', 'slain', 'slithy', 'snack', 'snicker', 'so', 'son', 'sought', 'stood', 'stood,', 'sword', 'that', 'the', 'thou', 'thought', 'through', 'time', 'to', 'took', 'toves', 'tree,', 'tulgey', 'tumtum', 'twas', 'two', 'uffish', 'vorpal', 'wabe', 'went', 'were', 'whiffling', 'with', 'wood,']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(jabber_uniq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "94"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hyperloglog\n",
      "\n",
      "# accept 1% counting error\n",
      "hll = hyperloglog.HyperLogLog(0.01)\n",
      "\n",
      "for word in jabber_words:\n",
      "  hll.add(word)\n",
      "\n",
      "print \"prob count %d, true count %d\" % (len(hll), len(jabber_uniq))\n",
      "print \"observed error rate %0.2f\" % (abs(len(hll) - len(jabber_uniq)) / float(len(jabber_uniq)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "prob count 93, true count 94\n",
        "observed error rate 0.01\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybloom import BloomFilter\n",
      "\n",
      "bf = BloomFilter(capacity=1000, error_rate=0.001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in jabber_words:\n",
      "    bf.add(word)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intersect = set([])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "less ../Hangman_AI/README.md"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Hangman AI\n",
        "==========\n",
        "\n",
        "Setup a hangman game with JavaScript. It can be run with a human player agains the machine as well as the machine playing itself. \n",
        "\n",
        "Built JavaScript Hangman game that runs results in Chrome Inspecter (or equivalent in other browsers). The game is built to run for a user play or the computer to play. Currently set to have the computer play and run multiple games while graphing the success rate. There is a text list of words that are used to randomly pull a word for the game and then the corpus is used and shortened with the initial size of the word and then based on the results of each guess. Basically the corpus is cut down in size based on the information gathered from guesses.\n",
        "\n",
        "I built this with my mentor in fall 2013 Yoh and we did it to have fun as well as to help me understand prototypal inheritance and  apply machine learning techniques and a little data viz.\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../Hangman_AI/README.md\") as f:\n",
      "    for line in f:\n",
      "        for word in clean_words(line.strip().lower()):\n",
      "            if word in bf:\n",
      "                intersect.add(word)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intersect"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "{'and', 'as', 'did', 'in', 'it', 'my', 'of', 'that', 'the', 'to', 'with'}"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Play with Twitter Stream & NLTK"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pulled connection data to file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stream, testing = twitter_conn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'favorited': False, u'contributors': None, u'truncated': False, u'text': u'@sgnyooo \\u307b\\u3093\\u3068\\u300c\\u3053\\u308c\\u304c\\u30cf\\u30ea\\u30fc\\u30dd\\u30c3\\u30bf\\u30fc\\u306e\\u4e16\\u754c\\u304b\\u30fc\\uff01\\u300d\\u3063\\u3066\\u611f\\u3058\\u3060\\u3088\\uff01\\u8857\\u5168\\u4f53\\u304c\\uff01\\u3042\\u3063\\u3088\\u30fc\\u3053\\u3082\\u30cf\\u30ea\\u30dd\\u30bf\\u77e5\\u3089\\u306a\\u3044\\u52e2\\uff1f', u'possibly_sensitive': False, u'in_reply_to_status_id': 506499022388203520, u'user': {u'follow_request_sent': None, u'profile_use_background_image': True, u'default_profile_image': False, u'id': 545878310, u'verified': False, u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/378800000207793221/b0ab91e1013dd3c45405f9c61bfa00c8_normal.jpeg', u'profile_sidebar_fill_color': u'DDFFCC', u'profile_text_color': u'333333', u'followers_count': 118, u'profile_sidebar_border_color': u'BDDCAD', u'id_str': u'545878310', u'profile_background_color': u'9AE4E8', u'listed_count': 1, u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme16/bg.gif', u'utc_offset': 32400, u'statuses_count': 9851, u'description': u'\\u6d5c\\u540d/\\u4e2d\\u90e8\\u5927\\u30b3\\u30df\\u30e5\\u79d13\\u5e74 \\u30ec\\u30fc\\u30b9\\u597d\\u304d', u'friends_count': 177, u'location': u'', u'profile_link_color': u'0084B4', u'profile_image_url': u'http://pbs.twimg.com/profile_images/378800000207793221/b0ab91e1013dd3c45405f9c61bfa00c8_normal.jpeg', u'following': None, u'geo_enabled': False, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/545878310/1377790209', u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme16/bg.gif', u'name': u'\\u3048\\u307f\\u3053', u'lang': u'ja', u'profile_background_tile': False, u'favourites_count': 356, u'screen_name': u'emikokko29', u'notifications': None, u'url': None, u'created_at': u'Thu Apr 05 10:57:27 +0000 2012', u'contributors_enabled': False, u'time_zone': u'Irkutsk', u'protected': False, u'default_profile': False, u'is_translator': False}, u'filter_level': u'medium', u'geo': None, u'id': 506499390543233024, u'favorite_count': 0, u'lang': u'ja', u'entities': {u'user_mentions': [{u'id': 491960086, u'indices': [0, 8], u'id_str': u'491960086', u'screen_name': u'sgnyooo', u'name': u'\\u3088\\u3046\\u3053'}], u'symbols': [], u'trends': [], u'hashtags': [], u'urls': []}, u'in_reply_to_user_id_str': u'491960086', u'retweeted': False, u'coordinates': None, u'timestamp_ms': u'1409593839672', u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', u'in_reply_to_status_id_str': u'506499022388203520', u'in_reply_to_screen_name': u'sgnyooo', u'id_str': u'506499390543233024', u'place': None, u'retweet_count': 0, u'created_at': u'Mon Sep 01 17:50:39 +0000 2014', u'in_reply_to_user_id': 491960086}\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "too many values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-8749e20ce256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stream.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "{u'contributors': None,\n",
        " u'coordinates': None,\n",
        " u'created_at': u'Mon Sep 01 17:49:38 +0000 2014',\n",
        " u'entities': {u'hashtags': [],\n",
        "  u'media': [{u'display_url': u'pic.twitter.com/Tw1DsOgISM',\n",
        "    u'expanded_url': u'http://twitter.com/relatableog/status/506485135727153152/photo/1',\n",
        "    u'id': 506485133751615488,\n",
        "    u'id_str': u'506485133751615488',\n",
        "    u'indices': [96, 118],\n",
        "    u'media_url': u'http://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "    u'media_url_https': u'https://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "    u'sizes': {u'large': {u'h': 960, u'resize': u'fit', u'w': 640},\n",
        "     u'medium': {u'h': 900, u'resize': u'fit', u'w': 600},\n",
        "     u'small': {u'h': 510, u'resize': u'fit', u'w': 340},\n",
        "     u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}},\n",
        "    u'source_status_id': 506485135727153152,\n",
        "    u'source_status_id_str': u'506485135727153152',\n",
        "    u'type': u'photo',\n",
        "    u'url': u'http://t.co/Tw1DsOgISM'}],\n",
        "  u'symbols': [],\n",
        "  u'trends': [],\n",
        "  u'urls': [],\n",
        "  u'user_mentions': [{u'id': 2612340400,\n",
        "    u'id_str': u'2612340400',\n",
        "    u'indices': [3, 15],\n",
        "    u'name': u'relatable OG',\n",
        "    u'screen_name': u'relatableog'}]},\n",
        " u'extended_entities': {u'media': [{u'display_url': u'pic.twitter.com/Tw1DsOgISM',\n",
        "    u'expanded_url': u'http://twitter.com/relatableog/status/506485135727153152/photo/1',\n",
        "    u'id': 506485133751615488,\n",
        "    u'id_str': u'506485133751615488',\n",
        "    u'indices': [96, 118],\n",
        "    u'media_url': u'http://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "    u'media_url_https': u'https://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "    u'sizes': {u'large': {u'h': 960, u'resize': u'fit', u'w': 640},\n",
        "     u'medium': {u'h': 900, u'resize': u'fit', u'w': 600},\n",
        "     u'small': {u'h': 510, u'resize': u'fit', u'w': 340},\n",
        "     u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}},\n",
        "    u'source_status_id': 506485135727153152,\n",
        "    u'source_status_id_str': u'506485135727153152',\n",
        "    u'type': u'photo',\n",
        "    u'url': u'http://t.co/Tw1DsOgISM'}]},\n",
        " u'favorite_count': 0,\n",
        " u'favorited': False,\n",
        " u'filter_level': u'medium',\n",
        " u'geo': None,\n",
        " u'id': 506499134686502912,\n",
        " u'id_str': u'506499134686502912',\n",
        " u'in_reply_to_screen_name': None,\n",
        " u'in_reply_to_status_id': None,\n",
        " u'in_reply_to_status_id_str': None,\n",
        " u'in_reply_to_user_id': None,\n",
        " u'in_reply_to_user_id_str': None,\n",
        " u'lang': u'sv',\n",
        " u'place': None,\n",
        " u'possibly_sensitive': False,\n",
        " u'retweet_count': 0,\n",
        " u'retweeted': False,\n",
        " u'retweeted_status': {u'contributors': None,\n",
        "  u'coordinates': None,\n",
        "  u'created_at': u'Mon Sep 01 16:54:01 +0000 2014',\n",
        "  u'entities': {u'hashtags': [],\n",
        "   u'media': [{u'display_url': u'pic.twitter.com/Tw1DsOgISM',\n",
        "     u'expanded_url': u'http://twitter.com/relatableog/status/506485135727153152/photo/1',\n",
        "     u'id': 506485133751615488,\n",
        "     u'id_str': u'506485133751615488',\n",
        "     u'indices': [79, 101],\n",
        "     u'media_url': u'http://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "     u'media_url_https': u'https://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "     u'sizes': {u'large': {u'h': 960, u'resize': u'fit', u'w': 640},\n",
        "      u'medium': {u'h': 900, u'resize': u'fit', u'w': 600},\n",
        "      u'small': {u'h': 510, u'resize': u'fit', u'w': 340},\n",
        "      u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}},\n",
        "     u'type': u'photo',\n",
        "     u'url': u'http://t.co/Tw1DsOgISM'}],\n",
        "   u'symbols': [],\n",
        "   u'trends': [],\n",
        "   u'urls': [],\n",
        "   u'user_mentions': []},\n",
        "  u'extended_entities': {u'media': [{u'display_url': u'pic.twitter.com/Tw1DsOgISM',\n",
        "     u'expanded_url': u'http://twitter.com/relatableog/status/506485135727153152/photo/1',\n",
        "     u'id': 506485133751615488,\n",
        "     u'id_str': u'506485133751615488',\n",
        "     u'indices': [79, 101],\n",
        "     u'media_url': u'http://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "     u'media_url_https': u'https://pbs.twimg.com/media/Bwdli7FIAAAAHEi.jpg',\n",
        "     u'sizes': {u'large': {u'h': 960, u'resize': u'fit', u'w': 640},\n",
        "      u'medium': {u'h': 900, u'resize': u'fit', u'w': 600},\n",
        "      u'small': {u'h': 510, u'resize': u'fit', u'w': 340},\n",
        "      u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}},\n",
        "     u'type': u'photo',\n",
        "     u'url': u'http://t.co/Tw1DsOgISM'}]},\n",
        "  u'favorite_count': 7,\n",
        "  u'favorited': False,\n",
        "  u'filter_level': u'low',\n",
        "  u'geo': None,\n",
        "  u'id': 506485135727153152,\n",
        "  u'id_str': u'506485135727153152',\n",
        "  u'in_reply_to_screen_name': None,\n",
        "  u'in_reply_to_status_id': None,\n",
        "  u'in_reply_to_status_id_str': None,\n",
        "  u'in_reply_to_user_id': None,\n",
        "  u'in_reply_to_user_id_str': None,\n",
        "  u'lang': u'sv',\n",
        "  u'place': None,\n",
        "  u'possibly_sensitive': False,\n",
        "  u'retweet_count': 51,\n",
        "  u'retweeted': False,\n",
        "  u'source': u'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
        "  u'text': u'L\\xe4gg ner f\\xf6rhelvete det kommer inte \\xe4ndra n\\xe5got bara g\\xf6ra dom j\\xe4vligt besvikna http://t.co/Tw1DsOgISM',\n",
        "  u'truncated': False,\n",
        "  u'user': {u'contributors_enabled': False,\n",
        "   u'created_at': u'Sun Jun 15 20:41:18 +0000 2014',\n",
        "   u'default_profile': True,\n",
        "   u'default_profile_image': False,\n",
        "   u'description': u'Relate or die',\n",
        "   u'favourites_count': 256,\n",
        "   u'follow_request_sent': None,\n",
        "   u'followers_count': 854,\n",
        "   u'following': None,\n",
        "   u'friends_count': 11,\n",
        "   u'geo_enabled': False,\n",
        "   u'id': 2612340400,\n",
        "   u'id_str': u'2612340400',\n",
        "   u'is_translator': False,\n",
        "   u'lang': u'sv',\n",
        "   u'listed_count': 0,\n",
        "   u'location': u'',\n",
        "   u'name': u'relatable OG',\n",
        "   u'notifications': None,\n",
        "   u'profile_background_color': u'C0DEED',\n",
        "   u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
        "   u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
        "   u'profile_background_tile': False,\n",
        "   u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/2612340400/1402864931',\n",
        "   u'profile_image_url': u'http://pbs.twimg.com/profile_images/478276308674576385/GXhKgdI8_normal.jpeg',\n",
        "   u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/478276308674576385/GXhKgdI8_normal.jpeg',\n",
        "   u'profile_link_color': u'0084B4',\n",
        "   u'profile_sidebar_border_color': u'C0DEED',\n",
        "   u'profile_sidebar_fill_color': u'DDEEF6',\n",
        "   u'profile_text_color': u'333333',\n",
        "   u'profile_use_background_image': True,\n",
        "   u'protected': False,\n",
        "   u'screen_name': u'relatableog',\n",
        "   u'statuses_count': 358,\n",
        "   u'time_zone': None,\n",
        "   u'url': None,\n",
        "   u'utc_offset': None,\n",
        "   u'verified': False}},\n",
        " u'source': u'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
        " u'text': u'RT @relatableog: L\\xe4gg ner f\\xf6rhelvete det kommer inte \\xe4ndra n\\xe5got bara g\\xf6ra dom j\\xe4vligt besvikna http://t.co/Tw1DsOgISM',\n",
        " u'timestamp_ms': u'1409593778687',\n",
        " u'truncated': False,\n",
        " u'user': {u'contributors_enabled': False,\n",
        "  u'created_at': u'Mon May 13 15:25:10 +0000 2013',\n",
        "  u'default_profile': False,\n",
        "  u'default_profile_image': False,\n",
        "  u'description': None,\n",
        "  u'favourites_count': 16173,\n",
        "  u'follow_request_sent': None,\n",
        "  u'followers_count': 354,\n",
        "  u'following': None,\n",
        "  u'friends_count': 215,\n",
        "  u'geo_enabled': False,\n",
        "  u'id': 1425745393,\n",
        "  u'id_str': u'1425745393',\n",
        "  u'is_translator': False,\n",
        "  u'lang': u'sv',\n",
        "  u'listed_count': 3,\n",
        "  u'location': u'0/1 \\u263c 3/4 ',\n",
        "  u'name': u'\\u2716\\ufe0f',\n",
        "  u'notifications': None,\n",
        "  u'profile_background_color': u'FFFFFF',\n",
        "  u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/378800000053646676/a10d85f81d2a9a26ce2bd08924fd029f.jpeg',\n",
        "  u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/378800000053646676/a10d85f81d2a9a26ce2bd08924fd029f.jpeg',\n",
        "  u'profile_background_tile': False,\n",
        "  u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/1425745393/1409577102',\n",
        "  u'profile_image_url': u'http://pbs.twimg.com/profile_images/506493114526474240/u9aCvpvm_normal.jpeg',\n",
        "  u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/506493114526474240/u9aCvpvm_normal.jpeg',\n",
        "  u'profile_link_color': u'000000',\n",
        "  u'profile_sidebar_border_color': u'FFFFFF',\n",
        "  u'profile_sidebar_fill_color': u'DDEEF6',\n",
        "  u'profile_text_color': u'333333',\n",
        "  u'profile_use_background_image': True,\n",
        "  u'protected': False,\n",
        "  u'screen_name': u'linneakidrauhl',\n",
        "  u'statuses_count': 29534,\n",
        "  u'time_zone': u'Athens',\n",
        "  u'url': None,\n",
        "  u'utc_offset': 10800,\n",
        "  u'verified': False}}"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "raw_T = None\n",
      "while not raw_T or 'delete' in raw_T:\n",
      "    raw_T = stream.next()\n",
      "print json.dumps(raw_T, indent=2, sort_keys=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\n",
        "  \"contributors\": null, \n",
        "  \"coordinates\": null, \n",
        "  \"created_at\": \"Mon Sep 01 17:49:38 +0000 2014\", \n",
        "  \"entities\": {\n",
        "    \"hashtags\": [], \n",
        "    \"symbols\": [], \n",
        "    \"trends\": [], \n",
        "    \"urls\": [], \n",
        "    \"user_mentions\": [\n",
        "      {\n",
        "        \"id\": 1608864770, \n",
        "        \"id_str\": \"1608864770\", \n",
        "        \"indices\": [\n",
        "          3, \n",
        "          17\n",
        "        ], \n",
        "        \"name\": \"$a'\", \n",
        "        \"screen_name\": \"salvamiharry_\"\n",
        "      }\n",
        "    ]\n",
        "  }, \n",
        "  \"favorite_count\": 0, \n",
        "  \"favorited\": false, \n",
        "  \"filter_level\": \"medium\", \n",
        "  \"geo\": null, \n",
        "  \"id\": 506499134669742080, \n",
        "  \"id_str\": \"506499134669742080\", \n",
        "  \"in_reply_to_screen_name\": null, \n",
        "  \"in_reply_to_status_id\": null, \n",
        "  \"in_reply_to_status_id_str\": null, \n",
        "  \"in_reply_to_user_id\": null, \n",
        "  \"in_reply_to_user_id_str\": null, \n",
        "  \"lang\": \"it\", \n",
        "  \"place\": null, \n",
        "  \"possibly_sensitive\": false, \n",
        "  \"retweet_count\": 0, \n",
        "  \"retweeted\": false, \n",
        "  \"retweeted_status\": {\n",
        "    \"contributors\": null, \n",
        "    \"coordinates\": null, \n",
        "    \"created_at\": \"Sat Aug 30 12:51:30 +0000 2014\", \n",
        "    \"entities\": {\n",
        "      \"hashtags\": [], \n",
        "      \"symbols\": [], \n",
        "      \"trends\": [], \n",
        "      \"urls\": [], \n",
        "      \"user_mentions\": []\n",
        "    }, \n",
        "    \"favorite_count\": 819, \n",
        "    \"favorited\": false, \n",
        "    \"filter_level\": \"low\", \n",
        "    \"geo\": null, \n",
        "    \"id\": 505699332482678784, \n",
        "    \"id_str\": \"505699332482678784\", \n",
        "    \"in_reply_to_screen_name\": null, \n",
        "    \"in_reply_to_status_id\": null, \n",
        "    \"in_reply_to_status_id_str\": null, \n",
        "    \"in_reply_to_user_id\": null, \n",
        "    \"in_reply_to_user_id_str\": null, \n",
        "    \"lang\": \"it\", \n",
        "    \"place\": null, \n",
        "    \"possibly_sensitive\": false, \n",
        "    \"retweet_count\": 1317, \n",
        "    \"retweeted\": false, \n",
        "    \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \n",
        "    \"text\": \"MA PERCHE' 3 MESI DI VACANZA PASSANO SUBITO,INVECE 8 MESI DI SCUOLA PASSANO COSI' LENTI CHE ANCHE MIRROS DI JUSTIN TIMBERLAKE FINISCE PRIMA?\", \n",
        "    \"truncated\": false, \n",
        "    \"user\": {\n",
        "      \"contributors_enabled\": false, \n",
        "      \"created_at\": \"Sat Jul 20 19:12:16 +0000 2013\", \n",
        "      \"default_profile\": true, \n",
        "      \"default_profile_image\": false, \n",
        "      \"description\": \"Preferiamo ignorarla, la verit\\u00e0. Per non soffrire. Per non guarire. Perch\\u00e9 altrimenti diventeremmo quello che abbiamo paura di essere. Completamente vivi.\", \n",
        "      \"favourites_count\": 2609, \n",
        "      \"follow_request_sent\": null, \n",
        "      \"followers_count\": 4571, \n",
        "      \"following\": null, \n",
        "      \"friends_count\": 3734, \n",
        "      \"geo_enabled\": true, \n",
        "      \"id\": 1608864770, \n",
        "      \"id_str\": \"1608864770\", \n",
        "      \"is_translator\": false, \n",
        "      \"lang\": \"it\", \n",
        "      \"listed_count\": 56, \n",
        "      \"location\": \"\", \n",
        "      \"name\": \"$a'\", \n",
        "      \"notifications\": null, \n",
        "      \"profile_background_color\": \"C0DEED\", \n",
        "      \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \n",
        "      \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \n",
        "      \"profile_background_tile\": false, \n",
        "      \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/1608864770/1407080336\", \n",
        "      \"profile_image_url\": \"http://pbs.twimg.com/profile_images/495956933401001984/tPxW8gLz_normal.jpeg\", \n",
        "      \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/495956933401001984/tPxW8gLz_normal.jpeg\", \n",
        "      \"profile_link_color\": \"0084B4\", \n",
        "      \"profile_sidebar_border_color\": \"C0DEED\", \n",
        "      \"profile_sidebar_fill_color\": \"DDEEF6\", \n",
        "      \"profile_text_color\": \"333333\", \n",
        "      \"profile_use_background_image\": true, \n",
        "      \"protected\": false, \n",
        "      \"screen_name\": \"salvamiharry_\", \n",
        "      \"statuses_count\": 4054, \n",
        "      \"time_zone\": \"Athens\", \n",
        "      \"url\": null, \n",
        "      \"utc_offset\": 10800, \n",
        "      \"verified\": false\n",
        "    }\n",
        "  }, \n",
        "  \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \n",
        "  \"text\": \"RT @salvamiharry_: MA PERCHE' 3 MESI DI VACANZA PASSANO SUBITO,INVECE 8 MESI DI SCUOLA PASSANO COSI' LENTI CHE ANCHE MIRROS DI JUSTIN TIMBE\\u2026\", \n",
        "  \"timestamp_ms\": \"1409593778691\", \n",
        "  \"truncated\": false, \n",
        "  \"user\": {\n",
        "    \"contributors_enabled\": false, \n",
        "    \"created_at\": \"Thu Oct 25 14:22:32 +0000 2012\", \n",
        "    \"default_profile\": false, \n",
        "    \"default_profile_image\": false, \n",
        "    \"description\": \"\\u2728Simplicity is the keynote of true elegance\\u2728\", \n",
        "    \"favourites_count\": 5710, \n",
        "    \"follow_request_sent\": null, \n",
        "    \"followers_count\": 3005, \n",
        "    \"following\": null, \n",
        "    \"friends_count\": 3030, \n",
        "    \"geo_enabled\": true, \n",
        "    \"id\": 904002164, \n",
        "    \"id_str\": \"904002164\", \n",
        "    \"is_translator\": false, \n",
        "    \"lang\": \"it\", \n",
        "    \"listed_count\": 39, \n",
        "    \"location\": \"\", \n",
        "    \"name\": \"\\u2728\\u24b8\\u24bd\\u24b6\\u24c3\\u24ba\\u24c1\\u2728\", \n",
        "    \"notifications\": null, \n",
        "    \"profile_background_color\": \"FFFFFF\", \n",
        "    \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/378800000056436158/4fbc5cfcf7bd528b0b03320cbb2bd23c.jpeg\", \n",
        "    \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/378800000056436158/4fbc5cfcf7bd528b0b03320cbb2bd23c.jpeg\", \n",
        "    \"profile_background_tile\": true, \n",
        "    \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/904002164/1407174226\", \n",
        "    \"profile_image_url\": \"http://pbs.twimg.com/profile_images/496346954209984512/W3nuNHoB_normal.jpeg\", \n",
        "    \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/496346954209984512/W3nuNHoB_normal.jpeg\", \n",
        "    \"profile_link_color\": \"8C6180\", \n",
        "    \"profile_sidebar_border_color\": \"FFFFFF\", \n",
        "    \"profile_sidebar_fill_color\": \"FA1933\", \n",
        "    \"profile_text_color\": \"7D213B\", \n",
        "    \"profile_use_background_image\": true, \n",
        "    \"protected\": false, \n",
        "    \"screen_name\": \"xchanelover\", \n",
        "    \"statuses_count\": 27549, \n",
        "    \"time_zone\": \"Rome\", \n",
        "    \"url\": null, \n",
        "    \"utc_offset\": 7200, \n",
        "    \"verified\": false\n",
        "  }\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dateutil.parser import parse\n",
      "class Tweet(dict):\n",
      "    def __init__(self, raw_tweet):\n",
      "        super(Tweet, self).__init__(self)\n",
      "        if raw_tweet and 'delete' not in raw_tweet:\n",
      "            self['timestamp'] = parse(raw_tweet[u'created_at']\n",
      "                                ).replace(tzinfo=None).isoformat()\n",
      "            self['text'] = raw_tweet['text']\n",
      "            self['hashtags'] = [x['text'] for x in raw_tweet['entities']['hashtags']]\n",
      "            self['geo'] = raw_tweet['geo']['coordinates'] if raw_tweet['geo'] else None\n",
      "            self['id'] = raw_tweet['id']\n",
      "            self['screen_name'] = raw_tweet['user']['screen_name']\n",
      "            self['user_id'] = raw_tweet['user']['id'] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T = None\n",
      "while not T:\n",
      "    T = Tweet(stream.next())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "{'geo': None,\n",
        " 'hashtags': [],\n",
        " 'id': 506499134686507009,\n",
        " 'screen_name': u'sadkidcIifford',\n",
        " 'text': u'@Irwinisapizza IS DOING FOLLOW TRICKS! \\U0001f338\\U0001f338 \\nSTALK TO GAIN\\n(im so close to 3k please!) \\nx128',\n",
        " 'timestamp': '2014-09-01T17:49:38',\n",
        " 'user_id': 2298299736}"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "from nltk import wordpunct_tokenize\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopword_sets = dict([(lang, set(stopwords.words(lang))) for lang in stopwords._fileids])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_likely_language(input_text):\n",
      "    input_text = input_text.lower()\n",
      "    input_words = wordpunct_tokenize(input_text)\n",
      "    \n",
      "    likely_language = 'unknown'\n",
      "    likely_language_matches = 0\n",
      "    total_matches = 0\n",
      "    stopword_sets = dict([(lang, set(stopwords.words(lang))) for lang in stopwords._fileids])\n",
      "    \n",
      "    for language in np.random.permutation(stopwords._fileids):\n",
      "        language_matches = len(set(input_words) & stopword_sets[language])\n",
      "        total_matches += language_matches\n",
      "        if language_matches > likely_language_matches:\n",
      "            likely_language_matches = language_matches\n",
      "            likely_language = language\n",
      "            \n",
      "    return (likely_language, likely_language_matches, total_matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hold_obj = []\n",
      "for i in range(5):\n",
      "    T = Tweet(stream.next())\n",
      "    if T:\n",
      "        T['language'] = get_likely_language(T['text'])[0]\n",
      "        print \"%s, %i, %i: %s\" % (get_likely_language(T['text']) + (T['text'],))\n",
      "        hold_obj.append(T['text'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "english, 1, 1: @MiaTGrey_EU your welcome sweetie xx\n",
        "english, 7, 15: @loebie26 my allegiance was so evident last year I even pitched up to the match.\n",
        "finnish, 1, 7: Somebody Make Me Dey #MCM\n",
        "spanish, 1, 3: Que buen temaaaaaaa\n",
        "english, 2, 2: @DavonLTF what time the gym open ?\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "u'@DavonLTF what time the gym open ?'"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = sc.parallelize(hold_obj)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.collect()\n",
      "f.takeSample(False,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "[u'Somebody Make Me Dey #MCM', u'@DavonLTF what time the gym open ?']"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.flatMap(lambda word: word.split(\" \")).filter(lambda word: word.startswith('#')).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "[u'#MCM']"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = f.filter(lambda line: line.startswith('@'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.takeSample(False, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 198,
       "text": [
        "[u'@loebie26 my allegiance was so evident last year I even pitched up to the match.']"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def letter(x):\n",
      "    return x.split(' ')\n",
      "def check_lang(x):\n",
      "    input_words = wordpunct_tokenize(x.lower())\n",
      "    likely_language = 'unknown'\n",
      "    likely_language_matches = 0\n",
      "    stopword_sets = dict([(lang, set(stopwords.words(lang))) for lang in stopwords._fileids])\n",
      "    for language in np.random.permutation(stopwords._fileids):\n",
      "        language_matches = len(set(input_words) & stopword_sets[language])\n",
      "        if language_matches > likely_language_matches:\n",
      "            likely_language_matches = language_matches\n",
      "            likely_language = language        \n",
      "    return likely_language, x\n",
      "\n",
      "# reduces to each word and flattens to 1 list that returns a response per word\n",
      "# results.flatMap(letter).map(lambda word: check_lang(word)).collect()\n",
      "results.map(lambda word: check_lang(word)).min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 236,
       "text": [
        "('english', u'@DavonLTF what time the gym open ?')"
       ]
      }
     ],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = f.map(lambda s: (s,1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "(u'@MiaTGrey_EU your welcome sweetie xx', 1)"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.flatMap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "[u'@MiaTGrey_EU your welcome sweetie xx',\n",
        " u'@loebie26 my allegiance was so evident last year I even pitched up to the match.',\n",
        " u'Somebody Make Me Dey #MCM',\n",
        " u'Que buen temaaaaaaa',\n",
        " u'@DavonLTF what time the gym open ?']"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(pyspark)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on package pyspark:\n",
        "\n",
        "NAME\n",
        "    pyspark - PySpark is the Python API for Spark.\n",
        "\n",
        "FILE\n",
        "    /Users/willow/Downloads/spark-1.0.0/python/pyspark/__init__.py\n",
        "\n",
        "DESCRIPTION\n",
        "    Public classes:\n",
        "    \n",
        "      - L{SparkContext<pyspark.context.SparkContext>}\n",
        "          Main entry point for Spark functionality.\n",
        "      - L{RDD<pyspark.rdd.RDD>}\n",
        "          A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
        "      - L{Broadcast<pyspark.broadcast.Broadcast>}\n",
        "          A broadcast variable that gets reused across tasks.\n",
        "      - L{Accumulator<pyspark.accumulators.Accumulator>}\n",
        "          An \"add-only\" shared variable that tasks can only add values to.\n",
        "      - L{SparkConf<pyspark.conf.SparkConf>}\n",
        "          For configuring Spark.\n",
        "      - L{SparkFiles<pyspark.files.SparkFiles>}\n",
        "          Access files shipped with jobs.\n",
        "      - L{StorageLevel<pyspark.storagelevel.StorageLevel>}\n",
        "          Finer-grained cache persistence levels.\n",
        "    \n",
        "    Spark SQL:\n",
        "      - L{SQLContext<pyspark.sql.SQLContext>}\n",
        "          Main entry point for SQL functionality.\n",
        "      - L{SchemaRDD<pyspark.sql.SchemaRDD>}\n",
        "          A Resilient Distributed Dataset (RDD) with Schema information for the data contained. In\n",
        "          addition to normal RDD operations, SchemaRDDs also support SQL.\n",
        "      - L{Row<pyspark.sql.Row>}\n",
        "          A Row of data returned by a Spark SQL query.\n",
        "    \n",
        "    Hive:\n",
        "      - L{HiveContext<pyspark.context.HiveContext>}\n",
        "          Main entry point for accessing data stored in Apache Hive..\n",
        "\n",
        "PACKAGE CONTENTS\n",
        "    accumulators\n",
        "    broadcast\n",
        "    cloudpickle\n",
        "    conf\n",
        "    context\n",
        "    daemon\n",
        "    files\n",
        "    java_gateway\n",
        "    join\n",
        "    mllib (package)\n",
        "    rdd\n",
        "    rddsampler\n",
        "    resultiterable\n",
        "    serializers\n",
        "    shell\n",
        "    sql\n",
        "    statcounter\n",
        "    storagelevel\n",
        "    tests\n",
        "    worker\n",
        "\n",
        "CLASSES\n",
        "    __builtin__.dict(__builtin__.object)\n",
        "        pyspark.sql.Row\n",
        "    __builtin__.object\n",
        "        pyspark.conf.SparkConf\n",
        "        pyspark.context.SparkContext\n",
        "        pyspark.files.SparkFiles\n",
        "        pyspark.rdd.RDD\n",
        "            pyspark.sql.SchemaRDD\n",
        "    pyspark.sql.SQLContext\n",
        "    pyspark.storagelevel.StorageLevel\n",
        "    \n",
        "    class RDD(__builtin__.object)\n",
        "     |  A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
        "     |  Represents an immutable, partitioned collection of elements that can be\n",
        "     |  operated on in parallel.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __add__(self, other)\n",
        "     |      Return the union of this RDD and another one.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 1, 2, 3])\n",
        "     |      >>> (rdd + rdd).collect()\n",
        "     |      [1, 1, 2, 3, 1, 1, 2, 3]\n",
        "     |  \n",
        "     |  __init__(self, jrdd, ctx, jrdd_deserializer)\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  aggregate(self, zeroValue, seqOp, combOp)\n",
        "     |      Aggregate the elements of each partition, and then the results for all\n",
        "     |      the partitions, using a given combine functions and a neutral \"zero\n",
        "     |      value.\"\n",
        "     |      \n",
        "     |      The functions C{op(t1, t2)} is allowed to modify C{t1} and return it\n",
        "     |      as its result value to avoid object allocation; however, it should not\n",
        "     |      modify C{t2}.\n",
        "     |      \n",
        "     |      The first function (seqOp) can return a different result type, U, than\n",
        "     |      the type of this RDD. Thus, we need one operation for merging a T into an U\n",
        "     |      and one operation for merging two U\n",
        "     |      \n",
        "     |      >>> seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
        "     |      >>> combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4]).aggregate((0, 0), seqOp, combOp)\n",
        "     |      (10, 4)\n",
        "     |      >>> sc.parallelize([]).aggregate((0, 0), seqOp, combOp)\n",
        "     |      (0, 0)\n",
        "     |  \n",
        "     |  cache(self)\n",
        "     |      Persist this RDD with the default storage level (C{MEMORY_ONLY}).\n",
        "     |  \n",
        "     |  cartesian(self, other)\n",
        "     |      Return the Cartesian product of this RDD and another one, that is, the\n",
        "     |      RDD of all pairs of elements C{(a, b)} where C{a} is in C{self} and\n",
        "     |      C{b} is in C{other}.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2])\n",
        "     |      >>> sorted(rdd.cartesian(rdd).collect())\n",
        "     |      [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
        "     |  \n",
        "     |  checkpoint(self)\n",
        "     |      Mark this RDD for checkpointing. It will be saved to a file inside the\n",
        "     |      checkpoint directory set with L{SparkContext.setCheckpointDir()} and\n",
        "     |      all references to its parent RDDs will be removed. This function must\n",
        "     |      be called before any job has been executed on this RDD. It is strongly\n",
        "     |      recommended that this RDD is persisted in memory, otherwise saving it\n",
        "     |      on a file will require recomputation.\n",
        "     |  \n",
        "     |  coalesce(self, numPartitions, shuffle=False)\n",
        "     |      Return a new RDD that is reduced into `numPartitions` partitions.\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5], 3).glom().collect()\n",
        "     |      [[1], [2, 3], [4, 5]]\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5], 3).coalesce(1).glom().collect()\n",
        "     |      [[1, 2, 3, 4, 5]]\n",
        "     |  \n",
        "     |  cogroup(self, other, numPartitions=None)\n",
        "     |      For each key k in C{self} or C{other}, return a resulting RDD that\n",
        "     |      contains a tuple with the list of values for that key in C{self} as well\n",
        "     |      as C{other}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2)])\n",
        "     |      >>> map((lambda (x,y): (x, (list(y[0]), list(y[1])))), sorted(list(x.cogroup(y).collect())))\n",
        "     |      [('a', ([1], [2])), ('b', ([4], []))]\n",
        "     |  \n",
        "     |  collect(self)\n",
        "     |      Return a list that contains all of the elements in this RDD.\n",
        "     |  \n",
        "     |  collectAsMap(self)\n",
        "     |      Return the key-value pairs in this RDD to the master as a dictionary.\n",
        "     |      \n",
        "     |      >>> m = sc.parallelize([(1, 2), (3, 4)]).collectAsMap()\n",
        "     |      >>> m[1]\n",
        "     |      2\n",
        "     |      >>> m[3]\n",
        "     |      4\n",
        "     |  \n",
        "     |  combineByKey(self, createCombiner, mergeValue, mergeCombiners, numPartitions=None)\n",
        "     |      Generic function to combine the elements for each key using a custom\n",
        "     |      set of aggregation functions.\n",
        "     |      \n",
        "     |      Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a \"combined\n",
        "     |      type\" C.  Note that V and C can be different -- for example, one might\n",
        "     |      group an RDD of type (Int, Int) into an RDD of type (Int, List[Int]).\n",
        "     |      \n",
        "     |      Users provide three functions:\n",
        "     |      \n",
        "     |          - C{createCombiner}, which turns a V into a C (e.g., creates\n",
        "     |            a one-element list)\n",
        "     |          - C{mergeValue}, to merge a V into a C (e.g., adds it to the end of\n",
        "     |            a list)\n",
        "     |          - C{mergeCombiners}, to combine two C's into a single one.\n",
        "     |      \n",
        "     |      In addition, users can control the partitioning of the output RDD.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> def f(x): return x\n",
        "     |      >>> def add(a, b): return a + str(b)\n",
        "     |      >>> sorted(x.combineByKey(str, add, add).collect())\n",
        "     |      [('a', '11'), ('b', '1')]\n",
        "     |  \n",
        "     |  count(self)\n",
        "     |      Return the number of elements in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([2, 3, 4]).count()\n",
        "     |      3\n",
        "     |  \n",
        "     |  countByKey(self)\n",
        "     |      Count the number of elements for each key, and return the result to the\n",
        "     |      master as a dictionary.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> sorted(rdd.countByKey().items())\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  countByValue(self)\n",
        "     |      Return the count of each unique value in this RDD as a dictionary of\n",
        "     |      (value, count) pairs.\n",
        "     |      \n",
        "     |      >>> sorted(sc.parallelize([1, 2, 1, 2, 2], 2).countByValue().items())\n",
        "     |      [(1, 2), (2, 3)]\n",
        "     |  \n",
        "     |  distinct(self)\n",
        "     |      Return a new RDD containing the distinct elements in this RDD.\n",
        "     |      \n",
        "     |      >>> sorted(sc.parallelize([1, 1, 2, 3]).distinct().collect())\n",
        "     |      [1, 2, 3]\n",
        "     |  \n",
        "     |  filter(self, f)\n",
        "     |      Return a new RDD containing only the elements that satisfy a predicate.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "     |      >>> rdd.filter(lambda x: x % 2 == 0).collect()\n",
        "     |      [2, 4]\n",
        "     |  \n",
        "     |  first(self)\n",
        "     |      Return the first element in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([2, 3, 4]).first()\n",
        "     |      2\n",
        "     |  \n",
        "     |  flatMap(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by first applying a function to all elements of this\n",
        "     |      RDD, and then flattening the results.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([2, 3, 4])\n",
        "     |      >>> sorted(rdd.flatMap(lambda x: range(1, x)).collect())\n",
        "     |      [1, 1, 1, 2, 2, 3]\n",
        "     |      >>> sorted(rdd.flatMap(lambda x: [(x, x), (x, x)]).collect())\n",
        "     |      [(2, 2), (2, 2), (3, 3), (3, 3), (4, 4), (4, 4)]\n",
        "     |  \n",
        "     |  flatMapValues(self, f)\n",
        "     |      Pass each value in the key-value pair RDD through a flatMap function\n",
        "     |      without changing the keys; this also retains the original RDD's\n",
        "     |      partitioning.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", [\"x\", \"y\", \"z\"]), (\"b\", [\"p\", \"r\"])])\n",
        "     |      >>> def f(x): return x\n",
        "     |      >>> x.flatMapValues(f).collect()\n",
        "     |      [('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n",
        "     |  \n",
        "     |  fold(self, zeroValue, op)\n",
        "     |      Aggregate the elements of each partition, and then the results for all\n",
        "     |      the partitions, using a given associative function and a neutral \"zero\n",
        "     |      value.\"\n",
        "     |      \n",
        "     |      The function C{op(t1, t2)} is allowed to modify C{t1} and return it\n",
        "     |      as its result value to avoid object allocation; however, it should not\n",
        "     |      modify C{t2}.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).fold(0, add)\n",
        "     |      15\n",
        "     |  \n",
        "     |  foldByKey(self, zeroValue, func, numPartitions=None)\n",
        "     |      Merge the values for each key using an associative function \"func\" and a neutral \"zeroValue\"\n",
        "     |      which may be added to the result an arbitrary number of times, and must not change \n",
        "     |      the result (e.g., 0 for addition, or 1 for multiplication.).                \n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> from operator import add\n",
        "     |      >>> rdd.foldByKey(0, add).collect()\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  foreach(self, f)\n",
        "     |      Applies a function to all elements of this RDD.\n",
        "     |      \n",
        "     |      >>> def f(x): print x\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).foreach(f)\n",
        "     |  \n",
        "     |  foreachPartition(self, f)\n",
        "     |      Applies a function to each partition of this RDD.\n",
        "     |      \n",
        "     |      >>> def f(iterator): \n",
        "     |      ...      for x in iterator: \n",
        "     |      ...           print x \n",
        "     |      ...      yield None\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).foreachPartition(f)\n",
        "     |  \n",
        "     |  getCheckpointFile(self)\n",
        "     |      Gets the name of the file to which this RDD was checkpointed\n",
        "     |  \n",
        "     |  getStorageLevel(self)\n",
        "     |      Get the RDD's current storage level.\n",
        "     |      >>> rdd1 = sc.parallelize([1,2])\n",
        "     |      >>> rdd1.getStorageLevel()\n",
        "     |      StorageLevel(False, False, False, False, 1)\n",
        "     |  \n",
        "     |  glom(self)\n",
        "     |      Return an RDD created by coalescing all elements within each partition\n",
        "     |      into a list.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
        "     |      >>> sorted(rdd.glom().collect())\n",
        "     |      [[1, 2], [3, 4]]\n",
        "     |  \n",
        "     |  groupBy(self, f, numPartitions=None)\n",
        "     |      Return an RDD of grouped items.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 1, 2, 3, 5, 8])\n",
        "     |      >>> result = rdd.groupBy(lambda x: x % 2).collect()\n",
        "     |      >>> sorted([(x, sorted(y)) for (x, y) in result])\n",
        "     |      [(0, [2, 8]), (1, [1, 1, 3, 5])]\n",
        "     |  \n",
        "     |  groupByKey(self, numPartitions=None)\n",
        "     |      Group the values for each key in the RDD into a single sequence.\n",
        "     |      Hash-partitions the resulting RDD with into numPartitions partitions.\n",
        "     |      \n",
        "     |      Note: If you are grouping in order to perform an aggregation (such as a\n",
        "     |      sum or average) over each key, using reduceByKey will provide much better\n",
        "     |      performance.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> map((lambda (x,y): (x, list(y))), sorted(x.groupByKey().collect()))\n",
        "     |      [('a', [1, 1]), ('b', [1])]\n",
        "     |  \n",
        "     |  groupWith(self, other)\n",
        "     |      Alias for cogroup.\n",
        "     |  \n",
        "     |  id(self)\n",
        "     |      A unique ID for this RDD (within its SparkContext).\n",
        "     |  \n",
        "     |  intersection(self, other)\n",
        "     |      Return the intersection of this RDD and another one. The output will not \n",
        "     |      contain any duplicate elements, even if the input RDDs did.\n",
        "     |      \n",
        "     |      Note that this method performs a shuffle internally.\n",
        "     |      \n",
        "     |      >>> rdd1 = sc.parallelize([1, 10, 2, 3, 4, 5])\n",
        "     |      >>> rdd2 = sc.parallelize([1, 6, 2, 3, 7, 8])\n",
        "     |      >>> rdd1.intersection(rdd2).collect()\n",
        "     |      [1, 2, 3]\n",
        "     |  \n",
        "     |  isCheckpointed(self)\n",
        "     |      Return whether this RDD has been checkpointed or not\n",
        "     |  \n",
        "     |  join(self, other, numPartitions=None)\n",
        "     |      Return an RDD containing all pairs of elements with matching keys in\n",
        "     |      C{self} and C{other}.\n",
        "     |      \n",
        "     |      Each pair of elements will be returned as a (k, (v1, v2)) tuple, where\n",
        "     |      (k, v1) is in C{self} and (k, v2) is in C{other}.\n",
        "     |      \n",
        "     |      Performs a hash join across the cluster.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2), (\"a\", 3)])\n",
        "     |      >>> sorted(x.join(y).collect())\n",
        "     |      [('a', (1, 2)), ('a', (1, 3))]\n",
        "     |  \n",
        "     |  keyBy(self, f)\n",
        "     |      Creates tuples of the elements in this RDD by applying C{f}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize(range(0,3)).keyBy(lambda x: x*x)\n",
        "     |      >>> y = sc.parallelize(zip(range(0,5), range(0,5)))\n",
        "     |      >>> map((lambda (x,y): (x, (list(y[0]), (list(y[1]))))), sorted(x.cogroup(y).collect()))\n",
        "     |      [(0, ([0], [0])), (1, ([1], [1])), (2, ([], [2])), (3, ([], [3])), (4, ([2], [4]))]\n",
        "     |  \n",
        "     |  keys(self)\n",
        "     |      Return an RDD with the keys of each tuple.\n",
        "     |      >>> m = sc.parallelize([(1, 2), (3, 4)]).keys()\n",
        "     |      >>> m.collect()\n",
        "     |      [1, 3]\n",
        "     |  \n",
        "     |  leftOuterJoin(self, other, numPartitions=None)\n",
        "     |      Perform a left outer join of C{self} and C{other}.\n",
        "     |      \n",
        "     |      For each element (k, v) in C{self}, the resulting RDD will either\n",
        "     |      contain all pairs (k, (v, w)) for w in C{other}, or the pair\n",
        "     |      (k, (v, None)) if no elements in other have key k.\n",
        "     |      \n",
        "     |      Hash-partitions the resulting RDD into the given number of partitions.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2)])\n",
        "     |      >>> sorted(x.leftOuterJoin(y).collect())\n",
        "     |      [('a', (1, 2)), ('b', (4, None))]\n",
        "     |  \n",
        "     |  map(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by applying a function to each element of this RDD.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n",
        "     |      >>> sorted(rdd.map(lambda x: (x, 1)).collect())\n",
        "     |      [('a', 1), ('b', 1), ('c', 1)]\n",
        "     |  \n",
        "     |  mapPartitions(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by applying a function to each partition of this RDD.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
        "     |      >>> def f(iterator): yield sum(iterator)\n",
        "     |      >>> rdd.mapPartitions(f).collect()\n",
        "     |      [3, 7]\n",
        "     |  \n",
        "     |  mapPartitionsWithIndex(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by applying a function to each partition of this RDD,\n",
        "     |      while tracking the index of the original partition.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
        "     |      >>> def f(splitIndex, iterator): yield splitIndex\n",
        "     |      >>> rdd.mapPartitionsWithIndex(f).sum()\n",
        "     |      6\n",
        "     |  \n",
        "     |  mapPartitionsWithSplit(self, f, preservesPartitioning=False)\n",
        "     |      Deprecated: use mapPartitionsWithIndex instead.\n",
        "     |      \n",
        "     |      Return a new RDD by applying a function to each partition of this RDD,\n",
        "     |      while tracking the index of the original partition.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
        "     |      >>> def f(splitIndex, iterator): yield splitIndex\n",
        "     |      >>> rdd.mapPartitionsWithSplit(f).sum()\n",
        "     |      6\n",
        "     |  \n",
        "     |  mapValues(self, f)\n",
        "     |      Pass each value in the key-value pair RDD through a map function\n",
        "     |      without changing the keys; this also retains the original RDD's\n",
        "     |      partitioning.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", [\"apple\", \"banana\", \"lemon\"]), (\"b\", [\"grapes\"])])\n",
        "     |      >>> def f(x): return len(x)\n",
        "     |      >>> x.mapValues(f).collect()\n",
        "     |      [('a', 3), ('b', 1)]\n",
        "     |  \n",
        "     |  max(self)\n",
        "     |      Find the maximum item in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1.0, 5.0, 43.0, 10.0]).max()\n",
        "     |      43.0\n",
        "     |  \n",
        "     |  mean(self)\n",
        "     |      Compute the mean of this RDD's elements.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).mean()\n",
        "     |      2.0\n",
        "     |  \n",
        "     |  min(self)\n",
        "     |      Find the maximum item in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1.0, 5.0, 43.0, 10.0]).min()\n",
        "     |      1.0\n",
        "     |  \n",
        "     |  name(self)\n",
        "     |      Return the name of this RDD.\n",
        "     |  \n",
        "     |  partitionBy(self, numPartitions, partitionFunc=<built-in function hash>)\n",
        "     |      Return a copy of the RDD partitioned using the specified partitioner.\n",
        "     |      \n",
        "     |      >>> pairs = sc.parallelize([1, 2, 3, 4, 2, 4, 1]).map(lambda x: (x, x))\n",
        "     |      >>> sets = pairs.partitionBy(2).glom().collect()\n",
        "     |      >>> set(sets[0]).intersection(set(sets[1]))\n",
        "     |      set([])\n",
        "     |  \n",
        "     |  persist(self, storageLevel)\n",
        "     |      Set this RDD's storage level to persist its values across operations after the first time\n",
        "     |      it is computed. This can only be used to assign a new storage level if the RDD does not\n",
        "     |      have a storage level set yet.\n",
        "     |  \n",
        "     |  pipe(self, command, env={})\n",
        "     |      Return an RDD created by piping elements to a forked external process.\n",
        "     |      \n",
        "     |      >>> sc.parallelize(['1', '2', '', '3']).pipe('cat').collect()\n",
        "     |      ['1', '2', '', '3']\n",
        "     |  \n",
        "     |  reduce(self, f)\n",
        "     |      Reduces the elements of this RDD using the specified commutative and\n",
        "     |      associative binary operator. Currently reduces partitions locally.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).reduce(add)\n",
        "     |      15\n",
        "     |      >>> sc.parallelize((2 for _ in range(10))).map(lambda x: 1).cache().reduce(add)\n",
        "     |      10\n",
        "     |  \n",
        "     |  reduceByKey(self, func, numPartitions=None)\n",
        "     |      Merge the values for each key using an associative reduce function.\n",
        "     |      \n",
        "     |      This will also perform the merging locally on each mapper before\n",
        "     |      sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
        "     |      \n",
        "     |      Output will be hash-partitioned with C{numPartitions} partitions, or\n",
        "     |      the default parallelism level if C{numPartitions} is not specified.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> sorted(rdd.reduceByKey(add).collect())\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  reduceByKeyLocally(self, func)\n",
        "     |      Merge the values for each key using an associative reduce function, but\n",
        "     |      return the results immediately to the master as a dictionary.\n",
        "     |      \n",
        "     |      This will also perform the merging locally on each mapper before\n",
        "     |      sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> sorted(rdd.reduceByKeyLocally(add).items())\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  repartition(self, numPartitions)\n",
        "     |      Return a new RDD that has exactly numPartitions partitions.\n",
        "     |       \n",
        "     |      Can increase or decrease the level of parallelism in this RDD. Internally, this uses\n",
        "     |      a shuffle to redistribute data.\n",
        "     |      If you are decreasing the number of partitions in this RDD, consider using `coalesce`,\n",
        "     |      which can avoid performing a shuffle.\n",
        "     |      >>> rdd = sc.parallelize([1,2,3,4,5,6,7], 4)\n",
        "     |      >>> sorted(rdd.glom().collect())\n",
        "     |      [[1], [2, 3], [4, 5], [6, 7]]\n",
        "     |      >>> len(rdd.repartition(2).glom().collect())\n",
        "     |      2\n",
        "     |      >>> len(rdd.repartition(10).glom().collect())\n",
        "     |      10\n",
        "     |  \n",
        "     |  rightOuterJoin(self, other, numPartitions=None)\n",
        "     |      Perform a right outer join of C{self} and C{other}.\n",
        "     |      \n",
        "     |      For each element (k, w) in C{other}, the resulting RDD will either\n",
        "     |      contain all pairs (k, (v, w)) for v in this, or the pair (k, (None, w))\n",
        "     |      if no elements in C{self} have key k.\n",
        "     |      \n",
        "     |      Hash-partitions the resulting RDD into the given number of partitions.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2)])\n",
        "     |      >>> sorted(y.rightOuterJoin(x).collect())\n",
        "     |      [('a', (2, 1)), ('b', (None, 4))]\n",
        "     |  \n",
        "     |  sample(self, withReplacement, fraction, seed=None)\n",
        "     |      Return a sampled subset of this RDD (relies on numpy and falls back\n",
        "     |      on default random generator if numpy is unavailable).\n",
        "     |      \n",
        "     |      >>> sc.parallelize(range(0, 100)).sample(False, 0.1, 2).collect() #doctest: +SKIP\n",
        "     |      [2, 3, 20, 21, 24, 41, 42, 66, 67, 89, 90, 98]\n",
        "     |  \n",
        "     |  sampleStdev(self)\n",
        "     |      Compute the sample standard deviation of this RDD's elements (which corrects for bias in\n",
        "     |      estimating the standard deviation by dividing by N-1 instead of N).\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).sampleStdev()\n",
        "     |      1.0\n",
        "     |  \n",
        "     |  sampleVariance(self)\n",
        "     |      Compute the sample variance of this RDD's elements (which corrects for bias in\n",
        "     |      estimating the variance by dividing by N-1 instead of N).\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).sampleVariance()\n",
        "     |      1.0\n",
        "     |  \n",
        "     |  saveAsTextFile(self, path)\n",
        "     |      Save this RDD as a text file, using string representations of elements.\n",
        "     |      \n",
        "     |      >>> tempFile = NamedTemporaryFile(delete=True)\n",
        "     |      >>> tempFile.close()\n",
        "     |      >>> sc.parallelize(range(10)).saveAsTextFile(tempFile.name)\n",
        "     |      >>> from fileinput import input\n",
        "     |      >>> from glob import glob\n",
        "     |      >>> ''.join(sorted(input(glob(tempFile.name + \"/part-0000*\"))))\n",
        "     |      '0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'\n",
        "     |      \n",
        "     |      Empty lines are tolerated when saving to text files.\n",
        "     |      \n",
        "     |      >>> tempFile2 = NamedTemporaryFile(delete=True)\n",
        "     |      >>> tempFile2.close()\n",
        "     |      >>> sc.parallelize(['', 'foo', '', 'bar', '']).saveAsTextFile(tempFile2.name)\n",
        "     |      >>> ''.join(sorted(input(glob(tempFile2.name + \"/part-0000*\"))))\n",
        "     |      '\\n\\n\\nbar\\nfoo\\n'\n",
        "     |  \n",
        "     |  setName(self, name)\n",
        "     |      Assign a name to this RDD.\n",
        "     |      >>> rdd1 = sc.parallelize([1,2])\n",
        "     |      >>> rdd1.setName('RDD1')\n",
        "     |      >>> rdd1.name()\n",
        "     |      'RDD1'\n",
        "     |  \n",
        "     |  sortByKey(self, ascending=True, numPartitions=None, keyfunc=<function <lambda>>)\n",
        "     |      Sorts this RDD, which is assumed to consist of (key, value) pairs.\n",
        "     |      \n",
        "     |      >>> tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
        "     |      >>> sc.parallelize(tmp).sortByKey(True, 2).collect()\n",
        "     |      [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n",
        "     |      >>> tmp2 = [('Mary', 1), ('had', 2), ('a', 3), ('little', 4), ('lamb', 5)]\n",
        "     |      >>> tmp2.extend([('whose', 6), ('fleece', 7), ('was', 8), ('white', 9)])\n",
        "     |      >>> sc.parallelize(tmp2).sortByKey(True, 3, keyfunc=lambda k: k.lower()).collect()\n",
        "     |      [('a', 3), ('fleece', 7), ('had', 2), ('lamb', 5), ('little', 4), ('Mary', 1), ('was', 8), ('white', 9), ('whose', 6)]\n",
        "     |  \n",
        "     |  stats(self)\n",
        "     |      Return a L{StatCounter} object that captures the mean, variance\n",
        "     |      and count of the RDD's elements in one operation.\n",
        "     |  \n",
        "     |  stdev(self)\n",
        "     |      Compute the standard deviation of this RDD's elements.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).stdev()\n",
        "     |      0.816...\n",
        "     |  \n",
        "     |  subtract(self, other, numPartitions=None)\n",
        "     |      Return each value in C{self} that is not contained in C{other}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 3)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
        "     |      >>> sorted(x.subtract(y).collect())\n",
        "     |      [('a', 1), ('b', 4), ('b', 5)]\n",
        "     |  \n",
        "     |  subtractByKey(self, other, numPartitions=None)\n",
        "     |      Return each (key, value) pair in C{self} that has no pair with matching key\n",
        "     |      in C{other}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 2)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
        "     |      >>> sorted(x.subtractByKey(y).collect())\n",
        "     |      [('b', 4), ('b', 5)]\n",
        "     |  \n",
        "     |  sum(self)\n",
        "     |      Add up the elements in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1.0, 2.0, 3.0]).sum()\n",
        "     |      6.0\n",
        "     |  \n",
        "     |  take(self, num)\n",
        "     |      Take the first num elements of the RDD.\n",
        "     |      \n",
        "     |      This currently scans the partitions *one by one*, so it will be slow if\n",
        "     |      a lot of partitions are required. In that case, use L{collect} to get\n",
        "     |      the whole RDD instead.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)\n",
        "     |      [2, 3]\n",
        "     |      >>> sc.parallelize([2, 3, 4, 5, 6]).take(10)\n",
        "     |      [2, 3, 4, 5, 6]\n",
        "     |  \n",
        "     |  takeOrdered(self, num, key=None)\n",
        "     |      Get the N elements from a RDD ordered in ascending order or as specified\n",
        "     |      by the optional key function. \n",
        "     |      \n",
        "     |      >>> sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7]).takeOrdered(6)\n",
        "     |      [1, 2, 3, 4, 5, 6]\n",
        "     |      >>> sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7], 2).takeOrdered(6, key=lambda x: -x)\n",
        "     |      [10, 9, 7, 6, 5, 4]\n",
        "     |  \n",
        "     |  takeSample(self, withReplacement, num, seed=None)\n",
        "     |      Return a fixed-size sampled subset of this RDD (currently requires numpy).\n",
        "     |      \n",
        "     |      >>> sc.parallelize(range(0, 10)).takeSample(True, 10, 1) #doctest: +SKIP\n",
        "     |      [4, 2, 1, 8, 2, 7, 0, 4, 1, 4]\n",
        "     |  \n",
        "     |  toDebugString(self)\n",
        "     |      A description of this RDD and its recursive dependencies for debugging.\n",
        "     |  \n",
        "     |  top(self, num)\n",
        "     |      Get the top N elements from a RDD.\n",
        "     |      \n",
        "     |      Note: It returns the list sorted in descending order.\n",
        "     |      >>> sc.parallelize([10, 4, 2, 12, 3]).top(1)\n",
        "     |      [12]\n",
        "     |      >>> sc.parallelize([2, 3, 4, 5, 6], 2).cache().top(2)\n",
        "     |      [6, 5]\n",
        "     |  \n",
        "     |  union(self, other)\n",
        "     |      Return the union of this RDD and another one.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 1, 2, 3])\n",
        "     |      >>> rdd.union(rdd).collect()\n",
        "     |      [1, 1, 2, 3, 1, 1, 2, 3]\n",
        "     |  \n",
        "     |  unpersist(self)\n",
        "     |      Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.\n",
        "     |  \n",
        "     |  values(self)\n",
        "     |      Return an RDD with the values of each tuple.\n",
        "     |      >>> m = sc.parallelize([(1, 2), (3, 4)]).values()\n",
        "     |      >>> m.collect()\n",
        "     |      [2, 4]\n",
        "     |  \n",
        "     |  variance(self)\n",
        "     |      Compute the variance of this RDD's elements.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).variance()\n",
        "     |      0.666...\n",
        "     |  \n",
        "     |  zip(self, other)\n",
        "     |      Zips this RDD with another one, returning key-value pairs with the first element in each RDD\n",
        "     |      second element in each RDD, etc. Assumes that the two RDDs have the same number of\n",
        "     |      partitions and the same number of elements in each partition (e.g. one was made through\n",
        "     |      a map on the other).\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize(range(0,5))\n",
        "     |      >>> y = sc.parallelize(range(1000, 1005))\n",
        "     |      >>> x.zip(y).collect()\n",
        "     |      [(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  context\n",
        "     |      The L{SparkContext} that this RDD was created on.\n",
        "    \n",
        "    class Row(__builtin__.dict)\n",
        "     |  A row in L{SchemaRDD}.\n",
        "     |  \n",
        "     |  An extended L{dict} that takes a L{dict} in its constructor, and\n",
        "     |  exposes those items as fields.\n",
        "     |  \n",
        "     |  >>> r = Row({\"hello\" : \"world\", \"foo\" : \"bar\"})\n",
        "     |  >>> r.hello\n",
        "     |  'world'\n",
        "     |  >>> r.foo\n",
        "     |  'bar'\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      Row\n",
        "     |      __builtin__.dict\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, d)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from __builtin__.dict:\n",
        "     |  \n",
        "     |  __cmp__(...)\n",
        "     |      x.__cmp__(y) <==> cmp(x,y)\n",
        "     |  \n",
        "     |  __contains__(...)\n",
        "     |      D.__contains__(k) -> True if D has a key k, else False\n",
        "     |  \n",
        "     |  __delitem__(...)\n",
        "     |      x.__delitem__(y) <==> del x[y]\n",
        "     |  \n",
        "     |  __eq__(...)\n",
        "     |      x.__eq__(y) <==> x==y\n",
        "     |  \n",
        "     |  __ge__(...)\n",
        "     |      x.__ge__(y) <==> x>=y\n",
        "     |  \n",
        "     |  __getattribute__(...)\n",
        "     |      x.__getattribute__('name') <==> x.name\n",
        "     |  \n",
        "     |  __getitem__(...)\n",
        "     |      x.__getitem__(y) <==> x[y]\n",
        "     |  \n",
        "     |  __gt__(...)\n",
        "     |      x.__gt__(y) <==> x>y\n",
        "     |  \n",
        "     |  __iter__(...)\n",
        "     |      x.__iter__() <==> iter(x)\n",
        "     |  \n",
        "     |  __le__(...)\n",
        "     |      x.__le__(y) <==> x<=y\n",
        "     |  \n",
        "     |  __len__(...)\n",
        "     |      x.__len__() <==> len(x)\n",
        "     |  \n",
        "     |  __lt__(...)\n",
        "     |      x.__lt__(y) <==> x<y\n",
        "     |  \n",
        "     |  __ne__(...)\n",
        "     |      x.__ne__(y) <==> x!=y\n",
        "     |  \n",
        "     |  __repr__(...)\n",
        "     |      x.__repr__() <==> repr(x)\n",
        "     |  \n",
        "     |  __setitem__(...)\n",
        "     |      x.__setitem__(i, y) <==> x[i]=y\n",
        "     |  \n",
        "     |  __sizeof__(...)\n",
        "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
        "     |  \n",
        "     |  clear(...)\n",
        "     |      D.clear() -> None.  Remove all items from D.\n",
        "     |  \n",
        "     |  copy(...)\n",
        "     |      D.copy() -> a shallow copy of D\n",
        "     |  \n",
        "     |  fromkeys(...)\n",
        "     |      dict.fromkeys(S[,v]) -> New dict with keys from S and values equal to v.\n",
        "     |      v defaults to None.\n",
        "     |  \n",
        "     |  get(...)\n",
        "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
        "     |  \n",
        "     |  has_key(...)\n",
        "     |      D.has_key(k) -> True if D has a key k, else False\n",
        "     |  \n",
        "     |  items(...)\n",
        "     |      D.items() -> list of D's (key, value) pairs, as 2-tuples\n",
        "     |  \n",
        "     |  iteritems(...)\n",
        "     |      D.iteritems() -> an iterator over the (key, value) items of D\n",
        "     |  \n",
        "     |  iterkeys(...)\n",
        "     |      D.iterkeys() -> an iterator over the keys of D\n",
        "     |  \n",
        "     |  itervalues(...)\n",
        "     |      D.itervalues() -> an iterator over the values of D\n",
        "     |  \n",
        "     |  keys(...)\n",
        "     |      D.keys() -> list of D's keys\n",
        "     |  \n",
        "     |  pop(...)\n",
        "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
        "     |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
        "     |  \n",
        "     |  popitem(...)\n",
        "     |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
        "     |      2-tuple; but raise KeyError if D is empty.\n",
        "     |  \n",
        "     |  setdefault(...)\n",
        "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
        "     |  \n",
        "     |  update(...)\n",
        "     |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
        "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
        "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
        "     |      In either case, this is followed by: for k in F: D[k] = F[k]\n",
        "     |  \n",
        "     |  values(...)\n",
        "     |      D.values() -> list of D's values\n",
        "     |  \n",
        "     |  viewitems(...)\n",
        "     |      D.viewitems() -> a set-like object providing a view on D's items\n",
        "     |  \n",
        "     |  viewkeys(...)\n",
        "     |      D.viewkeys() -> a set-like object providing a view on D's keys\n",
        "     |  \n",
        "     |  viewvalues(...)\n",
        "     |      D.viewvalues() -> an object providing a view on D's values\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes inherited from __builtin__.dict:\n",
        "     |  \n",
        "     |  __hash__ = None\n",
        "     |  \n",
        "     |  __new__ = <built-in method __new__ of type object>\n",
        "     |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
        "    \n",
        "    class SQLContext\n",
        "     |  Main entry point for SparkSQL functionality.\n",
        "     |  \n",
        "     |  A SQLContext can be used create L{SchemaRDD}s, register L{SchemaRDD}s as\n",
        "     |  tables, execute SQL over tables, cache tables, and read parquet files.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, sparkContext, sqlContext=None)\n",
        "     |      Create a new SQLContext.\n",
        "     |      \n",
        "     |      @param sparkContext: The SparkContext to wrap.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> sqlCtx.inferSchema(srdd) # doctest: +IGNORE_EXCEPTION_DETAIL\n",
        "     |      Traceback (most recent call last):\n",
        "     |          ...\n",
        "     |      ValueError:...\n",
        "     |      \n",
        "     |      >>> bad_rdd = sc.parallelize([1,2,3])\n",
        "     |      >>> sqlCtx.inferSchema(bad_rdd) # doctest: +IGNORE_EXCEPTION_DETAIL\n",
        "     |      Traceback (most recent call last):\n",
        "     |          ...\n",
        "     |      ValueError:...\n",
        "     |      \n",
        "     |      >>> allTypes = sc.parallelize([{\"int\" : 1, \"string\" : \"string\", \"double\" : 1.0, \"long\": 1L,\n",
        "     |      ... \"boolean\" : True}])\n",
        "     |      >>> srdd = sqlCtx.inferSchema(allTypes).map(lambda x: (x.int, x.string, x.double, x.long,\n",
        "     |      ... x.boolean))\n",
        "     |      >>> srdd.collect()[0]\n",
        "     |      (1, u'string', 1.0, 1, True)\n",
        "     |  \n",
        "     |  cacheTable(self, tableName)\n",
        "     |      Caches the specified table in-memory.\n",
        "     |  \n",
        "     |  inferSchema(self, rdd)\n",
        "     |      Infer and apply a schema to an RDD of L{dict}s.\n",
        "     |      \n",
        "     |      We peek at the first row of the RDD to determine the fields names\n",
        "     |      and types, and then use that to extract all the dictionaries.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> srdd.collect() == [{\"field1\" : 1, \"field2\" : \"row1\"}, {\"field1\" : 2, \"field2\": \"row2\"},\n",
        "     |      ...                    {\"field1\" : 3, \"field2\": \"row3\"}]\n",
        "     |      True\n",
        "     |  \n",
        "     |  parquetFile(self, path)\n",
        "     |      Loads a Parquet file, returning the result as a L{SchemaRDD}.\n",
        "     |      \n",
        "     |      >>> import tempfile, shutil\n",
        "     |      >>> parquetFile = tempfile.mkdtemp()\n",
        "     |      >>> shutil.rmtree(parquetFile)\n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> srdd.saveAsParquetFile(parquetFile)\n",
        "     |      >>> srdd2 = sqlCtx.parquetFile(parquetFile)\n",
        "     |      >>> srdd.collect() == srdd2.collect()\n",
        "     |      True\n",
        "     |  \n",
        "     |  registerRDDAsTable(self, rdd, tableName)\n",
        "     |      Registers the given RDD as a temporary table in the catalog.\n",
        "     |      \n",
        "     |      Temporary tables exist only during the lifetime of this instance of\n",
        "     |      SQLContext.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> sqlCtx.registerRDDAsTable(srdd, \"table1\")\n",
        "     |  \n",
        "     |  sql(self, sqlQuery)\n",
        "     |      Return a L{SchemaRDD} representing the result of the given query.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> sqlCtx.registerRDDAsTable(srdd, \"table1\")\n",
        "     |      >>> srdd2 = sqlCtx.sql(\"SELECT field1 AS f1, field2 as f2 from table1\")\n",
        "     |      >>> srdd2.collect() == [{\"f1\" : 1, \"f2\" : \"row1\"}, {\"f1\" : 2, \"f2\": \"row2\"},\n",
        "     |      ...                     {\"f1\" : 3, \"f2\": \"row3\"}]\n",
        "     |      True\n",
        "     |  \n",
        "     |  table(self, tableName)\n",
        "     |      Returns the specified table as a L{SchemaRDD}.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> sqlCtx.registerRDDAsTable(srdd, \"table1\")\n",
        "     |      >>> srdd2 = sqlCtx.table(\"table1\")\n",
        "     |      >>> srdd.collect() == srdd2.collect()\n",
        "     |      True\n",
        "     |  \n",
        "     |  uncacheTable(self, tableName)\n",
        "     |      Removes the specified table from the in-memory cache.\n",
        "    \n",
        "    class SchemaRDD(pyspark.rdd.RDD)\n",
        "     |  An RDD of L{Row} objects that has an associated schema.\n",
        "     |  \n",
        "     |  The underlying JVM object is a SchemaRDD, not a PythonRDD, so we can\n",
        "     |  utilize the relational query api exposed by SparkSQL.\n",
        "     |  \n",
        "     |  For normal L{pyspark.rdd.RDD} operations (map, count, etc.) the\n",
        "     |  L{SchemaRDD} is not operated on directly, as it's underlying\n",
        "     |  implementation is a RDD composed of Java objects. Instead it is\n",
        "     |  converted to a PythonRDD in the JVM, on which Python operations can\n",
        "     |  be done.\n",
        "     |  \n",
        "     |  Method resolution order:\n",
        "     |      SchemaRDD\n",
        "     |      pyspark.rdd.RDD\n",
        "     |      __builtin__.object\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, jschema_rdd, sql_ctx)\n",
        "     |  \n",
        "     |  cache(self)\n",
        "     |      # We override the default cache/persist/checkpoint behavior as we want to cache the underlying\n",
        "     |      # SchemaRDD object in the JVM, not the PythonRDD checkpointed by the super class\n",
        "     |  \n",
        "     |  checkpoint(self)\n",
        "     |  \n",
        "     |  coalesce(self, numPartitions, shuffle=False)\n",
        "     |  \n",
        "     |  count(self)\n",
        "     |      Return the number of elements in this RDD.\n",
        "     |      \n",
        "     |      Unlike the base RDD implementation of count, this implementation\n",
        "     |      leverages the query optimizer to compute the count on the SchemaRDD,\n",
        "     |      which supports features such as filter pushdown.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> srdd.count()\n",
        "     |      3L\n",
        "     |      >>> srdd.count() == srdd.map(lambda x: x).count()\n",
        "     |      True\n",
        "     |  \n",
        "     |  distinct(self)\n",
        "     |  \n",
        "     |  getCheckpointFile(self)\n",
        "     |  \n",
        "     |  insertInto(self, tableName, overwrite=False)\n",
        "     |      Inserts the contents of this SchemaRDD into the specified table.\n",
        "     |      \n",
        "     |      Optionally overwriting any existing data.\n",
        "     |  \n",
        "     |  intersection(self, other)\n",
        "     |  \n",
        "     |  isCheckpointed(self)\n",
        "     |  \n",
        "     |  persist(self, storageLevel)\n",
        "     |  \n",
        "     |  registerAsTable(self, name)\n",
        "     |      Registers this RDD as a temporary table using the given name.\n",
        "     |      \n",
        "     |      The lifetime of this temporary table is tied to the L{SQLContext}\n",
        "     |      that was used to create this SchemaRDD.\n",
        "     |      \n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> srdd.registerAsTable(\"test\")\n",
        "     |      >>> srdd2 = sqlCtx.sql(\"select * from test\")\n",
        "     |      >>> srdd.collect() == srdd2.collect()\n",
        "     |      True\n",
        "     |  \n",
        "     |  repartition(self, numPartitions)\n",
        "     |  \n",
        "     |  saveAsParquetFile(self, path)\n",
        "     |      Save the contents as a Parquet file, preserving the schema.\n",
        "     |      \n",
        "     |      Files that are written out using this method can be read back in as\n",
        "     |      a SchemaRDD using the L{SQLContext.parquetFile} method.\n",
        "     |      \n",
        "     |      >>> import tempfile, shutil\n",
        "     |      >>> parquetFile = tempfile.mkdtemp()\n",
        "     |      >>> shutil.rmtree(parquetFile)\n",
        "     |      >>> srdd = sqlCtx.inferSchema(rdd)\n",
        "     |      >>> srdd.saveAsParquetFile(parquetFile)\n",
        "     |      >>> srdd2 = sqlCtx.parquetFile(parquetFile)\n",
        "     |      >>> srdd2.collect() == srdd.collect()\n",
        "     |      True\n",
        "     |  \n",
        "     |  saveAsTable(self, tableName)\n",
        "     |      Creates a new table with the contents of this SchemaRDD.\n",
        "     |  \n",
        "     |  subtract(self, other, numPartitions=None)\n",
        "     |  \n",
        "     |  unpersist(self)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Methods inherited from pyspark.rdd.RDD:\n",
        "     |  \n",
        "     |  __add__(self, other)\n",
        "     |      Return the union of this RDD and another one.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 1, 2, 3])\n",
        "     |      >>> (rdd + rdd).collect()\n",
        "     |      [1, 1, 2, 3, 1, 1, 2, 3]\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  aggregate(self, zeroValue, seqOp, combOp)\n",
        "     |      Aggregate the elements of each partition, and then the results for all\n",
        "     |      the partitions, using a given combine functions and a neutral \"zero\n",
        "     |      value.\"\n",
        "     |      \n",
        "     |      The functions C{op(t1, t2)} is allowed to modify C{t1} and return it\n",
        "     |      as its result value to avoid object allocation; however, it should not\n",
        "     |      modify C{t2}.\n",
        "     |      \n",
        "     |      The first function (seqOp) can return a different result type, U, than\n",
        "     |      the type of this RDD. Thus, we need one operation for merging a T into an U\n",
        "     |      and one operation for merging two U\n",
        "     |      \n",
        "     |      >>> seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
        "     |      >>> combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4]).aggregate((0, 0), seqOp, combOp)\n",
        "     |      (10, 4)\n",
        "     |      >>> sc.parallelize([]).aggregate((0, 0), seqOp, combOp)\n",
        "     |      (0, 0)\n",
        "     |  \n",
        "     |  cartesian(self, other)\n",
        "     |      Return the Cartesian product of this RDD and another one, that is, the\n",
        "     |      RDD of all pairs of elements C{(a, b)} where C{a} is in C{self} and\n",
        "     |      C{b} is in C{other}.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2])\n",
        "     |      >>> sorted(rdd.cartesian(rdd).collect())\n",
        "     |      [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
        "     |  \n",
        "     |  cogroup(self, other, numPartitions=None)\n",
        "     |      For each key k in C{self} or C{other}, return a resulting RDD that\n",
        "     |      contains a tuple with the list of values for that key in C{self} as well\n",
        "     |      as C{other}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2)])\n",
        "     |      >>> map((lambda (x,y): (x, (list(y[0]), list(y[1])))), sorted(list(x.cogroup(y).collect())))\n",
        "     |      [('a', ([1], [2])), ('b', ([4], []))]\n",
        "     |  \n",
        "     |  collect(self)\n",
        "     |      Return a list that contains all of the elements in this RDD.\n",
        "     |  \n",
        "     |  collectAsMap(self)\n",
        "     |      Return the key-value pairs in this RDD to the master as a dictionary.\n",
        "     |      \n",
        "     |      >>> m = sc.parallelize([(1, 2), (3, 4)]).collectAsMap()\n",
        "     |      >>> m[1]\n",
        "     |      2\n",
        "     |      >>> m[3]\n",
        "     |      4\n",
        "     |  \n",
        "     |  combineByKey(self, createCombiner, mergeValue, mergeCombiners, numPartitions=None)\n",
        "     |      Generic function to combine the elements for each key using a custom\n",
        "     |      set of aggregation functions.\n",
        "     |      \n",
        "     |      Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a \"combined\n",
        "     |      type\" C.  Note that V and C can be different -- for example, one might\n",
        "     |      group an RDD of type (Int, Int) into an RDD of type (Int, List[Int]).\n",
        "     |      \n",
        "     |      Users provide three functions:\n",
        "     |      \n",
        "     |          - C{createCombiner}, which turns a V into a C (e.g., creates\n",
        "     |            a one-element list)\n",
        "     |          - C{mergeValue}, to merge a V into a C (e.g., adds it to the end of\n",
        "     |            a list)\n",
        "     |          - C{mergeCombiners}, to combine two C's into a single one.\n",
        "     |      \n",
        "     |      In addition, users can control the partitioning of the output RDD.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> def f(x): return x\n",
        "     |      >>> def add(a, b): return a + str(b)\n",
        "     |      >>> sorted(x.combineByKey(str, add, add).collect())\n",
        "     |      [('a', '11'), ('b', '1')]\n",
        "     |  \n",
        "     |  countByKey(self)\n",
        "     |      Count the number of elements for each key, and return the result to the\n",
        "     |      master as a dictionary.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> sorted(rdd.countByKey().items())\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  countByValue(self)\n",
        "     |      Return the count of each unique value in this RDD as a dictionary of\n",
        "     |      (value, count) pairs.\n",
        "     |      \n",
        "     |      >>> sorted(sc.parallelize([1, 2, 1, 2, 2], 2).countByValue().items())\n",
        "     |      [(1, 2), (2, 3)]\n",
        "     |  \n",
        "     |  filter(self, f)\n",
        "     |      Return a new RDD containing only the elements that satisfy a predicate.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "     |      >>> rdd.filter(lambda x: x % 2 == 0).collect()\n",
        "     |      [2, 4]\n",
        "     |  \n",
        "     |  first(self)\n",
        "     |      Return the first element in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([2, 3, 4]).first()\n",
        "     |      2\n",
        "     |  \n",
        "     |  flatMap(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by first applying a function to all elements of this\n",
        "     |      RDD, and then flattening the results.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([2, 3, 4])\n",
        "     |      >>> sorted(rdd.flatMap(lambda x: range(1, x)).collect())\n",
        "     |      [1, 1, 1, 2, 2, 3]\n",
        "     |      >>> sorted(rdd.flatMap(lambda x: [(x, x), (x, x)]).collect())\n",
        "     |      [(2, 2), (2, 2), (3, 3), (3, 3), (4, 4), (4, 4)]\n",
        "     |  \n",
        "     |  flatMapValues(self, f)\n",
        "     |      Pass each value in the key-value pair RDD through a flatMap function\n",
        "     |      without changing the keys; this also retains the original RDD's\n",
        "     |      partitioning.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", [\"x\", \"y\", \"z\"]), (\"b\", [\"p\", \"r\"])])\n",
        "     |      >>> def f(x): return x\n",
        "     |      >>> x.flatMapValues(f).collect()\n",
        "     |      [('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n",
        "     |  \n",
        "     |  fold(self, zeroValue, op)\n",
        "     |      Aggregate the elements of each partition, and then the results for all\n",
        "     |      the partitions, using a given associative function and a neutral \"zero\n",
        "     |      value.\"\n",
        "     |      \n",
        "     |      The function C{op(t1, t2)} is allowed to modify C{t1} and return it\n",
        "     |      as its result value to avoid object allocation; however, it should not\n",
        "     |      modify C{t2}.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).fold(0, add)\n",
        "     |      15\n",
        "     |  \n",
        "     |  foldByKey(self, zeroValue, func, numPartitions=None)\n",
        "     |      Merge the values for each key using an associative function \"func\" and a neutral \"zeroValue\"\n",
        "     |      which may be added to the result an arbitrary number of times, and must not change \n",
        "     |      the result (e.g., 0 for addition, or 1 for multiplication.).                \n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> from operator import add\n",
        "     |      >>> rdd.foldByKey(0, add).collect()\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  foreach(self, f)\n",
        "     |      Applies a function to all elements of this RDD.\n",
        "     |      \n",
        "     |      >>> def f(x): print x\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).foreach(f)\n",
        "     |  \n",
        "     |  foreachPartition(self, f)\n",
        "     |      Applies a function to each partition of this RDD.\n",
        "     |      \n",
        "     |      >>> def f(iterator): \n",
        "     |      ...      for x in iterator: \n",
        "     |      ...           print x \n",
        "     |      ...      yield None\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).foreachPartition(f)\n",
        "     |  \n",
        "     |  getStorageLevel(self)\n",
        "     |      Get the RDD's current storage level.\n",
        "     |      >>> rdd1 = sc.parallelize([1,2])\n",
        "     |      >>> rdd1.getStorageLevel()\n",
        "     |      StorageLevel(False, False, False, False, 1)\n",
        "     |  \n",
        "     |  glom(self)\n",
        "     |      Return an RDD created by coalescing all elements within each partition\n",
        "     |      into a list.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
        "     |      >>> sorted(rdd.glom().collect())\n",
        "     |      [[1, 2], [3, 4]]\n",
        "     |  \n",
        "     |  groupBy(self, f, numPartitions=None)\n",
        "     |      Return an RDD of grouped items.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 1, 2, 3, 5, 8])\n",
        "     |      >>> result = rdd.groupBy(lambda x: x % 2).collect()\n",
        "     |      >>> sorted([(x, sorted(y)) for (x, y) in result])\n",
        "     |      [(0, [2, 8]), (1, [1, 1, 3, 5])]\n",
        "     |  \n",
        "     |  groupByKey(self, numPartitions=None)\n",
        "     |      Group the values for each key in the RDD into a single sequence.\n",
        "     |      Hash-partitions the resulting RDD with into numPartitions partitions.\n",
        "     |      \n",
        "     |      Note: If you are grouping in order to perform an aggregation (such as a\n",
        "     |      sum or average) over each key, using reduceByKey will provide much better\n",
        "     |      performance.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> map((lambda (x,y): (x, list(y))), sorted(x.groupByKey().collect()))\n",
        "     |      [('a', [1, 1]), ('b', [1])]\n",
        "     |  \n",
        "     |  groupWith(self, other)\n",
        "     |      Alias for cogroup.\n",
        "     |  \n",
        "     |  id(self)\n",
        "     |      A unique ID for this RDD (within its SparkContext).\n",
        "     |  \n",
        "     |  join(self, other, numPartitions=None)\n",
        "     |      Return an RDD containing all pairs of elements with matching keys in\n",
        "     |      C{self} and C{other}.\n",
        "     |      \n",
        "     |      Each pair of elements will be returned as a (k, (v1, v2)) tuple, where\n",
        "     |      (k, v1) is in C{self} and (k, v2) is in C{other}.\n",
        "     |      \n",
        "     |      Performs a hash join across the cluster.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2), (\"a\", 3)])\n",
        "     |      >>> sorted(x.join(y).collect())\n",
        "     |      [('a', (1, 2)), ('a', (1, 3))]\n",
        "     |  \n",
        "     |  keyBy(self, f)\n",
        "     |      Creates tuples of the elements in this RDD by applying C{f}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize(range(0,3)).keyBy(lambda x: x*x)\n",
        "     |      >>> y = sc.parallelize(zip(range(0,5), range(0,5)))\n",
        "     |      >>> map((lambda (x,y): (x, (list(y[0]), (list(y[1]))))), sorted(x.cogroup(y).collect()))\n",
        "     |      [(0, ([0], [0])), (1, ([1], [1])), (2, ([], [2])), (3, ([], [3])), (4, ([2], [4]))]\n",
        "     |  \n",
        "     |  keys(self)\n",
        "     |      Return an RDD with the keys of each tuple.\n",
        "     |      >>> m = sc.parallelize([(1, 2), (3, 4)]).keys()\n",
        "     |      >>> m.collect()\n",
        "     |      [1, 3]\n",
        "     |  \n",
        "     |  leftOuterJoin(self, other, numPartitions=None)\n",
        "     |      Perform a left outer join of C{self} and C{other}.\n",
        "     |      \n",
        "     |      For each element (k, v) in C{self}, the resulting RDD will either\n",
        "     |      contain all pairs (k, (v, w)) for w in C{other}, or the pair\n",
        "     |      (k, (v, None)) if no elements in other have key k.\n",
        "     |      \n",
        "     |      Hash-partitions the resulting RDD into the given number of partitions.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2)])\n",
        "     |      >>> sorted(x.leftOuterJoin(y).collect())\n",
        "     |      [('a', (1, 2)), ('b', (4, None))]\n",
        "     |  \n",
        "     |  map(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by applying a function to each element of this RDD.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n",
        "     |      >>> sorted(rdd.map(lambda x: (x, 1)).collect())\n",
        "     |      [('a', 1), ('b', 1), ('c', 1)]\n",
        "     |  \n",
        "     |  mapPartitions(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by applying a function to each partition of this RDD.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
        "     |      >>> def f(iterator): yield sum(iterator)\n",
        "     |      >>> rdd.mapPartitions(f).collect()\n",
        "     |      [3, 7]\n",
        "     |  \n",
        "     |  mapPartitionsWithIndex(self, f, preservesPartitioning=False)\n",
        "     |      Return a new RDD by applying a function to each partition of this RDD,\n",
        "     |      while tracking the index of the original partition.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
        "     |      >>> def f(splitIndex, iterator): yield splitIndex\n",
        "     |      >>> rdd.mapPartitionsWithIndex(f).sum()\n",
        "     |      6\n",
        "     |  \n",
        "     |  mapPartitionsWithSplit(self, f, preservesPartitioning=False)\n",
        "     |      Deprecated: use mapPartitionsWithIndex instead.\n",
        "     |      \n",
        "     |      Return a new RDD by applying a function to each partition of this RDD,\n",
        "     |      while tracking the index of the original partition.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
        "     |      >>> def f(splitIndex, iterator): yield splitIndex\n",
        "     |      >>> rdd.mapPartitionsWithSplit(f).sum()\n",
        "     |      6\n",
        "     |  \n",
        "     |  mapValues(self, f)\n",
        "     |      Pass each value in the key-value pair RDD through a map function\n",
        "     |      without changing the keys; this also retains the original RDD's\n",
        "     |      partitioning.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", [\"apple\", \"banana\", \"lemon\"]), (\"b\", [\"grapes\"])])\n",
        "     |      >>> def f(x): return len(x)\n",
        "     |      >>> x.mapValues(f).collect()\n",
        "     |      [('a', 3), ('b', 1)]\n",
        "     |  \n",
        "     |  max(self)\n",
        "     |      Find the maximum item in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1.0, 5.0, 43.0, 10.0]).max()\n",
        "     |      43.0\n",
        "     |  \n",
        "     |  mean(self)\n",
        "     |      Compute the mean of this RDD's elements.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).mean()\n",
        "     |      2.0\n",
        "     |  \n",
        "     |  min(self)\n",
        "     |      Find the maximum item in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1.0, 5.0, 43.0, 10.0]).min()\n",
        "     |      1.0\n",
        "     |  \n",
        "     |  name(self)\n",
        "     |      Return the name of this RDD.\n",
        "     |  \n",
        "     |  partitionBy(self, numPartitions, partitionFunc=<built-in function hash>)\n",
        "     |      Return a copy of the RDD partitioned using the specified partitioner.\n",
        "     |      \n",
        "     |      >>> pairs = sc.parallelize([1, 2, 3, 4, 2, 4, 1]).map(lambda x: (x, x))\n",
        "     |      >>> sets = pairs.partitionBy(2).glom().collect()\n",
        "     |      >>> set(sets[0]).intersection(set(sets[1]))\n",
        "     |      set([])\n",
        "     |  \n",
        "     |  pipe(self, command, env={})\n",
        "     |      Return an RDD created by piping elements to a forked external process.\n",
        "     |      \n",
        "     |      >>> sc.parallelize(['1', '2', '', '3']).pipe('cat').collect()\n",
        "     |      ['1', '2', '', '3']\n",
        "     |  \n",
        "     |  reduce(self, f)\n",
        "     |      Reduces the elements of this RDD using the specified commutative and\n",
        "     |      associative binary operator. Currently reduces partitions locally.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4, 5]).reduce(add)\n",
        "     |      15\n",
        "     |      >>> sc.parallelize((2 for _ in range(10))).map(lambda x: 1).cache().reduce(add)\n",
        "     |      10\n",
        "     |  \n",
        "     |  reduceByKey(self, func, numPartitions=None)\n",
        "     |      Merge the values for each key using an associative reduce function.\n",
        "     |      \n",
        "     |      This will also perform the merging locally on each mapper before\n",
        "     |      sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
        "     |      \n",
        "     |      Output will be hash-partitioned with C{numPartitions} partitions, or\n",
        "     |      the default parallelism level if C{numPartitions} is not specified.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> sorted(rdd.reduceByKey(add).collect())\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  reduceByKeyLocally(self, func)\n",
        "     |      Merge the values for each key using an associative reduce function, but\n",
        "     |      return the results immediately to the master as a dictionary.\n",
        "     |      \n",
        "     |      This will also perform the merging locally on each mapper before\n",
        "     |      sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
        "     |      \n",
        "     |      >>> from operator import add\n",
        "     |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
        "     |      >>> sorted(rdd.reduceByKeyLocally(add).items())\n",
        "     |      [('a', 2), ('b', 1)]\n",
        "     |  \n",
        "     |  rightOuterJoin(self, other, numPartitions=None)\n",
        "     |      Perform a right outer join of C{self} and C{other}.\n",
        "     |      \n",
        "     |      For each element (k, w) in C{other}, the resulting RDD will either\n",
        "     |      contain all pairs (k, (v, w)) for v in this, or the pair (k, (None, w))\n",
        "     |      if no elements in C{self} have key k.\n",
        "     |      \n",
        "     |      Hash-partitions the resulting RDD into the given number of partitions.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 2)])\n",
        "     |      >>> sorted(y.rightOuterJoin(x).collect())\n",
        "     |      [('a', (2, 1)), ('b', (None, 4))]\n",
        "     |  \n",
        "     |  sample(self, withReplacement, fraction, seed=None)\n",
        "     |      Return a sampled subset of this RDD (relies on numpy and falls back\n",
        "     |      on default random generator if numpy is unavailable).\n",
        "     |      \n",
        "     |      >>> sc.parallelize(range(0, 100)).sample(False, 0.1, 2).collect() #doctest: +SKIP\n",
        "     |      [2, 3, 20, 21, 24, 41, 42, 66, 67, 89, 90, 98]\n",
        "     |  \n",
        "     |  sampleStdev(self)\n",
        "     |      Compute the sample standard deviation of this RDD's elements (which corrects for bias in\n",
        "     |      estimating the standard deviation by dividing by N-1 instead of N).\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).sampleStdev()\n",
        "     |      1.0\n",
        "     |  \n",
        "     |  sampleVariance(self)\n",
        "     |      Compute the sample variance of this RDD's elements (which corrects for bias in\n",
        "     |      estimating the variance by dividing by N-1 instead of N).\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).sampleVariance()\n",
        "     |      1.0\n",
        "     |  \n",
        "     |  saveAsTextFile(self, path)\n",
        "     |      Save this RDD as a text file, using string representations of elements.\n",
        "     |      \n",
        "     |      >>> tempFile = NamedTemporaryFile(delete=True)\n",
        "     |      >>> tempFile.close()\n",
        "     |      >>> sc.parallelize(range(10)).saveAsTextFile(tempFile.name)\n",
        "     |      >>> from fileinput import input\n",
        "     |      >>> from glob import glob\n",
        "     |      >>> ''.join(sorted(input(glob(tempFile.name + \"/part-0000*\"))))\n",
        "     |      '0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'\n",
        "     |      \n",
        "     |      Empty lines are tolerated when saving to text files.\n",
        "     |      \n",
        "     |      >>> tempFile2 = NamedTemporaryFile(delete=True)\n",
        "     |      >>> tempFile2.close()\n",
        "     |      >>> sc.parallelize(['', 'foo', '', 'bar', '']).saveAsTextFile(tempFile2.name)\n",
        "     |      >>> ''.join(sorted(input(glob(tempFile2.name + \"/part-0000*\"))))\n",
        "     |      '\\n\\n\\nbar\\nfoo\\n'\n",
        "     |  \n",
        "     |  setName(self, name)\n",
        "     |      Assign a name to this RDD.\n",
        "     |      >>> rdd1 = sc.parallelize([1,2])\n",
        "     |      >>> rdd1.setName('RDD1')\n",
        "     |      >>> rdd1.name()\n",
        "     |      'RDD1'\n",
        "     |  \n",
        "     |  sortByKey(self, ascending=True, numPartitions=None, keyfunc=<function <lambda>>)\n",
        "     |      Sorts this RDD, which is assumed to consist of (key, value) pairs.\n",
        "     |      \n",
        "     |      >>> tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
        "     |      >>> sc.parallelize(tmp).sortByKey(True, 2).collect()\n",
        "     |      [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n",
        "     |      >>> tmp2 = [('Mary', 1), ('had', 2), ('a', 3), ('little', 4), ('lamb', 5)]\n",
        "     |      >>> tmp2.extend([('whose', 6), ('fleece', 7), ('was', 8), ('white', 9)])\n",
        "     |      >>> sc.parallelize(tmp2).sortByKey(True, 3, keyfunc=lambda k: k.lower()).collect()\n",
        "     |      [('a', 3), ('fleece', 7), ('had', 2), ('lamb', 5), ('little', 4), ('Mary', 1), ('was', 8), ('white', 9), ('whose', 6)]\n",
        "     |  \n",
        "     |  stats(self)\n",
        "     |      Return a L{StatCounter} object that captures the mean, variance\n",
        "     |      and count of the RDD's elements in one operation.\n",
        "     |  \n",
        "     |  stdev(self)\n",
        "     |      Compute the standard deviation of this RDD's elements.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).stdev()\n",
        "     |      0.816...\n",
        "     |  \n",
        "     |  subtractByKey(self, other, numPartitions=None)\n",
        "     |      Return each (key, value) pair in C{self} that has no pair with matching key\n",
        "     |      in C{other}.\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 2)])\n",
        "     |      >>> y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
        "     |      >>> sorted(x.subtractByKey(y).collect())\n",
        "     |      [('b', 4), ('b', 5)]\n",
        "     |  \n",
        "     |  sum(self)\n",
        "     |      Add up the elements in this RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1.0, 2.0, 3.0]).sum()\n",
        "     |      6.0\n",
        "     |  \n",
        "     |  take(self, num)\n",
        "     |      Take the first num elements of the RDD.\n",
        "     |      \n",
        "     |      This currently scans the partitions *one by one*, so it will be slow if\n",
        "     |      a lot of partitions are required. In that case, use L{collect} to get\n",
        "     |      the whole RDD instead.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)\n",
        "     |      [2, 3]\n",
        "     |      >>> sc.parallelize([2, 3, 4, 5, 6]).take(10)\n",
        "     |      [2, 3, 4, 5, 6]\n",
        "     |  \n",
        "     |  takeOrdered(self, num, key=None)\n",
        "     |      Get the N elements from a RDD ordered in ascending order or as specified\n",
        "     |      by the optional key function. \n",
        "     |      \n",
        "     |      >>> sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7]).takeOrdered(6)\n",
        "     |      [1, 2, 3, 4, 5, 6]\n",
        "     |      >>> sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7], 2).takeOrdered(6, key=lambda x: -x)\n",
        "     |      [10, 9, 7, 6, 5, 4]\n",
        "     |  \n",
        "     |  takeSample(self, withReplacement, num, seed=None)\n",
        "     |      Return a fixed-size sampled subset of this RDD (currently requires numpy).\n",
        "     |      \n",
        "     |      >>> sc.parallelize(range(0, 10)).takeSample(True, 10, 1) #doctest: +SKIP\n",
        "     |      [4, 2, 1, 8, 2, 7, 0, 4, 1, 4]\n",
        "     |  \n",
        "     |  toDebugString(self)\n",
        "     |      A description of this RDD and its recursive dependencies for debugging.\n",
        "     |  \n",
        "     |  top(self, num)\n",
        "     |      Get the top N elements from a RDD.\n",
        "     |      \n",
        "     |      Note: It returns the list sorted in descending order.\n",
        "     |      >>> sc.parallelize([10, 4, 2, 12, 3]).top(1)\n",
        "     |      [12]\n",
        "     |      >>> sc.parallelize([2, 3, 4, 5, 6], 2).cache().top(2)\n",
        "     |      [6, 5]\n",
        "     |  \n",
        "     |  union(self, other)\n",
        "     |      Return the union of this RDD and another one.\n",
        "     |      \n",
        "     |      >>> rdd = sc.parallelize([1, 1, 2, 3])\n",
        "     |      >>> rdd.union(rdd).collect()\n",
        "     |      [1, 1, 2, 3, 1, 1, 2, 3]\n",
        "     |  \n",
        "     |  values(self)\n",
        "     |      Return an RDD with the values of each tuple.\n",
        "     |      >>> m = sc.parallelize([(1, 2), (3, 4)]).values()\n",
        "     |      >>> m.collect()\n",
        "     |      [2, 4]\n",
        "     |  \n",
        "     |  variance(self)\n",
        "     |      Compute the variance of this RDD's elements.\n",
        "     |      \n",
        "     |      >>> sc.parallelize([1, 2, 3]).variance()\n",
        "     |      0.666...\n",
        "     |  \n",
        "     |  zip(self, other)\n",
        "     |      Zips this RDD with another one, returning key-value pairs with the first element in each RDD\n",
        "     |      second element in each RDD, etc. Assumes that the two RDDs have the same number of\n",
        "     |      partitions and the same number of elements in each partition (e.g. one was made through\n",
        "     |      a map on the other).\n",
        "     |      \n",
        "     |      >>> x = sc.parallelize(range(0,5))\n",
        "     |      >>> y = sc.parallelize(range(1000, 1005))\n",
        "     |      >>> x.zip(y).collect()\n",
        "     |      [(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors inherited from pyspark.rdd.RDD:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  context\n",
        "     |      The L{SparkContext} that this RDD was created on.\n",
        "    \n",
        "    class SparkConf(__builtin__.object)\n",
        "     |  Configuration for a Spark application. Used to set various Spark\n",
        "     |  parameters as key-value pairs.\n",
        "     |  \n",
        "     |  Most of the time, you would create a SparkConf object with\n",
        "     |  C{SparkConf()}, which will load values from C{spark.*} Java system\n",
        "     |  properties as well. In this case, any parameters you set directly on\n",
        "     |  the C{SparkConf} object take priority over system properties.\n",
        "     |  \n",
        "     |  For unit tests, you can also call C{SparkConf(false)} to skip\n",
        "     |  loading external settings and get the same configuration no matter\n",
        "     |  what the system properties are.\n",
        "     |  \n",
        "     |  All setter methods in this class support chaining. For example,\n",
        "     |  you can write C{conf.setMaster(\"local\").setAppName(\"My app\")}.\n",
        "     |  \n",
        "     |  Note that once a SparkConf object is passed to Spark, it is cloned\n",
        "     |  and can no longer be modified by the user.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, loadDefaults=True, _jvm=None, _jconf=None)\n",
        "     |      Create a new Spark configuration.\n",
        "     |      \n",
        "     |      @param loadDefaults: whether to load values from Java system\n",
        "     |             properties (True by default)\n",
        "     |      @param _jvm: internal parameter used to pass a handle to the\n",
        "     |             Java VM; does not need to be set by users\n",
        "     |      @param _jconf: Optionally pass in an existing SparkConf handle\n",
        "     |             to use its parameters\n",
        "     |  \n",
        "     |  contains(self, key)\n",
        "     |      Does this configuration contain a given key?\n",
        "     |  \n",
        "     |  get(self, key, defaultValue=None)\n",
        "     |      Get the configured value for some key, or return a default otherwise.\n",
        "     |  \n",
        "     |  getAll(self)\n",
        "     |      Get all values as a list of key-value pairs.\n",
        "     |  \n",
        "     |  set(self, key, value)\n",
        "     |      Set a configuration property.\n",
        "     |  \n",
        "     |  setAll(self, pairs)\n",
        "     |      Set multiple parameters, passed as a list of key-value pairs.\n",
        "     |      \n",
        "     |      @param pairs: list of key-value pairs to set\n",
        "     |  \n",
        "     |  setAppName(self, value)\n",
        "     |      Set application name.\n",
        "     |  \n",
        "     |  setExecutorEnv(self, key=None, value=None, pairs=None)\n",
        "     |      Set an environment variable to be passed to executors.\n",
        "     |  \n",
        "     |  setMaster(self, value)\n",
        "     |      Set master URL to connect to.\n",
        "     |  \n",
        "     |  setSparkHome(self, value)\n",
        "     |      Set path where Spark is installed on worker nodes.\n",
        "     |  \n",
        "     |  toDebugString(self)\n",
        "     |      Returns a printable version of the configuration, as a list of\n",
        "     |      key=value pairs, one per line.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "    \n",
        "    class SparkContext(__builtin__.object)\n",
        "     |  Main entry point for Spark functionality. A SparkContext represents the\n",
        "     |  connection to a Spark cluster, and can be used to create L{RDD}s and\n",
        "     |  broadcast variables on that cluster.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __del__(self)\n",
        "     |  \n",
        "     |  __init__(self, master=None, appName=None, sparkHome=None, pyFiles=None, environment=None, batchSize=1024, serializer=<pyspark.serializers.PickleSerializer object>, conf=None, gateway=None)\n",
        "     |      Create a new SparkContext. At least the master and app name should be set,\n",
        "     |      either through the named parameters here or through C{conf}.\n",
        "     |      \n",
        "     |      @param master: Cluster URL to connect to\n",
        "     |             (e.g. mesos://host:port, spark://host:port, local[4]).\n",
        "     |      @param appName: A name for your job, to display on the cluster web UI.\n",
        "     |      @param sparkHome: Location where Spark is installed on cluster nodes.\n",
        "     |      @param pyFiles: Collection of .zip or .py files to send to the cluster\n",
        "     |             and add to PYTHONPATH.  These can be paths on the local file\n",
        "     |             system or HDFS, HTTP, HTTPS, or FTP URLs.\n",
        "     |      @param environment: A dictionary of environment variables to set on\n",
        "     |             worker nodes.\n",
        "     |      @param batchSize: The number of Python objects represented as a single\n",
        "     |             Java object.  Set 1 to disable batching or -1 to use an\n",
        "     |             unlimited batch size.\n",
        "     |      @param serializer: The serializer for RDDs.\n",
        "     |      @param conf: A L{SparkConf} object setting Spark properties.\n",
        "     |      @param gateway: Use an existing gateway and JVM, otherwise a new JVM\n",
        "     |             will be instatiated.\n",
        "     |      \n",
        "     |      \n",
        "     |      >>> from pyspark.context import SparkContext\n",
        "     |      >>> sc = SparkContext('local', 'test')\n",
        "     |      \n",
        "     |      >>> sc2 = SparkContext('local', 'test2') # doctest: +IGNORE_EXCEPTION_DETAIL\n",
        "     |      Traceback (most recent call last):\n",
        "     |          ...\n",
        "     |      ValueError:...\n",
        "     |  \n",
        "     |  accumulator(self, value, accum_param=None)\n",
        "     |      Create an L{Accumulator} with the given initial value, using a given\n",
        "     |      L{AccumulatorParam} helper object to define how to add values of the\n",
        "     |      data type if provided. Default AccumulatorParams are used for integers\n",
        "     |      and floating-point numbers if you do not provide one. For other types,\n",
        "     |      a custom AccumulatorParam can be used.\n",
        "     |  \n",
        "     |  addFile(self, path)\n",
        "     |      Add a file to be downloaded with this Spark job on every node.\n",
        "     |      The C{path} passed can be either a local file, a file in HDFS\n",
        "     |      (or other Hadoop-supported filesystems), or an HTTP, HTTPS or\n",
        "     |      FTP URI.\n",
        "     |      \n",
        "     |      To access the file in Spark jobs, use\n",
        "     |      L{SparkFiles.get(path)<pyspark.files.SparkFiles.get>} to find its\n",
        "     |      download location.\n",
        "     |      \n",
        "     |      >>> from pyspark import SparkFiles\n",
        "     |      >>> path = os.path.join(tempdir, \"test.txt\")\n",
        "     |      >>> with open(path, \"w\") as testFile:\n",
        "     |      ...    testFile.write(\"100\")\n",
        "     |      >>> sc.addFile(path)\n",
        "     |      >>> def func(iterator):\n",
        "     |      ...    with open(SparkFiles.get(\"test.txt\")) as testFile:\n",
        "     |      ...        fileVal = int(testFile.readline())\n",
        "     |      ...        return [x * 100 for x in iterator]\n",
        "     |      >>> sc.parallelize([1, 2, 3, 4]).mapPartitions(func).collect()\n",
        "     |      [100, 200, 300, 400]\n",
        "     |  \n",
        "     |  addPyFile(self, path)\n",
        "     |      Add a .py or .zip dependency for all tasks to be executed on this\n",
        "     |      SparkContext in the future.  The C{path} passed can be either a local\n",
        "     |      file, a file in HDFS (or other Hadoop-supported filesystems), or an\n",
        "     |      HTTP, HTTPS or FTP URI.\n",
        "     |  \n",
        "     |  broadcast(self, value)\n",
        "     |      Broadcast a read-only variable to the cluster, returning a\n",
        "     |      L{Broadcast<pyspark.broadcast.Broadcast>}\n",
        "     |      object for reading it in distributed functions. The variable will be\n",
        "     |      sent to each cluster only once.\n",
        "     |  \n",
        "     |  cancelAllJobs(self)\n",
        "     |      Cancel all jobs that have been scheduled or are running.\n",
        "     |  \n",
        "     |  cancelJobGroup(self, groupId)\n",
        "     |      Cancel active jobs for the specified group. See L{SparkContext.setJobGroup}\n",
        "     |      for more information.\n",
        "     |  \n",
        "     |  clearFiles(self)\n",
        "     |      Clear the job's list of files added by L{addFile} or L{addPyFile} so\n",
        "     |      that they do not get downloaded to any new nodes.\n",
        "     |  \n",
        "     |  getLocalProperty(self, key)\n",
        "     |      Get a local property set in this thread, or null if it is missing. See\n",
        "     |      L{setLocalProperty}\n",
        "     |  \n",
        "     |  parallelize(self, c, numSlices=None)\n",
        "     |      Distribute a local Python collection to form an RDD.\n",
        "     |      \n",
        "     |      >>> sc.parallelize(range(5), 5).glom().collect()\n",
        "     |      [[0], [1], [2], [3], [4]]\n",
        "     |  \n",
        "     |  setCheckpointDir(self, dirName)\n",
        "     |      Set the directory under which RDDs are going to be checkpointed. The\n",
        "     |      directory must be a HDFS path if running on a cluster.\n",
        "     |  \n",
        "     |  setJobGroup(self, groupId, description, interruptOnCancel=False)\n",
        "     |      Assigns a group ID to all the jobs started by this thread until the group ID is set to a\n",
        "     |      different value or cleared.\n",
        "     |      \n",
        "     |      Often, a unit of execution in an application consists of multiple Spark actions or jobs.\n",
        "     |      Application programmers can use this method to group all those jobs together and give a\n",
        "     |      group description. Once set, the Spark web UI will associate such jobs with this group.\n",
        "     |      \n",
        "     |      The application can use L{SparkContext.cancelJobGroup} to cancel all\n",
        "     |      running jobs in this group.\n",
        "     |      \n",
        "     |      >>> import thread, threading\n",
        "     |      >>> from time import sleep\n",
        "     |      >>> result = \"Not Set\"\n",
        "     |      >>> lock = threading.Lock()\n",
        "     |      >>> def map_func(x):\n",
        "     |      ...     sleep(100)\n",
        "     |      ...     raise Exception(\"Task should have been cancelled\")\n",
        "     |      >>> def start_job(x):\n",
        "     |      ...     global result\n",
        "     |      ...     try:\n",
        "     |      ...         sc.setJobGroup(\"job_to_cancel\", \"some description\")\n",
        "     |      ...         result = sc.parallelize(range(x)).map(map_func).collect()\n",
        "     |      ...     except Exception as e:\n",
        "     |      ...         result = \"Cancelled\"\n",
        "     |      ...     lock.release()\n",
        "     |      >>> def stop_job():\n",
        "     |      ...     sleep(5)\n",
        "     |      ...     sc.cancelJobGroup(\"job_to_cancel\")\n",
        "     |      >>> supress = lock.acquire()\n",
        "     |      >>> supress = thread.start_new_thread(start_job, (10,))\n",
        "     |      >>> supress = thread.start_new_thread(stop_job, tuple())\n",
        "     |      >>> supress = lock.acquire()\n",
        "     |      >>> print result\n",
        "     |      Cancelled\n",
        "     |      \n",
        "     |      If interruptOnCancel is set to true for the job group, then job cancellation will result\n",
        "     |      in Thread.interrupt() being called on the job's executor threads. This is useful to help ensure\n",
        "     |      that the tasks are actually stopped in a timely manner, but is off by default due to HDFS-1208,\n",
        "     |      where HDFS may respond to Thread.interrupt() by marking nodes as dead.\n",
        "     |  \n",
        "     |  setLocalProperty(self, key, value)\n",
        "     |      Set a local property that affects jobs submitted from this thread, such as the\n",
        "     |      Spark fair scheduler pool.\n",
        "     |  \n",
        "     |  sparkUser(self)\n",
        "     |      Get SPARK_USER for user who is running SparkContext.\n",
        "     |  \n",
        "     |  stop(self)\n",
        "     |      Shut down the SparkContext.\n",
        "     |  \n",
        "     |  textFile(self, name, minPartitions=None)\n",
        "     |      Read a text file from HDFS, a local file system (available on all\n",
        "     |      nodes), or any Hadoop-supported file system URI, and return it as an\n",
        "     |      RDD of Strings.\n",
        "     |  \n",
        "     |  union(self, rdds)\n",
        "     |      Build the union of a list of RDDs.\n",
        "     |      \n",
        "     |      This supports unions() of RDDs with different serialized formats,\n",
        "     |      although this forces them to be reserialized using the default\n",
        "     |      serializer:\n",
        "     |      \n",
        "     |      >>> path = os.path.join(tempdir, \"union-text.txt\")\n",
        "     |      >>> with open(path, \"w\") as testFile:\n",
        "     |      ...    testFile.write(\"Hello\")\n",
        "     |      >>> textFile = sc.textFile(path)\n",
        "     |      >>> textFile.collect()\n",
        "     |      [u'Hello']\n",
        "     |      >>> parallelized = sc.parallelize([\"World!\"])\n",
        "     |      >>> sorted(sc.union([textFile, parallelized]).collect())\n",
        "     |      [u'Hello', 'World!']\n",
        "     |  \n",
        "     |  wholeTextFiles(self, path, minPartitions=None)\n",
        "     |      Read a directory of text files from HDFS, a local file system\n",
        "     |      (available on all nodes), or any  Hadoop-supported file system\n",
        "     |      URI. Each file is read as a single record and returned in a\n",
        "     |      key-value pair, where the key is the path of each file, the\n",
        "     |      value is the content of each file.\n",
        "     |      \n",
        "     |      For example, if you have the following files::\n",
        "     |      \n",
        "     |        hdfs://a-hdfs-path/part-00000\n",
        "     |        hdfs://a-hdfs-path/part-00001\n",
        "     |        ...\n",
        "     |        hdfs://a-hdfs-path/part-nnnnn\n",
        "     |      \n",
        "     |      Do C{rdd = sparkContext.wholeTextFiles(\"hdfs://a-hdfs-path\")},\n",
        "     |      then C{rdd} contains::\n",
        "     |      \n",
        "     |        (a-hdfs-path/part-00000, its content)\n",
        "     |        (a-hdfs-path/part-00001, its content)\n",
        "     |        ...\n",
        "     |        (a-hdfs-path/part-nnnnn, its content)\n",
        "     |      \n",
        "     |      NOTE: Small files are preferred, as each file will be loaded\n",
        "     |      fully in memory.\n",
        "     |      \n",
        "     |      >>> dirPath = os.path.join(tempdir, \"files\")\n",
        "     |      >>> os.mkdir(dirPath)\n",
        "     |      >>> with open(os.path.join(dirPath, \"1.txt\"), \"w\") as file1:\n",
        "     |      ...    file1.write(\"1\")\n",
        "     |      >>> with open(os.path.join(dirPath, \"2.txt\"), \"w\") as file2:\n",
        "     |      ...    file2.write(\"2\")\n",
        "     |      >>> textFiles = sc.wholeTextFiles(dirPath)\n",
        "     |      >>> sorted(textFiles.collect())\n",
        "     |      [(u'.../1.txt', u'1'), (u'.../2.txt', u'2')]\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Class methods defined here:\n",
        "     |  \n",
        "     |  setSystemProperty(cls, key, value) from __builtin__.type\n",
        "     |      Set a Java system property, such as spark.executor.memory. This must\n",
        "     |      must be invoked before instantiating SparkContext.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "     |  \n",
        "     |  defaultMinPartitions\n",
        "     |      Default min number of partitions for Hadoop RDDs when not given by user\n",
        "     |  \n",
        "     |  defaultParallelism\n",
        "     |      Default level of parallelism to use when not given by user (e.g. for\n",
        "     |      reduce tasks)\n",
        "    \n",
        "    class SparkFiles(__builtin__.object)\n",
        "     |  Resolves paths to files added through\n",
        "     |  L{SparkContext.addFile()<pyspark.context.SparkContext.addFile>}.\n",
        "     |  \n",
        "     |  SparkFiles contains only classmethods; users should not create SparkFiles\n",
        "     |  instances.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Class methods defined here:\n",
        "     |  \n",
        "     |  get(cls, filename) from __builtin__.type\n",
        "     |      Get the absolute path of a file added through C{SparkContext.addFile()}.\n",
        "     |  \n",
        "     |  getRootDirectory(cls) from __builtin__.type\n",
        "     |      Get the root directory that contains files added through\n",
        "     |      C{SparkContext.addFile()}.\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data descriptors defined here:\n",
        "     |  \n",
        "     |  __dict__\n",
        "     |      dictionary for instance variables (if defined)\n",
        "     |  \n",
        "     |  __weakref__\n",
        "     |      list of weak references to the object (if defined)\n",
        "    \n",
        "    class StorageLevel\n",
        "     |  Flags for controlling the storage of an RDD. Each StorageLevel records whether to use memory,\n",
        "     |  whether to drop the RDD to disk if it falls out of memory, whether to keep the data in memory\n",
        "     |  in a serialized format, and whether to replicate the RDD partitions on multiple nodes.\n",
        "     |  Also contains static constants for some commonly used storage levels, such as MEMORY_ONLY.\n",
        "     |  \n",
        "     |  Methods defined here:\n",
        "     |  \n",
        "     |  __init__(self, useDisk, useMemory, useOffHeap, deserialized, replication=1)\n",
        "     |  \n",
        "     |  __repr__(self)\n",
        "     |  \n",
        "     |  ----------------------------------------------------------------------\n",
        "     |  Data and other attributes defined here:\n",
        "     |  \n",
        "     |  DISK_ONLY = StorageLevel(True, False, False, False, 1)\n",
        "     |  \n",
        "     |  DISK_ONLY_2 = StorageLevel(True, False, False, False, 2)\n",
        "     |  \n",
        "     |  MEMORY_AND_DISK = StorageLevel(True, True, False, True, 1)\n",
        "     |  \n",
        "     |  MEMORY_AND_DISK_2 = StorageLevel(True, True, False, True, 2)\n",
        "     |  \n",
        "     |  MEMORY_AND_DISK_SER = StorageLevel(True, True, False, False, 1)\n",
        "     |  \n",
        "     |  MEMORY_AND_DISK_SER_2 = StorageLevel(True, True, False, False, 2)\n",
        "     |  \n",
        "     |  MEMORY_ONLY = StorageLevel(False, True, False, True, 1)\n",
        "     |  \n",
        "     |  MEMORY_ONLY_2 = StorageLevel(False, True, False, True, 2)\n",
        "     |  \n",
        "     |  MEMORY_ONLY_SER = StorageLevel(False, True, False, False, 1)\n",
        "     |  \n",
        "     |  MEMORY_ONLY_SER_2 = StorageLevel(False, True, False, False, 2)\n",
        "     |  \n",
        "     |  OFF_HEAP = StorageLevel(False, False, True, False, 1)\n",
        "\n",
        "DATA\n",
        "    __all__ = ['SparkConf', 'SparkContext', 'SQLContext', 'RDD', 'SchemaRD...\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "info = sc.parallelize([stream.next()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "info.count()\n",
      "val = info.map(lambda a: Tweet(a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 256,
       "text": [
        "<repr(<pyspark.rdd.PipelinedRDD at 0x108492990>) failed: AssertionError: >"
       ]
      }
     ],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}